<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.36" />

<link rel="alternate" type="application/rss+xml" title="RSS" href="/categories/mcgill-statistics-seminar/index.xml">

<link rel="canonical" href="/categories/mcgill-statistics-seminar/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Mcgill Statistics Seminar - McGill Statistics Seminars</title>
    
    <link href="/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Mcgill Statistics Seminar</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-03-10T00:00:00JST">Mar 10, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2017winter/2017-03-10/">High-throughput single-cell biology: The challenges and opportunities for machine learning scientists</a></h2>
    <h3 class="post-meta">Nima Aghaeepour · Mar 10, 2017 </h3>
  </header>

  
  <div class="summary">Date: 2017-03-10 Time: 15:30-16:30 Location: BURN 1205 Abstract: The immune system does a lot more than killing “foreign” invaders. It’s a powerful sensory system that can detect stress levels, infections, wounds, and even cancer tumors. However, due to the complex interplay between different cell types and signaling pathways, the amount of data produced to characterize all different aspects of the immune system (tens of thousands of genes measured and hundreds of millions of cells, just from a single patient) completely overwhelms existing bioinformatics tools.</div>

  
  <footer>
    <a href="/post/2017winter/2017-03-10/" title="High-throughput single-cell biology: The challenges and opportunities for machine learning scientists">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-02-24T00:00:00JST">Feb 24, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2017winter/2017-02-24/">The first pillar of statistical wisdom</a></h2>
    <h3 class="post-meta">James A. Hanley · Feb 24, 2017 </h3>
  </header>

  
  <div class="summary">Date: 2017-02-24 Time: 15:30-16:30 Location: BURN 1205 Abstract: This talk will provide an introduction to the first of the pillars in Stephen Stigler&rsquo;s 2016 book The Seven Pillars of Statistical Wisdom, namely “Aggregation.” It will focus on early instances of the sample mean in scientific work, on the early error distributions, and on how their “centres” were fitted.
Speaker James A. Hanley is a Professor in the Department of Epidemiology, Biostatistics and Occupational Health, at McGill University.</div>

  
  <footer>
    <a href="/post/2017winter/2017-02-24/" title="The first pillar of statistical wisdom">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-02-17T00:00:00JST">Feb 17, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2017winter/2017-02-17/">Building end-to-end dialogue systems using deep neural architectures</a></h2>
    <h3 class="post-meta">Joelle Pineau · Feb 17, 2017 </h3>
  </header>

  
  <div class="summary">Date: 2017-02-17 Time: 15:30-16:30 Location: BURN 1205 Abstract: The ability for a computer to converse in a natural and coherent manner with a human has long been held as one of the important steps towards solving artificial intelligence. In this talk I will present recent results on building dialogue systems from large corpuses using deep neural architectures. I will highlight several challenges related to data acquisition, algorithmic development, and performance evaluation.</div>

  
  <footer>
    <a href="/post/2017winter/2017-02-17/" title="Building end-to-end dialogue systems using deep neural architectures">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-02-10T00:00:00JST">Feb 10, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2017winter/2017-02-10/">Sparse envelope model: Efficient estimation and response variable selection in multivariate linear regression</a></h2>
    <h3 class="post-meta">Zhihua Su · Feb 10, 2017 </h3>
  </header>

  
  <div class="summary">Date: 2017-02-10 Time: 15:30-16:30 Location: BURN 1205 Abstract: The envelope model is a method for efficient estimation in multivariate linear regression. In this article, we propose the sparse envelope model, which is motivated by applications where some response variables are invariant to changes of the predictors and have zero regression coefficients. The envelope estimator is consistent but not sparse, and in many situations it is important to identify the response variables for which the regression coefficients are zero.</div>

  
  <footer>
    <a href="/post/2017winter/2017-02-10/" title="Sparse envelope model: Efficient estimation and response variable selection in multivariate linear regression">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-02-03T00:00:00JST">Feb 3, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2017winter/2017-02-03/">MM algorithms for variance component models</a></h2>
    <h3 class="post-meta">Hua Zhou · Feb 3, 2017 </h3>
  </header>

  
  <div class="summary">Date: 2017-02-03 Time: 15:30-16:30 Location: BURN 1205 Abstract: Variance components estimation and mixed model analysis are central themes in statistics with applications in numerous scientific disciplines. Despite the best efforts of generations of statisticians and numerical analysts, maximum likelihood estimation and restricted maximum likelihood estimation of variance component models remain numerically challenging. In this talk, we present a novel iterative algorithm for variance components estimation based on the minorization-maximization (MM) principle.</div>

  
  <footer>
    <a href="/post/2017winter/2017-02-03/" title="MM algorithms for variance component models">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-01-20T00:00:00JST">Jan 20, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2017winter/2017-01-20/">Order selection in multidimensional finite mixture models</a></h2>
    <h3 class="post-meta">Tudor Manole · Jan 20, 2017 </h3>
  </header>

  
  <div class="summary">Date: 2017-01-20 Time: 15:30-16:30 Location: BURN 1205 Abstract: Finite mixture models provide a natural framework for analyzing data from heterogeneous populations. In practice, however, the number of hidden subpopulations in the data may be unknown. The problem of estimating the order of a mixture model, namely the number of subpopulations, is thus crucial for many applications. In this talk, we present a new penalized likelihood solution to this problem, which is applicable to models with a multidimensional parameter space.</div>

  
  <footer>
    <a href="/post/2017winter/2017-01-20/" title="Order selection in multidimensional finite mixture models">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-01-13T00:00:00JST">Jan 13, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2017winter/2017-01-13/">(Sparse) exchangeable graphs</a></h2>
    <h3 class="post-meta">Victor Veitch · Jan 13, 2017 </h3>
  </header>

  
  <div class="summary">Date: 2017-01-13 Time: 15:30-16:30 Location: BURN 1205 Abstract: Many popular statistical models for network valued datasets fall under the remit of the graphon framework, which (implicitly) assumes the networks are densely connected. However, this assumption rarely holds for the real-world networks of practical interest. We introduce a new class of models for random graphs that generalises the dense graphon models to the sparse graph regime, and we argue that this meets many of the desiderata one would demand of a model to serve as the foundation for a statistical analysis of real-world networks.</div>

  
  <footer>
    <a href="/post/2017winter/2017-01-13/" title="(Sparse) exchangeable graphs">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2016-12-02T00:00:00JST">Dec 2, 2016</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2016fall/2016-12-02/">Modeling dependence in bivariate multi-state processes: A frailty approach</a></h2>
    <h3 class="post-meta">Andrea Giussani · Dec 2, 2016 </h3>
  </header>

  
  <div class="summary">Date: 2016-12-02 Time: 15:30-16:30 Location: BURN 1205 Abstract: The aim of this talk is to present a statistical framework for the analysis of dependent bivariate multistate processes, allowing one to study the dependence both across subjects in a pair and among individual-specific events. As for the latter, copula- based models are employed, whereas dependence between multi-state models can be accomplished by means of frailties. The well known Marshall-Olkin Bivariate Exponential Distribution (MOBVE) is considered for the joint distribution of frailties.</div>

  
  <footer>
    <a href="/post/2016fall/2016-12-02/" title="Modeling dependence in bivariate multi-state processes: A frailty approach">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2016-11-25T00:00:00JST">Nov 25, 2016</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2016fall/2016-11-25/">Spatio-temporal models for skewed processes</a></h2>
    <h3 class="post-meta">Alexandra Schmidt · Nov 25, 2016 </h3>
  </header>

  
  <div class="summary">Date: 2016-11-25 Time: 15:30-16:30 Location: BURN 1205 Abstract: In the analysis of most spatio-temporal processes in environmental studies, observations present skewed distributions. Usually, a single transformation of the data is used to approximate normality, and stationary Gaussian processes are assumed to model the transformed data. The choice of transformation is key for spatial interpolation and temporal prediction. We propose a spatio-temporal model for skewed data that does not require the use of data transformation.</div>

  
  <footer>
    <a href="/post/2016fall/2016-11-25/" title="Spatio-temporal models for skewed processes">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2016-11-18T00:00:00JST">Nov 18, 2016</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2016fall/2016-11-18/">Progress in theoretical understanding of deep learning</a></h2>
    <h3 class="post-meta">Yoshua Bengio · Nov 18, 2016 </h3>
  </header>

  
  <div class="summary">Date: 2016-11-18 Time: 15:30-16:30 Location: BURN 1205 Abstract: Deep learning has arisen around 2006 as a renewal of neural networks research allowing such models to have more layers. Theoretical investigations have shown that functions obtained as deep compositions of simpler functions (which includes both deep and recurrent nets) can express highly varying functions (with many ups and downs and different input regions that can be distinguished) much more efficiently (with fewer parameters) than otherwise, under a prior which seems to work well for artificial intelligence tasks.</div>

  
  <footer>
    <a href="/post/2016fall/2016-11-18/" title="Progress in theoretical understanding of deep learning">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/categories/mcgill-statistics-seminar/page/5/">Previous</a></li>
    

    
    <li><a href="/categories/mcgill-statistics-seminar/page/7/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="/post/2019winter/2019-04-26/" class="list-group-item">Jian Tang · Apr 26, 2019</a>
      
      <a href="/post/2019winter/2019-04-12/" class="list-group-item">Tianchen Qian · Apr 12, 2019</a>
      
      <a href="/post/2019winter/2019-04-05/" class="list-group-item">Yanxun Xu · Apr 5, 2019</a>
      
      <a href="/post/2019winter/2019-03-29/" class="list-group-item">Nema Dean · Mar 29, 2019</a>
      
      <a href="/post/2019winter/2019-03-22/" class="list-group-item">Andrew Gelman · Mar 22, 2019</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="/categories/mcgill-statistics-seminar" class="list-group-item">mcgill-statistics-seminar</a>
      
      <a href="/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc-prize-address</a>
      
      <a href="/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="/tags/2019-winter" class="list-group-item">2019-winter</a>
      
      <a href="/tags/2019-fall" class="list-group-item">2019-fall</a>
      
      <a href="/tags/2018-winter" class="list-group-item">2018-winter</a>
      
      <a href="/tags/2018-fall" class="list-group-item">2018-fall</a>
      
      <a href="/tags/2017-winter" class="list-group-item">2017-winter</a>
      
      <a href="/tags/2017-fall" class="list-group-item">2017-fall</a>
      
      <a href="/tags/2016-winter" class="list-group-item">2016-winter</a>
      
      <a href="/tags/2016-fall" class="list-group-item">2016-fall</a>
      
      <a href="/tags/2015-winter" class="list-group-item">2015-winter</a>
      
      <a href="/tags/2015-fall" class="list-group-item">2015-fall</a>
      
      <a href="/tags/2014-winter" class="list-group-item">2014-winter</a>
      
      <a href="/tags/2014-fall" class="list-group-item">2014-fall</a>
      
      <a href="/tags/2013-winter" class="list-group-item">2013-winter</a>
      
      <a href="/tags/2013-fall" class="list-group-item">2013-fall</a>
      
      <a href="/tags/2012-winter" class="list-group-item">2012-winter</a>
      
      <a href="/tags/2012-fall" class="list-group-item">2012-fall</a>
      
      <a href="/tags/2011-fall" class="list-group-item">2011-fall</a>
      
    </div>
  </section>
  

</aside>


  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

