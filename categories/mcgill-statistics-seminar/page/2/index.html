<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.36.1" />

<link rel="alternate" type="application/rss+xml" title="RSS" href="/categories/mcgill-statistics-seminar/index.xml">

<link rel="canonical" href="/categories/mcgill-statistics-seminar/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Mcgill Statistics Seminar - McGill Statistics Seminars</title>
    
    <link href="/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Mcgill Statistics Seminar</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-01-13T00:00:00JST">Jan 13, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2020winter/2020-01-13/">Estimation and inference for changepoint models</a></h2>
    <h3 class="post-meta">Sean Jewell · Jan 13, 2020 </h3>
  </header>

  
  <div class="summary">Date: 2020-01-13 Time: 15:30-16:30 Location: BURNSIDE 1205 Abstract: This talk is motivated by statistical challenges that arise in the analysis of calcium imaging data, a new technology in neuroscience that makes it possible to record from huge numbers of neurons at single-neuron resolution. In the first part of this talk, I will consider the problem of estimating a neuron&rsquo;s spike times from calcium imaging data. A simple and natural model suggests a non-convex optimization problem for this task.</div>

  
  <footer>
    <a href="/post/2020winter/2020-01-13/" title="Estimation and inference for changepoint models">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-11-29T00:00:00JST">Nov 29, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-11-29/">Convergence rates for diffusions-based sampling and optimization methods</a></h2>
    <h3 class="post-meta">Murat A. Erdogdu · Nov 29, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-11-29 Time: 15:30-16:30 Location: BURN 1205 Abstract: An Euler discretization of the Langevin diffusion is known to converge to the global minimizers of certain convex and non-convex optimization problems. We show that this property holds for any suitably smooth diffusion and that different diffusions are suitable for optimizing different classes of convex and non-convex functions. This allows us to design diffusions suitable for globally optimizing convex and non-convex functions not covered by the existing Langevin theory.</div>

  
  <footer>
    <a href="/post/2019fall/2019-11-29/" title="Convergence rates for diffusions-based sampling and optimization methods">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-11-15T00:00:00JST">Nov 15, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-11-15/"> Logarithmic divergence: from finance to optimal transport and information geometry</a></h2>
    <h3 class="post-meta">Ting-Kam Leonard Wong · Nov 15, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-11-15 Time: 15:30-16:30 Location: BURN 1205 Abstract: Divergences, such as the Kullback-Leibler divergence, are distance-like quantities which arise in many applications in probability, statistics and data science. We introduce a family of logarithmic divergences which is a non-linear extension of the celebrated Bregman divergence. It is defined for any exponentially concave function (a function whose exponential is concave). We motivate this divergence by mathematical finance and large deviations of Dirichlet process.</div>

  
  <footer>
    <a href="/post/2019fall/2019-11-15/" title=" Logarithmic divergence: from finance to optimal transport and information geometry">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-11-08T00:00:00JST">Nov 8, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-11-08/">Joint Robust Multiple Inference on Large Scale Multivariate Regression</a></h2>
    <h3 class="post-meta">Wen Zhou · Nov 8, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-11-08 Time: 15:30-16:30 Location: BURN 1205 Abstract: Large scale multivariate regression with many heavy-tailed responses arises in a wide range of areas from genomics, financial asset pricing, banking regulation, to psychology and social studies. Simultaneously testing a large number of general linear hypotheses, such as multiple contrasts, based on the large scale multivariate regression reveals a variety of associations between responses and regression or experimental factors. Traditional multiple testing methods often ignore the effect of heavy-tailedness in the data and impose joint normality assumption that is arguably stringent in applications.</div>

  
  <footer>
    <a href="/post/2019fall/2019-11-08/" title="Joint Robust Multiple Inference on Large Scale Multivariate Regression">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-10-25T00:00:00JST">Oct 25, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-10-25/">Learning Connectivity Networks from High-Dimensional Point Processes</a></h2>
    <h3 class="post-meta">Ali Shojaie · Oct 25, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-10-25 Time: 15:30-16:30 Location: BURN 1205 Abstract: High-dimensional point processes have become ubiquitous in many scientific fields. For instance, neuroscientists use calcium florescent imaging to monitor the firing of thousands of neurons in live animals. In this talk, I will discuss new methodological, computational and theoretical developments for learning neuronal connectivity networks from high-dimensional point processes. Time permitting, I will also discuss a new approach for handling non-stationarity in high-dimensional time series.</div>

  
  <footer>
    <a href="/post/2019fall/2019-10-25/" title="Learning Connectivity Networks from High-Dimensional Point Processes">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-10-18T00:00:00JST">Oct 18, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-10-18/">Univariate and multivariate extremes of extendible random vectors</a></h2>
    <h3 class="post-meta">Klaus Herrmann · Oct 18, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-10-18 Time: 15:30-16:30 Location: BURN 1205 Abstract: In its most common form extreme value theory is concerned with the limiting distribution of location-scale transformed block-maxima $M_n = \max(X_1,\dots,X_n)$ of a sequence of identically distributed random variables $(X_i)$, $i\geq 1$. In case the members of the sequence $(X_i)$ are independent, the weak limiting behaviour of $M_n$ is adequately described by the classical Fisher-Tippett-Gnedenko theorem. In this presentation we are interested in the case of dependent random variables $(X_i)$ while retaining a common marginal distribution function $F$ for all $X_i$, $i\in\mathbb{N}$.</div>

  
  <footer>
    <a href="/post/2019fall/2019-10-18/" title="Univariate and multivariate extremes of extendible random vectors">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-10-11T00:00:00JST">Oct 11, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-10-11/">Repulsiveness for integration (not my social program)</a></h2>
    <h3 class="post-meta">Jean-Francois Coeurjolly  · Oct 11, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-10-11 Time: 15:30-16:30 Location: BURN 1205 Abstract: Integral estimation in any dimension is an extensive topic, largely treated in the literature, with a broad range of applications. Monte-Carlo type methods arise naturally when one looks forward to quantifying/controlling the error. Many methods have already been developped: MCMC, Poisson disk sampling, QMC (and randomized versions), Bayesian quadrature, etc. In this talk, I&rsquo;ll consider a different approach which consists in defining the quadrature nodes as the realization of a spatial point process.</div>

  
  <footer>
    <a href="/post/2019fall/2019-10-11/" title="Repulsiveness for integration (not my social program)">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-09-27T00:00:00JST">Sep 27, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-09-27/">Regression Models for Spatial Images</a></h2>
    <h3 class="post-meta">Murray Clayton · Sep 27, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-09-27 Time: 15:30-16:30 Location: McIntyre Medical Building, Room 521 Abstract: This work is motivated by a problem in describing forest nitrogen cycling, and a consequent goal of constructing regression models for spatial images. Specifically, I present a functional concurrent linear model (FLCM) with varying coefficients for two-dimensional spatial images. To address overparameterization issues, the parameter surfaces in this model are transformed into the wavelet domain and then sparse representations are found using two different methods: LASSO and Bayesian variable selection.</div>

  
  <footer>
    <a href="/post/2019fall/2019-09-27/" title="Regression Models for Spatial Images">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-09-20T00:00:00JST">Sep 20, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-09-20/">Deep Representation Learning using Discrete Domain Symmetries</a></h2>
    <h3 class="post-meta">Siamak Ravanbakhsh · Sep 20, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-09-20 Time: 15:30-16:30 Location: BURN 1205 Abstract: Symmetry has played a significant role in modern physics, in part by constraining the physical laws. I will discuss how it could play a fundamental role in AI by constraining the deep model design. In particular, I focus on discrete domain symmetries and through examples show how we can use this inductive bias as a principled means for constraining a feedforward layer and significantly improving its sample efficiency.</div>

  
  <footer>
    <a href="/post/2019fall/2019-09-20/" title="Deep Representation Learning using Discrete Domain Symmetries">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-09-13T00:00:00JST">Sep 13, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2019fall/2019-09-13/">Integrative computational approach in genomics and healthcare</a></h2>
    <h3 class="post-meta">Yue Li · Sep 13, 2019 </h3>
  </header>

  
  <div class="summary">Date: 2019-09-13 Time: 15:30-16:30 Location: BURN 1205 Abstract: In the current era of multi-omics and digital healthcare, we are facing unprecedented amount of data with tremendous opportunities to link molecular phenotypes with complex diseases. However, the lack of integrative statistical method hinders system-level interrogation of relevant disease-related pathways and the genetic implication in various healthcare outcome.
In this talk, I will present our current progress in mining genomics and healthcare data.</div>

  
  <footer>
    <a href="/post/2019fall/2019-09-13/" title="Integrative computational approach in genomics and healthcare">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/categories/mcgill-statistics-seminar/">Previous</a></li>
    

    
    <li><a href="/categories/mcgill-statistics-seminar/page/3/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="/post/2020fall/2020-10-16/" class="list-group-item">Jeffrey Rosenthal · Oct 16, 2020</a>
      
      <a href="/post/2020fall/2020-10-09/" class="list-group-item">Masoud Asgharian, Damoon Robatian and Zedian Xiao · Oct 9, 2020</a>
      
      <a href="/post/2020fall/2020-10-02/" class="list-group-item">Paul McNicholas · Oct 2, 2020</a>
      
      <a href="/post/2020fall/2020-09-25/" class="list-group-item">Yingying Fan · Sep 25, 2020</a>
      
      <a href="/post/2020fall/2020-09-18/" class="list-group-item">Simon Mak · Sep 18, 2020</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="/categories/mcgill-statistics-seminar" class="list-group-item">mcgill-statistics-seminar</a>
      
      <a href="/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc-prize-address</a>
      
      <a href="/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="/tags/2020-winter" class="list-group-item">2020-winter</a>
      
      <a href="/tags/2020-fall" class="list-group-item">2020-fall</a>
      
      <a href="/tags/2019-winter" class="list-group-item">2019-winter</a>
      
      <a href="/tags/2019-fall" class="list-group-item">2019-fall</a>
      
      <a href="/tags/2018-winter" class="list-group-item">2018-winter</a>
      
      <a href="/tags/2018-fall" class="list-group-item">2018-fall</a>
      
      <a href="/tags/2017-winter" class="list-group-item">2017-winter</a>
      
      <a href="/tags/2017-fall" class="list-group-item">2017-fall</a>
      
      <a href="/tags/2016-winter" class="list-group-item">2016-winter</a>
      
      <a href="/tags/2016-fall" class="list-group-item">2016-fall</a>
      
      <a href="/tags/2015-winter" class="list-group-item">2015-winter</a>
      
      <a href="/tags/2015-fall" class="list-group-item">2015-fall</a>
      
      <a href="/tags/2014-winter" class="list-group-item">2014-winter</a>
      
      <a href="/tags/2014-fall" class="list-group-item">2014-fall</a>
      
      <a href="/tags/2013-winter" class="list-group-item">2013-winter</a>
      
      <a href="/tags/2013-fall" class="list-group-item">2013-fall</a>
      
      <a href="/tags/2012-winter" class="list-group-item">2012-winter</a>
      
      <a href="/tags/2012-fall" class="list-group-item">2012-fall</a>
      
      <a href="/tags/2011-fall" class="list-group-item">2011-fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

