<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Crm Colloquium on McGill Statistics Seminars</title>
    <link>/categories/crm-colloquium/</link>
    <description>Recent content in Crm Colloquium on McGill Statistics Seminars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/crm-colloquium/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The Law of Large Populations: The return of the long-ignored N and how it can affect our 2020 vision</title>
      <link>/post/2018winter/2018-02-16/</link>
      <pubDate>Fri, 16 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018winter/2018-02-16/</guid>
      <description>Date: 2018-02-16 Time: 15:30-16:30 Location: McGill University, OTTO MAASS 217 Abstract: For over a century now, we statisticians have successfully convinced ourselves and almost everyone else, that in statistical inference the size of the population N can be ignored, especially when it is large. Instead, we focused on the size of the sample, n, the key driving force for both the Law of Large Numbers and the Central Limit Theorem.</description>
    </item>
    
    <item>
      <title>150 years (and more) of data analysis in Canada</title>
      <link>/post/2017fall/2017-11-24/</link>
      <pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017fall/2017-11-24/</guid>
      <description>Date: 2017-11-24 Time: 15:30-16:30 Location: LEA 232 Abstract: As Canada celebrates its 150th anniversary, it may be good to reflect on the past and future of data analysis and statistics in this country. In this talk, I will review the Victorian Statistics Movement and its effect in Canada, data analysis by a Montréal physician in the 1850s, a controversy over data analysis in the 1850s and 60s centred in Montréal, John A.</description>
    </item>
    
    <item>
      <title>McNeil: Spectral backtests of forecast distributions with application to risk management | Jasiulis-Goldyn: Asymptotic properties and renewal theory for Kendall random walks</title>
      <link>/post/2017fall/2017-09-29/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017fall/2017-09-29/</guid>
      <description>Date: 2017-09-29 Time: 14:30-16:30 Location: BURN 1205 Abstract: McNeil: In this talk we study a class of backtests for forecast distributions in which the test statistic is a spectral transformation that weights exceedance events by a function of the modelled probability level. The choice of the kernel function makes explicit the user’s priorities for model performance. The class of spectral backtests includes tests of unconditional coverage and tests of conditional coverage.</description>
    </item>
    
    <item>
      <title>Instrumental Variable Regression with Survival Outcomes</title>
      <link>/post/2017winter/2017-04-06/</link>
      <pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017winter/2017-04-06/</guid>
      <description>Date: 2017-04-06 Time: 15:30-16:30 Location: Universite Laval, Pavillon Vachon, Salle 3840 Abstract: Instrumental variable (IV) methods are popular in non-experimental studies to estimate the causal effects of medical interventions or exposures. These approaches allow for the consistent estimation of such effects even if important confounding factors are unobserved. Despite the increasing use of these methods, there have been few extensions of IV methods to censored data regression problems. We discuss challenges in applying IV structural equational modelling techniques to the proportional hazards model and suggest alternative modelling frameworks.</description>
    </item>
    
    <item>
      <title>Inference in dynamical systems</title>
      <link>/post/2017winter/2017-03-17/</link>
      <pubDate>Fri, 17 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017winter/2017-03-17/</guid>
      <description>Date: 2017-03-17 Time: 15:30-16:30 Location: BURN 1205 Abstract: We consider the asymptotic consistency of maximum likelihood parameter estimation for dynamical systems observed with noise. Under suitable conditions on the dynamical systems and the observations, we show that maximum likelihood parameter estimation is consistent. Furthermore, we show how some well-studied properties of dynamical systems imply the general statistical properties related to maximum likelihood estimation. Finally, we exhibit classical families of dynamical systems for which maximum likelihood estimation is consistent.</description>
    </item>
    
    <item>
      <title>High-dimensional changepoint estimation via sparse projection</title>
      <link>/post/2016fall/2016-12-01/</link>
      <pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-12-01/</guid>
      <description>Date: 2016-12-01 Time: 15:30-16:30 Location: BURN 708 Abstract: Changepoints are a very common feature of Big Data that arrive in the form of a data stream. We study high-dimensional time series in which, at certain time points, the mean structure changes in a sparse subset of the coordinates. The challenge is to borrow strength across the coordinates in order to detect smaller changes than could be observed in any individual component series.</description>
    </item>
    
    <item>
      <title>Efficient tests of covariate effects in two-phase failure time studies</title>
      <link>/post/2016fall/2016-10-28/</link>
      <pubDate>Fri, 28 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-10-28/</guid>
      <description>Date: 2016-10-28 Time: 15:30-16:30 Location: BURN 1205 Abstract: Two-phase studies are frequently used when observations on certain variables are expensive or difficult to obtain. One such situation is when a cohort exists for which certain variables have been measured (phase 1 data); then, a sub-sample of individuals is selected, and additional data are collected on them (phase 2). Efficiency for tests and estimators can be increased by basing the selection of phase 2 individuals on data collected at phase 1.</description>
    </item>
    
    <item>
      <title>Statistical inference for fractional diffusion processes</title>
      <link>/post/2016fall/2016-09-16/</link>
      <pubDate>Fri, 16 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-09-16/</guid>
      <description>Date: 2016-09-16 Time: 16:00-17:00 Location: LB-921.04, Library Building, Concordia Univ. Abstract: There are some time series which exhibit long-range dependence as noticed by Hurst in his investigations of river water levels along Nile river. Long-range dependence is connected with the concept of self-similarity in that increments of a self-similar process with stationary increments exhibit long-range dependence under some conditions. Fractional Brownian motion is an example of such a process. We discuss statistical inference for stochastic processes modeled by stochastic differential equations driven by a fractional Brownian motion.</description>
    </item>
    
    <item>
      <title>Ridges and valleys in the high excursion sets of Gaussian random fields</title>
      <link>/post/2016winter/2016-03-10/</link>
      <pubDate>Thu, 10 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016winter/2016-03-10/</guid>
      <description>Date: 2016-03-10 Time: 15:30-16:30 Location: MAASS 217, McGill Abstract: It is well known that normal random variables do not like taking large values. Therefore, a continuous Gaussian random field on a compact set does not like exceeding a large level. If it does exceed a large level at some point, it tends to go back below the level a short distance away from that point. One, therefore, does not expect the excursion set above a high for such a field to possess any interesting structure.</description>
    </item>
    
    <item>
      <title>Causal discovery with confidence using invariance principles</title>
      <link>/post/2015fall/2015-12-10/</link>
      <pubDate>Thu, 10 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015fall/2015-12-10/</guid>
      <description>Date: 2015-12-10 Time: 15:30-16:30 Location: UdeM, Pav. Roger-Gaudry, salle S-116 Abstract: What is interesting about causal inference? One of the most compelling aspects is that any prediction under a causal model is valid in environments that are possibly very different to the environment used for inference. For example, variables can be actively changed and predictions will still be valid and useful. This invariance is very useful but still leaves open the difficult question of inference.</description>
    </item>
    
    <item>
      <title>Inference regarding within-family association in disease onset times under biased sampling schemes</title>
      <link>/post/2015fall/2015-11-26/</link>
      <pubDate>Thu, 26 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015fall/2015-11-26/</guid>
      <description>Date: 2015-11-26 Time: 15:30-16:30 Location: BURN 306 Abstract: In preliminary studies of the genetic basis for chronic conditions, interest routinely lies in the within-family dependence in disease status. When probands are selected from disease registries and their respective families are recruited, a variety of ascertainment bias-corrected methods of inference are available which are typically based on models for correlated binary data. This approach ignores the age that family members are at the time of assessment.</description>
    </item>
    
    <item>
      <title>A knockoff filter for controlling the false discovery rate</title>
      <link>/post/2015fall/2015-10-30/</link>
      <pubDate>Fri, 30 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015fall/2015-10-30/</guid>
      <description>Date: 2015-10-30 Time: 16:00-17:00 Location: Salle 1360, Pavillon André-Aisenstadt, Université de Montréa Abstract: The big data era has created a new scientific paradigm: collect data first, ask questions later. Imagine that we observe a response variable together with a large number of potential explanatory variables, and would like to be able to discover which variables are truly associated with the response. At the same time, we need to know that the false discovery rate (FDR) - the expected fraction of false discoveries among all discoveries - is not too high, in order to assure the scientist that most of the discoveries are indeed true and replicable.</description>
    </item>
    
    <item>
      <title>A statistical view of some recent climate controversies</title>
      <link>/post/2015winter/2015-05-07/</link>
      <pubDate>Thu, 07 May 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015winter/2015-05-07/</guid>
      <description>Date: 2015-05-07 Time: 15:30-16:30 Location: Université de Sherbrooke Abstract: This talk looks at some recent climate controversies from a statistical standpoint. The issues are motivated via changepoints and their detection. Changepoints are ubiquitous features in climatic time series, occurring whenever stations relocate or gauges are changed. Ignoring changepoints can produce spurious trend conclusions. Changepoint tests involving cumulative sums, likelihood ratio, and maximums of F-statistics are introduced; the asymptotic distributions of these statistics are quantified under the changepoint-free null hypothesis.</description>
    </item>
    
    <item>
      <title>Functional data analysis and related topics</title>
      <link>/post/2015winter/2015-01-15/</link>
      <pubDate>Thu, 15 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015winter/2015-01-15/</guid>
      <description>Date: 2015-01-15 Time: 16:00-17:00 Location: CRM 1360 (U. de Montréal) Abstract: Functional data analysis (FDA) has received substantial attention, with applications arising from various disciplines, such as engineering, public health, finance etc. In general, the FDA approaches focus on nonparametric underlying models that assume the data are observed from realizations of stochastic processes satisfying some regularity conditions, e.g., smoothness constraints. The estimation and inference procedures usually do not depend on merely a finite number of parameters, which contrasts with parametric models, and exploit techniques, such as smoothing methods and dimension reduction, that allow data to speak for themselves.</description>
    </item>
    
    <item>
      <title>High-dimensional phenomena in mathematical statistics and convex analysis</title>
      <link>/post/2014fall/2014-11-20/</link>
      <pubDate>Thu, 20 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014fall/2014-11-20/</guid>
      <description>Date: 2014-11-20 Time: 16:00-17:00 Location: CRM 1360 (U. de Montréal) Abstract: Statistical models in which the ambient dimension is of the same order or larger than the sample size arise frequently in different areas of science and engineering. Although high-dimensional models of this type date back to the work of Kolmogorov, they have been the subject of intensive study over the past decade, and have interesting connections to many branches of mathematics (including concentration of measure, random matrix theory, convex geometry, and information theory).</description>
    </item>
    
    <item>
      <title>Adaptive piecewise polynomial estimation via trend filtering</title>
      <link>/post/2014winter/2014-04-11/</link>
      <pubDate>Fri, 11 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014winter/2014-04-11/</guid>
      <description>Date: 2014-04-11 Time: 15:30-16:30 Location: Salle KPMG, 1er étage HEC Montréal Abstract: We will discuss trend filtering, a recently proposed tool of Kim et al. (2009) for nonparametric regression. The trend filtering estimate is defined as the minimizer of a penalized least squares criterion, in which the penalty term sums the absolute kth order discrete derivatives over the input points. Perhaps not surprisingly, trend filtering estimates appear to have the structure of kth degree spline functions, with adaptively chosen knot points (we say “appear” here as trend filtering estimates are not really functions over continuous domains, and are only defined over the discrete set of inputs).</description>
    </item>
    
    <item>
      <title>Insurance company operations and dependence modeling</title>
      <link>/post/2014winter/2014-03-21/</link>
      <pubDate>Fri, 21 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014winter/2014-03-21/</guid>
      <description>Date: 2014-03-21 Time: 15:30-16:30 Location: BURN 107 Abstract: Actuaries and other analysts have long had the responsibility in insurance company operations for various financial functions including (i) ratemaking, the process of setting premiums, (ii) loss reserving, the process of predicting obligations that arise from policies, and (iii) claims management, including fraud detection. With the advent of modern computing capabilities and detailed and novel data sources, new opportunities to make an impact on insurance company operations are extensive.</description>
    </item>
    
    <item>
      <title>ABC as the new empirical Bayes approach?</title>
      <link>/post/2014winter/2014-02-28/</link>
      <pubDate>Fri, 28 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014winter/2014-02-28/</guid>
      <description>Date: 2014-02-28 Time: 13:30-14:30 Location: UdM, Pav. Roger-Gaudry, Salle S-116 Abstract: Approximate Bayesian computation (ABC) has now become an essential tool for the analysis of complex stochastic models when the likelihood function is unavailable. The approximation is seen as a nuisance from a computational statistic point of view but we argue here it is also a blessing from an inferential perspective. We illustrate this paradoxical stand in the case of dynamic models and population genetics models.</description>
    </item>
    
    <item>
      <title>Calibration of computer experiments with large data structures</title>
      <link>/post/2014winter/2014-01-24/</link>
      <pubDate>Fri, 24 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014winter/2014-01-24/</guid>
      <description>Date: 2014-01-24 Time: 15:30-16:30 Location: Salle 1355, pavillon André-Aisenstadt (CRM) Abstract: Statistical model calibration of computer models is commonly done in a wide variety of scientific endeavours. In the end, this exercise amounts to solving an inverse problem and a form of regression. Gaussian process model are very convenient in this setting as non-parametric regression estimators and provide sensible inference properties. However, when the data structures are large, fitting the model becomes difficult.</description>
    </item>
    
    <item>
      <title>Great probabilists publish posthumously</title>
      <link>/post/2013fall/2013-12-06/</link>
      <pubDate>Fri, 06 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013fall/2013-12-06/</guid>
      <description>Date: 2013-12-06 Time: 15:30-16:30 Location: UQAM Salle SH-3420 Abstract: Jacob Bernoulli died in 1705. His great book Ars Conjectandi was published in 1713, 300 years ago. Thomas Bayes died in 1761. His great paper was read to the Royal Society of London in December 1763, 250 years ago, and published in 1764. These anniversaries are noted by discussing new evidence regarding the circumstances of publication, which in turn can lead to a better understanding of the works themselves.</description>
    </item>
    
    <item>
      <title>Signal detection in high dimension: Testing sphericity against spiked alternatives</title>
      <link>/post/2013fall/2013-11-29/</link>
      <pubDate>Fri, 29 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013fall/2013-11-29/</guid>
      <description>Date: 2013-11-29 Time: 15:30-16:30 Location: Concordia MB-2.270 Abstract: We consider the problem of testing the null hypothesis of sphericity for a high-dimensional covariance matrix against the alternative of a finite (unspecified) number of symmetry-breaking directions (multispiked alternatives) from the point of view of the asymptotic theory of statistical experiments. The region lying below the so-called phase transition or impossibility threshold is shown to be a contiguity region. Simple analytical expressions are derived for the asymptotic power envelope and the asymptotic powers of existing tests.</description>
    </item>
    
    <item>
      <title>XY - Basketball meets Big Data</title>
      <link>/post/2013fall/2013-10-25/</link>
      <pubDate>Fri, 25 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013fall/2013-10-25/</guid>
      <description>Date: 2013-10-25 Time: 15:30-16:30 Location: HEC Montréal Salle CIBC 1er étage Abstract: In this talk, I will explore the state of the art in the analysis and modeling of player tracking data in the NBA. In the past, player tracking data has been used primarily for visualization, such as understanding the spatial distribution of a player’s shooting characteristics, or to extract summary statistics, such as the distance traveled by a player in a given game.</description>
    </item>
    
    <item>
      <title>Measurement error and variable selection in parametric and nonparametric models</title>
      <link>/post/2013fall/2013-09-27/</link>
      <pubDate>Fri, 27 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013fall/2013-09-27/</guid>
      <description>Date: 2013-09-27 Time: 15:30-16:30 Location: RPHYS 114 Abstract: This talk will start with a discussion of the relationships between LASSO estimation, ridge regression, and attenuation due to measurement error as motivation for, and introduction to, a new generalizable approach to variable selection in parametric and nonparametric regression and discriminant analysis. The approach transcends the boundaries of parametric/nonparametric models. It will first be described in the familiar context of linear regression where its relationship to the LASSO will be described in detail.</description>
    </item>
    
    <item>
      <title>Arup Bose: Consistency of large dimensional sample covariance matrix under weak dependence</title>
      <link>/post/2013winter/2013-04-12/</link>
      <pubDate>Fri, 12 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013winter/2013-04-12/</guid>
      <description>Date: 2013-04-12 Time: 14:30-15:30 Location: Concordia Abstract: Estimation of large dimensional covariance matrix has been of interest recently. One model assumes that there are $p$ dimensional independent identically distributed Gaussian observations $X_1, \ldots , X_n$ with dispersion matrix $\Sigma_p$ and $p$ grows much faster than $n$. Appropriate convergence rate results have been established in the literature for tapered and banded estimators of $\Sigma_p$ which are based on the sample variance covariance matrix of $n$ observations.</description>
    </item>
    
    <item>
      <title>Hélène Massam: The hyper Dirichlet revisited: a characterization</title>
      <link>/post/2013winter/2013-03-22/</link>
      <pubDate>Fri, 22 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013winter/2013-03-22/</guid>
      <description>Date: 2013-03-22 Time: 14:30-15:30 Location: BURN 107 Abstract: We give a characterization of the hyper Dirichlet distribution hyper Markov with respect to a decomposable graph $G$ (or equivalently a moral directed acyclic graph). For $X=(X_1,\ldots,X_d)$ following the hyper Dirichlet distribution, our characterization is through the so-called &amp;ldquo;local and global independence properties&amp;rdquo; for a carefully designed family of orders of the variables $X_1,\ldots,X_d$.
The hyper Dirichlet for general directed acyclic graphs was derived from a characterization of the Dirichlet distribution given by Geiger and Heckerman (1997).</description>
    </item>
    
    <item>
      <title>Victor Chernozhukov: Inference on treatment effects after selection amongst high-dimensional controls</title>
      <link>/post/2013winter/2013-01-18/</link>
      <pubDate>Fri, 18 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013winter/2013-01-18/</guid>
      <description>Date: 2013-01-18 Time: 14:30-15:30 Location: BURN 306 Abstract: We propose robust methods for inference on the effect of a treatment variable on a scalar outcome in the presence of very many controls. Our setting is a partially linear model with possibly non-Gaussian and heteroscedastic disturbances. Our analysis allows the number of controls to be much larger than the sample size. To make informative inference feasible, we require the model to be approximately sparse; that is, we require that the effect of confounding factors can be controlled for up to a small approximation error by conditioning on a relatively small number of controls whose identities are unknown.</description>
    </item>
    
    <item>
      <title>What percentage of children in the U.S. are eating a healthy diet? A statistical approach</title>
      <link>/post/2012fall/2012-12-14/</link>
      <pubDate>Fri, 14 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-12-14/</guid>
      <description>Date: 2012-12-14 Time: 14:30-15:30 Location: Concordia, Room LB 921-04 Abstract: In the United States the preferred method of obtaining dietary intake data is the 24-hour dietary recall, yet the measure of most interest is usual or long-term average daily intake, which is impossible to measure. Thus, usual dietary intake is assessed with considerable measurement error. Also, diet represents numerous foods, nutrients and other components, each of which have distinctive attributes.</description>
    </item>
    
    <item>
      <title>A nonparametric Bayesian model for local clustering</title>
      <link>/post/2012fall/2012-11-23/</link>
      <pubDate>Fri, 23 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-11-23/</guid>
      <description>Date: 2012-11-23 Time: 14:30-15:30 Location: BURN 107 Abstract: We propose a nonparametric Bayesian local clustering (NoB-LoC) approach for heterogeneous data. Using genomics data as an example, the NoB-LoC clusters genes into gene sets and simultaneously creates multiple partitions of samples, one for each gene set. In other words, the sample partitions are nested within the gene sets. Inference is guided by a joint probability model on all random elements. Biologically, the model formalizes the notion that biological samples cluster differently with respect to different genetic processes, and that each process is related to only a small subset of genes.</description>
    </item>
    
    <item>
      <title>Observational studies in healthcare: are they any good?</title>
      <link>/post/2012fall/2012-10-19/</link>
      <pubDate>Fri, 19 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-10-19/</guid>
      <description>Date: 2012-10-19 Time: 14:30-15:30 Location: UdeM Abstract: Observational healthcare data, such as administrative claims and electronic health records, play an increasingly prominent role in healthcare. Pharmacoepidemiologic studies in particular routinely estimate temporal associations between medical product exposure and subsequent health outcomes of interest, and such studies influence prescribing patterns and healthcare policy more generally. Some authors have questioned the reliability and accuracy of such studies, but few previous efforts have attempted to measure their performance.</description>
    </item>
    
    <item>
      <title>Regularized semiparametric functional linear regression</title>
      <link>/post/2012fall/2012-09-21/</link>
      <pubDate>Fri, 21 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-09-21/</guid>
      <description>Date: 2012-09-21 Time: 14:30-15:30 Location: McGill, Burnside Hall 1214 Abstract: In many scientific experiments we need to face analysis with functional data, where the observations are sampled from random process, together with a potentially large number of non-functional covariates. The complex nature of functional data makes it difficult to directly apply existing methods to model selection and estimation. We propose and study a new class of penalized semiparametric functional linear regression to characterize the regression relation between a scalar response and multiple covariates, including both functional covariates and scalar covariates.</description>
    </item>
    
    <item>
      <title>Li: High-dimensional feature selection using hierarchical Bayesian logistic regression with heavy-tailed priors | Rao: Best predictive estimation for linear mixed models with applications to small area estimation</title>
      <link>/post/2012winter/2012-04-13/</link>
      <pubDate>Fri, 13 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012winter/2012-04-13/</guid>
      <description>Date: 2012-04-13 Time: 14:00-16:30 Location: MAASS 217 Abstract: Li: The problem of selecting the most useful features from a great many (eg, thousands) of candidates arises in many areas of modern sciences. An interesting problem from genomic research is that, from thousands of genes that are active (expressed) in certain tissue cells, we want to ﬁnd the genes that can be used to separate tissues of diﬀerent classes (eg. cancer and normal).</description>
    </item>
    
    <item>
      <title>Using tests of homoscedasticity to test missing completely at random | Hugh Chipman: Sequential optimization of a computer model and other Active Learning problems</title>
      <link>/post/2012winter/2012-03-09/</link>
      <pubDate>Fri, 09 Mar 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012winter/2012-03-09/</guid>
      <description>Date: 2012-03-09 Time: 14:00-16:30 Location: UQAM, 201 ave. du Président-Kennedy, salle 5115 Abstract: Li: The problem of selecting the most useful features from a great many (eg, thousands) of candidates arises in many areas of modern sciences. An interesting problem from genomic research is that, from thousands of genes that are active (expressed) in certain tissue cells, we want to ﬁnd the genes that can be used to separate tissues of diﬀerent classes (eg.</description>
    </item>
    
    <item>
      <title>Stute: Principal component analysis of the Poisson Process | Blath: Longterm properties of the symbiotic branching model</title>
      <link>/post/2012winter/2012-02-10/</link>
      <pubDate>Fri, 10 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012winter/2012-02-10/</guid>
      <description>Date: 2012-02-10 Time: 14:00-16:30 Location: Concordia Abstract: Stute: The Poisson Process constitutes a well-known model for describing random events over time. It has many applications in marketing research, insurance mathematics and finance. Though it has been studied for decades not much is known how to check (in a non-asymptotic way) the validity of the Poisson Process. In this talk we present the principal component decomposition of the Poisson Process which enables us to derive finite sample properties of associated goodness-of-fit tests.</description>
    </item>
    
    <item>
      <title>Bayesian approaches to evidence synthesis in clinical practice guideline development</title>
      <link>/post/2012winter/2012-01-13/</link>
      <pubDate>Fri, 13 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012winter/2012-01-13/</guid>
      <description>Date: 2012-01-13 Time: 15:30-16:30 Location: Concordia, Library Building LB-921.04 Abstract: The American College of Cardiology Foundation (ACCF) and the American Heart Association (AHA) have jointly engaged in the production of guideline in the area of cardiovascular disease since 1980. The developed guidelines are intended to assist health care providers in clinical decision making by describing a range of generally acceptable approaches for the diagnosis, management, or prevention of specific diseases or conditions.</description>
    </item>
    
    <item>
      <title>Detecting evolution in experimental ecology: Diagnostics for missing state variables</title>
      <link>/post/2011fall/2011-12-09/</link>
      <pubDate>Fri, 09 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>/post/2011fall/2011-12-09/</guid>
      <description>Date: 2011-12-09 Time: 15:30-16:30 Location: UQAM Salle 5115 Abstract: This talk considers goodness of fit diagnostics for time-series data from processes approximately modeled by systems of nonlinear ordinary differential equations. In particular, we seek to determine three nested causes of lack of fit: (i) unmodeled stochastic forcing, (ii) mis-specified functional forms and (iii) mis-specified state variables. Testing lack of fit in differential equations is challenging since the model is expressed in terms of rates of change of the measured variables.</description>
    </item>
    
    <item>
      <title>Guérin: An ergodic variant of the telegraph process for a toy model of bacterial chemotaxis | Staicu: Skewed functional processes and their applications</title>
      <link>/post/2011fall/2011-11-11/</link>
      <pubDate>Fri, 11 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>/post/2011fall/2011-11-11/</guid>
      <description>Date: 2011-11-11 Time: 14:00-16:30 Location: UdeM Abstract: Guérin: I will study the long time behavior of a variant of the classic telegraph process, with non-constant jump rates that induce a drift towards the origin. This process can be seen as a toy model for velocity-jump processes recently proposed as mathematical models of bacterial chemotaxis. I will give its invariant law and construct an explicit coupling for velocity and position, providing exponential ergodicity with moreover a quantitative control of the total variation distance to equilibrium at each time instant.</description>
    </item>
    
    <item>
      <title>Dupuis: Modeling non-stationary extremes: The case of heat waves | Davis: Estimating extremal dependence in time series via the extremogram</title>
      <link>/post/2011fall/2011-10-14/</link>
      <pubDate>Fri, 14 Oct 2011 00:00:00 +0000</pubDate>
      
      <guid>/post/2011fall/2011-10-14/</guid>
      <description>Date: 2011-10-14 Time: 14:00-16:30 Location: TROTTIER 1080 Abstract: Dupuis: Environmental processes are often non-stationary since climate patterns cause systematic seasonal effects and long-term climate changes cause trends. The usual limit models are not applicable for non-stationary processes, but models from standard extreme value theory can be used along with statistical modeling to provide useful inference. Traditional approaches include letting model parameters be a function of covariates or using time-varying thresholds.</description>
    </item>
    
    <item>
      <title>Susko: Properties of Bayesian posteriors and bootstrap support in phylogenetic inference | Labbe: An integrated hierarchical Bayesian model for multivariate eQTL genetic mapping</title>
      <link>/post/2011fall/2011-09-09/</link>
      <pubDate>Fri, 09 Sep 2011 00:00:00 +0000</pubDate>
      
      <guid>/post/2011fall/2011-09-09/</guid>
      <description>Date: 2011-09-09 Time: 14:00-16:30 Location: UdeM, Pav. André-Aisenstadt, SALLE 1360 Abstract: Susko: The data generated by large scale sequencing projects is complex, high-dimensional, multivariate discrete data. In studies of evolutionary biology, the parameter space of evolutionary trees is an unusual additional complication from a statistical perspective. In this talk I will briefly introduce the general approaches to utilizing sequence data in phylogenetic inference. A particular issue of interest in phylogenetic inference is assessments of uncertainty about the true tree or structures that might be present in it.</description>
    </item>
    
  </channel>
</rss>