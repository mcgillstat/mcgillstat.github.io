<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.136.5">

/categories/crm-colloquium/index.xml

<link rel="canonical" href="https://mcgillstat.github.io/categories/crm-colloquium/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>CRM-Colloquium - McGill Statistics Seminars</title>
    
    <link href="https://mcgillstat.github.io/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://mcgillstat.github.io/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>CRM-Colloquium</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-09-11T00:00:00JST">Sep 11, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020fall/2020-09-11/">Machine Learning for Causal Inference</a></h2>
    <h3 class="post-meta">Stefan Wager · Sep 11, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-09-11">Date: 2020-09-11</h4>
<h4 id="time-1600-1700">Time: 16:00-17:00</h4>
<h4 id="zoom-linkhttpsumontrealzoomusj96525367383pwddzburjbvc2fwtgpyruh4aurbz0rvqt09"><a href="https://umontreal.zoom.us/j/96525367383?pwd=dzBURjBvc2FWTGpyRUh4aURBZ0RvQT09">Zoom Link</a></h4>
<h4 id="meeting-id-965-2536-7383">Meeting ID: 965 2536 7383</h4>
<h4 id="passcode-421254">Passcode: 421254</h4>
<h2 id="abstract">Abstract:</h2>
<p>Given advances in machine learning over the past decades, it is now possible to accurately solve difficult non-parametric prediction problems in a way that is routine and reproducible. In this talk, I’ll discuss how machine learning tools can be rigorously integrated into observational study analyses, and how they interact with classical statistical ideas around randomization, semiparametric modeling, double robustness, etc. I’ll also survey some recent advances in methods for treatment heterogeneity. When deployed carefully, machine learning enables us to develop causal estimators that reflect an observational study design more closely than basic linear regression based methods.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020fall/2020-09-11/" title="Machine Learning for Causal Inference">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-02-28T00:00:00JST">Feb 28, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020winter/2020-02-28/">Neyman-Pearson classification: parametrics and sample size requirement</a></h2>
    <h3 class="post-meta">Yang Feng · Feb 28, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-02-28">Date: 2020-02-28</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burnside-1104">Location: BURNSIDE 1104</h4>
<h2 id="abstract">Abstract:</h2>
<p>The Neyman-Pearson (NP) paradigm in binary classification seeks classifiers that achieve a minimal type II error while enforcing the prioritized type I error controlled under some user-specified level alpha. This paradigm serves naturally in applications such as severe disease diagnosis and spam detection, where people have clear priorities among the two error types. Recently, Tong, Feng and Li (2018) proposed a nonparametric umbrella algorithm that adapts all scoring-type classification methods (e.g., logistic regression, support vector machines, random forest) to respect the given type I error (i.e., conditional probability of classifying a class 0 observation as class 1 under the 0-1 coding) upper bound alpha with high probability, without specific distributional assumptions on the features and the responses. Universal the umbrella algorithm is, it demands an explicit minimum sample size requirement on class 0, which is often the more scarce class, such as in rare disease diagnosis applications. In this work, we employ the parametric linear discriminant analysis (LDA) model and propose a new parametric thresholding algorithm, which does not need the minimum sample size requirements on class 0 observations and thus is suitable for small sample applications such as rare disease diagnosis. Leveraging both the existing nonparametric and the newly proposed parametric thresholding rules, we propose four LDA-based NP classifiers, for both low- and high-dimensional settings. On the theoretical front, we prove NP oracle inequalities for one proposed classifier, where the rate for excess type II error benefits from the explicit parametric model assumption. Furthermore, as NP classifiers involve a sample splitting step of class 0 observations,  we construct a new adaptive sample splitting scheme that can be applied universally to NP classifiers, and this adaptive strategy reduces the type II error of these classifiers. The proposed NP classifiers are implemented in the R package nproc.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020winter/2020-02-28/" title="Neyman-Pearson classification: parametrics and sample size requirement">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-11-22T00:00:00JST">Nov 22, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2019fall/2019-11-22/">Formulation and solution of stochastic inverse problems for science and engineering models</a></h2>
    <h3 class="post-meta">Don Estep · Nov 22, 2019 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2019-11-22">Date: 2019-11-22</h4>
<h4 id="time-1600-1700">Time: 16:00-17:00</h4>
<h4 id="location-pavillon-kennedy-pk-5115-uqam">Location: Pavillon Kennedy, PK-5115, UQAM</h4>
<h2 id="abstract">Abstract:</h2>
<p>The stochastic inverse problem of determining probability
structures on input parameters for a physics model corresponding to a
given probability structure on the output of the model forms the core of
scientific inference and engineering design. We describe a formulation
and solution method for stochastic inverse problems that is based on
functional analysis, differential geometry, and probability/measure
theory. This approach yields a computationally tractable problem while
avoiding alterations of the model like regularization and ad hoc
assumptions about the probability structures. We present several
examples, including a high-dimensional application to determination of
parameter fields in storm surge models. We also describe work aimed at
defining a notion of condition for stochastic inverse problems and
tackling the related problem of designing sets of optimal observable
quantities.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2019fall/2019-11-22/" title="Formulation and solution of stochastic inverse problems for science and engineering models">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-11-01T00:00:00JST">Nov 1, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2019fall/2019-11-01/">General Bayesian Modeling</a></h2>
    <h3 class="post-meta">Stephen G. Walker · Nov 1, 2019 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2019-11-01">Date: 2019-11-01</h4>
<h4 id="time-1600-1700">Time: 16:00-17:00</h4>
<h4 id="location-burn-1104">Location: BURN 1104</h4>
<h2 id="abstract">Abstract:</h2>
<p>The work is motivated by the inflexibility of Bayesian modeling; in that only parameters of
probability models are required to be connected with data. The idea is to generalize this by
allowing arbitrary unknowns to be connected with data via loss functions. An updating process
is then detailed which can be viewed as arising in at least a couple of ways - one being purely
axiomatically driven.
The further exploration of replacing probability model based approaches to inference with loss
functions is ongoing. Joint work with Chris Holmes, Pier Giovanni Bissiri and Simon Lyddon.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2019fall/2019-11-01/" title="General Bayesian Modeling">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2019-02-01T00:00:00JST">Feb 1, 2019</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2019winter/2019-02-01/">Network models, sampling, and symmetry properties</a></h2>
    <h3 class="post-meta">Peter Orbanz · Feb 1, 2019 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2019-02-01">Date: 2019-02-01</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>A recent body of work, by myself and many others, aims to develop a statistical theory of network data for problems a single network is observed. Of the models studied in this area, graphon models are probably most widely known in statistics. I will explain the relationship between three aspects of this work: (1) Specific models, such as graphon models, graphex models, and edge-exchangeable graphs. (2) Sampling theory for networks, specifically in the case statisticians might refer to as an infinite-population limit. (3) Invariance properties, especially various forms of exchangeability. I will also present recent results that show how statistically relevant results (such as central limit theorems) can be derived from such invariance properties.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2019winter/2019-02-01/" title="Network models, sampling, and symmetry properties">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-02-16T00:00:00JST">Feb 16, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2018winter/2018-02-16/">The Law of Large Populations: The return of the long-ignored N and how it can affect our 2020 vision</a></h2>
    <h3 class="post-meta">Xiao-li Meng · Feb 16, 2018 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2018-02-16">Date: 2018-02-16</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-mcgill-university-otto-maass-217">Location: McGill University, OTTO MAASS 217</h4>
<h2 id="abstract">Abstract:</h2>
<p>For over a century now, we statisticians have successfully convinced ourselves and almost everyone else, that in statistical inference the size of the population N can be ignored, especially when it is large.  Instead, we focused on the size of the sample, n, the key driving force for both the Law of Large Numbers and the Central Limit Theorem. We were thus taught that the statistical error (standard error) goes down with n typically at the rate of 1/√n.   However, all these rely on the presumption that our data have perfect quality, in the sense of being equivalent to a probabilistic sample.  A largely overlooked statistical identity, a potential counterpart to the Euler identity in mathematics, reveals a Law of Large Populations (LLP), a law that we should be all afraid of. That is, once we lose control over data quality, the systematic error (bias) in the usual estimators, relative to the benchmarking standard error from simple random sampling, goes up with N at the rate of √N.   The coefficient in front of √N can be viewed as a data defect index, which is the simple Pearson correlation between the reporting/recording indicator and the value reported/recorded.  Because of the multiplier√N, a seemingly tiny correlation, say, 0.005, can have detrimental effect on the quality of inference.  Without understanding of this LLP,  “big data” can do more harm than good because of the drastically inflated precision assessment hence a gross overconfidence, setting us up to be caught by surprise when the reality unfolds, as we all experienced during the 2016 US presidential election. Data from Cooperative Congressional Election Study (CCES, conducted by Stephen Ansolabehere, Douglas River and others, and analyzed by Shiro Kuriwaki),   are used to estimate the data defect index for the 2016 US election, with the aim to gain a clearer vision for the 2020 election and beyond.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2018winter/2018-02-16/" title="The Law of Large Populations: The return of the long-ignored N and how it can affect our 2020 vision">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-11-24T00:00:00JST">Nov 24, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-11-24/">150 years (and more) of data analysis in Canada</a></h2>
    <h3 class="post-meta">David R. Bellhouse · Nov 24, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-11-24">Date: 2017-11-24</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-lea-232">Location: LEA 232</h4>
<h2 id="abstract">Abstract:</h2>
<p>As Canada celebrates its 150th anniversary, it may be good to reflect on the past and future of data analysis and statistics in this country. In this talk, I will review the Victorian Statistics Movement and its effect in Canada, data analysis by a Montréal physician in the 1850s, a controversy over data analysis in the 1850s and 60s centred in Montréal, John A. MacDonald’s use of statistics, the Canadian insurance industry and the use of statistics, the beginning of mathematical statistics in Canada, the Fisherian revolution, the influence of Fisher, Neyman and Pearson, the computer revolution, and the emergence of data science.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017fall/2017-11-24/" title="150 years (and more) of data analysis in Canada">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-09-29T00:00:00JST">Sep 29, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-09-29/">McNeil: Spectral backtests of forecast distributions with application to risk management | Jasiulis-Goldyn: Asymptotic properties and renewal theory for Kendall random walks</a></h2>
    <h3 class="post-meta">Alex McNeil and Barbara Jasiulis-Goldyn · Sep 29, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-09-29">Date: 2017-09-29</h4>
<h4 id="time-1430-1630">Time: 14:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p><em>McNeil</em>: In this talk we study a class of backtests for forecast distributions in which the test statistic is a spectral transformation that weights exceedance events by a function of the modelled probability level. The choice of the kernel function makes explicit the user’s priorities for model performance. The class of spectral backtests includes tests of unconditional coverage and tests of conditional coverage. We show how the class embeds a wide variety of backtests in the existing literature, and propose novel variants as well. We assess the size and power of the backtests in realistic sample sizes, and in particular demonstrate the tradeoff between power and specificity in validating quantile forecasts.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017fall/2017-09-29/" title="McNeil: Spectral backtests of forecast distributions with application to risk management | Jasiulis-Goldyn: Asymptotic properties and renewal theory for Kendall random walks">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-04-06T00:00:00JST">Apr 6, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017winter/2017-04-06/">Instrumental Variable Regression with Survival Outcomes</a></h2>
    <h3 class="post-meta">Jason Fine · Apr 6, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-04-06">Date: 2017-04-06</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-universite-laval-pavillon-vachon-salle-3840">Location: Universite Laval, Pavillon Vachon, Salle 3840</h4>
<h2 id="abstract">Abstract:</h2>
<p>Instrumental variable (IV) methods are popular in non-experimental studies to estimate the causal effects of medical interventions or exposures. These approaches allow for the consistent estimation of such effects even if important confounding factors are unobserved. Despite the increasing use of these methods, there have been few extensions of IV methods to censored data regression problems. We discuss challenges in applying IV structural equational modelling techniques to the proportional hazards model and suggest alternative modelling frameworks. We demonstrate the utility of the accelerated lifetime and additive hazards models for IV analyses with censored data. Assuming linear structural equation models for either the event time or the hazard function, we proposed closed-form, two-stage estimators for the causal effect in the structural models for the failure time outcomes. The asymptotic properties of the estimators are derived and the resulting inferences are shown to perform well in simulation studies and in an application to a data set on the effectiveness of a novel chemotherapeutic agent for colon cancer.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017winter/2017-04-06/" title="Instrumental Variable Regression with Survival Outcomes">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-03-17T00:00:00JST">Mar 17, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017winter/2017-03-17/">Inference in dynamical systems</a></h2>
    <h3 class="post-meta">Sayan Mukherjee · Mar 17, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-03-17">Date: 2017-03-17</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>We consider the asymptotic consistency of maximum likelihood parameter estimation for dynamical systems observed with noise. Under suitable conditions on the dynamical systems and the observations, we show that maximum likelihood parameter estimation is consistent. Furthermore, we show how some well-studied properties of dynamical systems imply the general statistical properties related to maximum likelihood estimation. Finally, we exhibit classical families of dynamical systems for which maximum likelihood estimation is consistent. Examples include shifts of finite type with Gibbs measures and Axiom A attractors with SRB measures. We also relate Bayesian inference to the thermodynamic formalism in tracking dynamical systems.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017winter/2017-03-17/" title="Inference in dynamical systems">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/categories/crm-colloquium/">Previous</a></li>
    

    
    <li><a href="/categories/crm-colloquium/page/3/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-winter/" class="list-group-item"> · Apr 4, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/" class="list-group-item"> · Apr 4, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar/" class="list-group-item"> · Apr 4, 2025</a>
      
      <a href="https://mcgillstat.github.io/post/2025winter/2025-04-04/" class="list-group-item">Konstantinos Spiliopoulos · Apr 4, 2025</a>
      
      <a href="https://mcgillstat.github.io/tags/" class="list-group-item"> · Apr 4, 2025</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar" class="list-group-item">mcgill statistics seminar</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc prize address</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-winter" class="list-group-item">2025 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-winter" class="list-group-item">2024 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-fall" class="list-group-item">2024 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-winter" class="list-group-item">2023 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-summer" class="list-group-item">2023 summer</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-fall" class="list-group-item">2023 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-winter" class="list-group-item">2022 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-fall" class="list-group-item">2022 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-winter" class="list-group-item">2021 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-fall" class="list-group-item">2021 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-winter" class="list-group-item">2020 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-fall" class="list-group-item">2020 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-winter" class="list-group-item">2019 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-fall" class="list-group-item">2019 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-winter" class="list-group-item">2018 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-fall" class="list-group-item">2018 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-winter" class="list-group-item">2017 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-fall" class="list-group-item">2017 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-winter" class="list-group-item">2016 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-fall" class="list-group-item">2016 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-winter" class="list-group-item">2015 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-fall" class="list-group-item">2015 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-winter" class="list-group-item">2014 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-fall" class="list-group-item">2014 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-winter" class="list-group-item">2013 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-fall" class="list-group-item">2013 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-winter" class="list-group-item">2012 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-fall" class="list-group-item">2012 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2011-fall" class="list-group-item">2011 fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

