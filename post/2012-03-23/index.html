<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.36" />



<link rel="canonical" href="/post/2012-03-23/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Jinchi Lv: Model selection principles in misspecified models - McGill Statistics Seminars</title>
    
<meta name="description" content="Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC.">

<meta property="og:title" content="Jinchi Lv: Model selection principles in misspecified models - McGill Statistics Seminars">
<meta property="og:type" content="article">
<meta property="og:url" content="/post/2012-03-23/">
<meta property="og:image" content="/images/default.png">
<meta property="og:site_name" content="McGill Statistics Seminars">
<meta property="og:description" content="Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC.">
<meta property="og:locale" content="ja_JP">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="McGill Statistics Seminars">
<meta name="twitter:url" content="/post/2012-03-23/">
<meta name="twitter:title" content="Jinchi Lv: Model selection principles in misspecified models - McGill Statistics Seminars">
<meta name="twitter:description" content="Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC.">
<meta name="twitter:image" content="/images/default.png">


<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "NewsArticle",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id":"/"
    },
    "headline": "Jinchi Lv: Model selection principles in misspecified models - McGill Statistics Seminars",
    "image": {
      "@type": "ImageObject",
      "url": "/images/default.png",
      "height": 800,
      "width": 800
    },
    "datePublished": "2012-03-23T00:00:00JST",
    "dateModified": "2012-03-23T00:00:00JST",
    "author": {
      "@type": "Person",
      "name": "McGill Statistics Seminars"
    },
    "publisher": {
      "@type": "Organization",
      "name": "McGill Statistics Seminars",
      "logo": {
        "@type": "ImageObject",
        "url": "/images/logo.png",
        "width": 600,
        "height": 60
      }
    },
    "description": "Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC."
  }
</script>


    <link href="/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">McGill Statistics Seminars</a>
          </div>

          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    <nav class="p-crumb">
      <ol class="breadcrumb">
        <li><a href="/"><i class="fa fa-home" aria-hidden="true"></i></a></li>
        
        <li itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb"><a href="/post/" itemprop="url"><span itemprop="title">post</span></a></li>
        
        <li class="active">Jinchi Lv: Model selection principles in misspecified models</li>
      </ol>
    </nav>

    <article class="single">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-03-23T00:00:00JST">Mar 23, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>

    <h1 class="title">Jinchi Lv: Model selection principles in misspecified models</h1>
  </header>

  

  <div class="article-body">

<h4 id="date-2012-03-23">Date: 2012-03-23</h4>

<h4 id="time-15-30-16-30">Time: 15:30-16:30</h4>

<h4 id="location-burn-1205">Location: BURN 1205</h4>

<h2 id="abstract">Abstract:</h2>

<p>Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC. A specific form of prior probabilities motivated by the Kullback-Leibler divergence principle leads to the generalized BIC with prior probability ($\mbox{GBIC}_p$), which can be naturally decomposed as the sum of  the negative maximum quasi-log-likelihood, and a penalty on model dimensionality, and a penalty on model misspecification directly. Numerical studies demonstrate the advantage of the new methods for model selection in both correctly specified and misspecified models.</p>

<h2 id="bio">Bio</h2>

<p>Jinchi Lv is an Assistant Professor in the Marshall School of Business, University of Southern California. He is interested in high dimensional inference, variable selection, machine learning and financial econometrics.</p>
</div>

  <footer class="article-footer">
    
    
    
    <section class="bordered">
      <header>
        <div class="panel-title">CATEGORIES</div>
      </header>
      <div>
        <ul class="p-terms">
          
          <li><a href="/categories/mcgill-statistics-seminar/">McGill Statistics Seminar</a></li>
          
        </ul>
      </div>
    </section>
    
    
    
    <section class="bordered">
      <header>
        <div class="panel-title">TAGS</div>
      </header>
      <div>
        <ul class="p-terms">
          
          <li><a href="/tags/2012-winter/">2012 Winter</a></li>
          
        </ul>
      </div>
    </section>
    
    
  </footer>

</article>


    
  </div>

  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">LATESTS</div>
    </div>
    <div class="list-group">
      
      <a href="/post/2012-04-13/" class="list-group-item">Longhai Li: High-dimensional feature selection using hierarchical Bayesian logistic regression with heavy-tailed priors | Sunil Rao: Best predictive estimation for linear mixed models with applications to small area estimation</a>
      
      <a href="/post/2012-04-05/" class="list-group-item">Pengfei Li: Hypothesis testing in finite mixture models: from the likelihood ratio test to EM-test</a>
      
      <a href="/post/2012-03-30/" class="list-group-item">Julian Wolfson: A matching-based approach to assessing the surrogate value of a biomarker</a>
      
      <a href="/post/2012-03-23/" class="list-group-item">Jinchi Lv: Model selection principles in misspecified models</a>
      
      <a href="/post/2012-03-16/" class="list-group-item">Azadeh Shohoudi: Variable selection in longitudinal data with a change-point</a>
      
      <a href="/post/2012-03-09/" class="list-group-item">Mori Jamshidian: Using tests of homoscedasticity to test missing completely at random | Hugh Chipman: Sequential optimization of a computer model and other Active Learning problems</a>
      
      <a href="/post/2012-03-02/" class="list-group-item">James O. Ramsay: Estimating a variance-covariance surface for functional and longitudinal data</a>
      
      <a href="/post/2012-02-17/" class="list-group-item">Annaliza McGillivray: A penalized quasi-likelihood approach for estimating the number of states in a hidden Markov model | Ana Best: Risk-set sampling and left truncation in survival analysis</a>
      
      <a href="/post/2012-02-10/" class="list-group-item">Winfried Stute: Principal component analysis of the Poisson Process | Jochen Blath: Longterm properties of the symbiotic branching model</a>
      
      <a href="/post/2012-02-03/" class="list-group-item">Yeting Du: Simultaneous fixed and random effects selection in finite mixtures of linear mixed-effects models | Daphna Harel: Measuring fatigue in systemic sclerosis: a comparison of the SF-36 vitality subscale and FACIT fatigue scale using item response theory</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="/categories/mcgill-statistics-seminar" class="list-group-item">mcgill-statistics-seminar</a>
      
      <a href="/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="/tags/2011-fall" class="list-group-item">2011-fall</a>
      
      <a href="/tags/2012-winter" class="list-group-item">2012-winter</a>
      
    </div>
  </section>
  

</aside>


  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p>Powered by <a href="https://gohugo.io/">Hugo</a>.</p>
          <p><a href="https://github.com/dim0627/hugo_theme_beg">Beg</a> designed by <a href="http://yet.unresolved.xyz/">Daisuke Tsuji</a>.</p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

