<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.36" />



<link rel="canonical" href="/post/2013winter/2012-03-23/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Jinchi Lv: Model selection principles in misspecified models - McGill Statistics Seminars</title>
    
<meta name="description" content="Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC.">

<meta property="og:title" content="Jinchi Lv: Model selection principles in misspecified models - McGill Statistics Seminars">
<meta property="og:type" content="article">
<meta property="og:url" content="/post/2013winter/2012-03-23/">
<meta property="og:image" content="/images/default.png">
<meta property="og:site_name" content="McGill Statistics Seminars">
<meta property="og:description" content="Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC.">
<meta property="og:locale" content="ja_JP">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="McGill Statistics Seminars">
<meta name="twitter:url" content="/post/2013winter/2012-03-23/">
<meta name="twitter:title" content="Jinchi Lv: Model selection principles in misspecified models - McGill Statistics Seminars">
<meta name="twitter:description" content="Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC.">
<meta name="twitter:image" content="/images/default.png">


<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "NewsArticle",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id":"/"
    },
    "headline": "Jinchi Lv: Model selection principles in misspecified models - McGill Statistics Seminars",
    "image": {
      "@type": "ImageObject",
      "url": "/images/default.png",
      "height": 800,
      "width": 800
    },
    "datePublished": "2012-03-23T00:00:00JST",
    "dateModified": "2012-03-23T00:00:00JST",
    "author": {
      "@type": "Person",
      "name": "McGill Statistics Seminars"
    },
    "publisher": {
      "@type": "Organization",
      "name": "McGill Statistics Seminars",
      "logo": {
        "@type": "ImageObject",
        "url": "/images/logo.png",
        "width": 600,
        "height": 60
      }
    },
    "description": "Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC."
  }
</script>


    <link href="/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">McGill Statistics Seminars</a>
          </div>

          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    <nav class="p-crumb">
      <ol class="breadcrumb">
        <li><a href="/"><i class="fa fa-home" aria-hidden="true"></i></a></li>
        
        <li itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb"><a href="/post/" itemprop="url"><span itemprop="title">post</span></a></li>
        
        <li class="active">Jinchi Lv: Model selection principles in misspecified models</li>
      </ol>
    </nav>

    <article class="single">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-03-23T00:00:00JST">Mar 23, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>

    <h1 class="title">Jinchi Lv: Model selection principles in misspecified models</h1>
  </header>

  

  <div class="article-body">

<h4 id="date-2012-03-23">Date: 2012-03-23</h4>

<h4 id="time-15-30-16-30">Time: 15:30-16:30</h4>

<h4 id="location-burn-1205">Location: BURN 1205</h4>

<h2 id="abstract">Abstract:</h2>

<p>Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC. A specific form of prior probabilities motivated by the Kullback-Leibler divergence principle leads to the generalized BIC with prior probability ($\mbox{GBIC}_p$), which can be naturally decomposed as the sum of  the negative maximum quasi-log-likelihood, and a penalty on model dimensionality, and a penalty on model misspecification directly. Numerical studies demonstrate the advantage of the new methods for model selection in both correctly specified and misspecified models.</p>

<h2 id="bio">Bio</h2>

<p>Jinchi Lv is an Assistant Professor in the Marshall School of Business, University of Southern California. He is interested in high dimensional inference, variable selection, machine learning and financial econometrics.</p>
</div>

  <footer class="article-footer">
    
    
    
    <section class="bordered">
      <header>
        <div class="panel-title">CATEGORIES</div>
      </header>
      <div>
        <ul class="p-terms">
          
          <li><a href="/categories/mcgill-statistics-seminar/">McGill Statistics Seminar</a></li>
          
        </ul>
      </div>
    </section>
    
    
    
    <section class="bordered">
      <header>
        <div class="panel-title">TAGS</div>
      </header>
      <div>
        <ul class="p-terms">
          
          <li><a href="/tags/2012-winter/">2012 Winter</a></li>
          
        </ul>
      </div>
    </section>
    
    
  </footer>

</article>


    
  </div>

  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">LATESTS</div>
    </div>
    <div class="list-group">
      
      <a href="/post/2012fall/2012-12-14/" class="list-group-item">Raymond J. Carroll: What percentage of children in the U.S. are eating a healthy diet? A statistical approach</a>
      
      <a href="/post/2012fall/2012-12-07/" class="list-group-item">Pierre Lafaye de Micheaux: Sample size and power determination for multiple comparison procedures aiming at rejecting at least r among m false hypotheses</a>
      
      <a href="/post/2012fall/2012-11-30/" class="list-group-item">Anne-Sophie Charest: Sharing confidential datasets using differential privacy</a>
      
      <a href="/post/2012fall/2012-11-23/" class="list-group-item">Peter Mueller: A nonparametric Bayesian model for local clustering</a>
      
      <a href="/post/2012fall/2012-11-16/" class="list-group-item">Taoufik Bouezmarni: Copula-based regression estimation and Inference</a>
      
      <a href="/post/2012fall/2012-11-09/" class="list-group-item">Sidney Resnick: The multidimensional edge: Seeking hidden risks </a>
      
      <a href="/post/2012fall/2012-11-02/" class="list-group-item">Anne-Laure Fougères: Multivariate extremal dependence: Estimation with bias correction</a>
      
      <a href="/post/2012fall/2012-10-26/" class="list-group-item">Derek Bingham: Simulation model calibration and prediction using outputs from multi-fidelity simulators</a>
      
      <a href="/post/2012fall/2012-10-19/" class="list-group-item">David Madigan: Observational studies in healthcare: are they any good?</a>
      
      <a href="/post/2012fall/2012-10-12/" class="list-group-item">	Elena Rivera Mancia: Modeling operational risk using a Bayesian approach to EVT</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="/categories/mcgill-statistics-seminar" class="list-group-item">mcgill-statistics-seminar</a>
      
      <a href="/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="/tags/2012-winter" class="list-group-item">2012-winter</a>
      
      <a href="/tags/2011-fall" class="list-group-item">2011-fall</a>
      
      <a href="/tags/2012-fall" class="list-group-item">2012-fall</a>
      
    </div>
  </section>
  

</aside>


  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p>Powered by <a href="https://gohugo.io/">Hugo</a>.</p>
          <p><a href="https://github.com/dim0627/hugo_theme_beg">Beg</a> designed by <a href="http://yet.unresolved.xyz/">Daisuke Tsuji</a>.</p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

