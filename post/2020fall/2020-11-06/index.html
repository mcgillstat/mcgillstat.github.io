<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.36.1" />



<link rel="canonical" href="/post/2020fall/2020-11-06/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Generalized Energy-Based Models - McGill Statistics Seminars</title>
    
<meta name="description" content="Date: 2020-11-06 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: I will introduce Generalized Energy Based Models (GEBM) for generative modelling. These models combine two trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. Both the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the &amp;ldquo;generator&amp;rdquo;).">

<meta property="og:title" content="Generalized Energy-Based Models - McGill Statistics Seminars">
<meta property="og:type" content="article">
<meta property="og:url" content="/post/2020fall/2020-11-06/">
<meta property="og:image" content="/images/default.png">
<meta property="og:site_name" content="McGill Statistics Seminars">
<meta property="og:description" content="Date: 2020-11-06 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: I will introduce Generalized Energy Based Models (GEBM) for generative modelling. These models combine two trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. Both the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the &amp;ldquo;generator&amp;rdquo;).">
<meta property="og:locale" content="ja_JP">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="McGill Statistics Seminars">
<meta name="twitter:url" content="/post/2020fall/2020-11-06/">
<meta name="twitter:title" content="Generalized Energy-Based Models - McGill Statistics Seminars">
<meta name="twitter:description" content="Date: 2020-11-06 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: I will introduce Generalized Energy Based Models (GEBM) for generative modelling. These models combine two trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. Both the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the &amp;ldquo;generator&amp;rdquo;).">
<meta name="twitter:image" content="/images/default.png">


<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "NewsArticle",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id":"/"
    },
    "headline": "Generalized Energy-Based Models - McGill Statistics Seminars",
    "image": {
      "@type": "ImageObject",
      "url": "/images/default.png",
      "height": 800,
      "width": 800
    },
    "datePublished": "2020-11-06T00:00:00JST",
    "dateModified": "2020-11-06T00:00:00JST",
    "author": {
      "@type": "Person",
      "name": "McGill Statistics Seminars"
    },
    "publisher": {
      "@type": "Organization",
      "name": "McGill Statistics Seminars",
      "logo": {
        "@type": "ImageObject",
        "url": "/images/logo.png",
        "width": 600,
        "height": 60
      }
    },
    "description": "Date: 2020-11-06 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: I will introduce Generalized Energy Based Models (GEBM) for generative modelling. These models combine two trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. Both the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the &ldquo;generator&rdquo;)."
  }
</script>


    <link href="/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    <nav class="p-crumb">
      <ol class="breadcrumb">
        <li><a href="/"><i class="fa fa-home" aria-hidden="true"></i></a></li>
        
        <li itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb"><a href="/post/" itemprop="url"><span itemprop="title">post</span></a></li>
        
        <li class="active">Arthur Gretton</li>
      </ol>
    </nav>

    <article class="single">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-11-06T00:00:00JST">Nov 6, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>

    <h2 class="title">Generalized Energy-Based Models</h1>
    <h3 class="post-meta">Arthur Gretton </h3>
    
  </header>

  

  <div class="article-body">

<h4 id="date-2020-11-06">Date: 2020-11-06</h4>

<h4 id="time-15-30-16-30">Time: 15:30-16:30</h4>

<h4 id="zoom-link-https-mcgill-zoom-us-j-92453904989-pwd-zdr6rumxtznyk0zime9obwtomgjqdz09"><a href="https://mcgill.zoom.us/j/92453904989?pwd=ZDR6RUMxTzNYK0ZiME9ObWtoMGJqdz09">Zoom Link</a></h4>

<h4 id="meeting-id-924-5390-4989">Meeting ID: 924 5390 4989</h4>

<h4 id="passcode-690084">Passcode: 690084</h4>

<h2 id="abstract">Abstract:</h2>

<p>I will introduce Generalized Energy Based Models (GEBM) for generative modelling. These models combine two trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. Both the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the &ldquo;generator&rdquo;). In particular, while the energy function is analogous to the GAN critic function, it is not discarded after training.
GEBMs are trained by alternating between learning the energy and the base, much like a GAN. Both training stages are well-defined: the energy is learned by maximising a generalized likelihood, and the resulting energy-based loss provides informative gradients for learning the base. Samples from the posterior on the latent space of the trained model can be obtained via MCMC, thus finding regions in this space that produce better quality samples. Empirically, the GEBM samples on image-generation tasks are of better quality than those from the learned generator alone, indicating that all else being equal, the GEBM will outperform a GAN of the same complexity. GEBMs also return state-of-the-art performance on density modelling tasks, and when using base measures with an explicit form.</p>

<h2 id="speaker">Speaker</h2>

<p>Arthur Gretton is a Professor with the Gatsby Computational Neuroscience Unit, and director of the Centre for Computational Statistics and Machine Learning (CSML) at UCL. He received degrees in Physics and Systems Engineering from the Australian National University, and a PhD with Microsoft Research and the Signal Processing and Communications Laboratory at the University of Cambridge. He previously worked at the MPI for Biological Cybernetics, and at the Machine Learning Department, Carnegie Mellon University.</p>

<p>Arthur&rsquo;s recent research interests in machine learning include the design and training of generative models, both implicit (e.g. GANs) and explicit (high/infinite dimensional exponential family models and energy-based models), nonparametric hypothesis testing, survival analysis, causality, and kernel methods.</p>

<p>He has been an associate editor at IEEE Transactions on Pattern Analysis and Machine Intelligence from 2009 to 2013, an Action Editor for JMLR since April 2013, an Area Chair for NeurIPS in 2008 and 2009, a Senior Area Chair for NeurIPS in 2018, an Area Chair for ICML in 2011 and 2012, a member of the COLT Program Committee in 2013, and a member of Royal Statistical Society Research Section Committee since January 2020. Arthur was program chair for AISTATS in 2016 (with Christian Robert), tutorials chair for ICML 2018 (with Ruslan Salakhutdinov), workshops chair for ICML 2019 (with Honglak Lee), program chair for the Dali workshop in 2019 (with Krikamol Muandet and Shakir Mohammed), and co-organsier of the Machine Learning Summer School 2019 in London (with Marc Deisenroth).</p>
</div>

  <footer class="article-footer">
    
    
    
    <section class="bordered">
      <header>
        <div class="panel-title">CATEGORIES</div>
      </header>
      <div>
        <ul class="p-terms">
          
          <li><a href="/categories/mcgill-statistics-seminar/">McGill Statistics Seminar</a></li>
          
        </ul>
      </div>
    </section>
    
    
    
    <section class="bordered">
      <header>
        <div class="panel-title">TAGS</div>
      </header>
      <div>
        <ul class="p-terms">
          
          <li><a href="/tags/2020-fall/">2020 fall</a></li>
          
        </ul>
      </div>
    </section>
    
    
  </footer>

</article>


    
  </div>

  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="/post/2021winter/2021-02-19/" class="list-group-item">Emily Hector · Feb 19, 2021</a>
      
      <a href="/post/2021winter/2020-01-29/" class="list-group-item">Jon Wakefield · Jan 29, 2021</a>
      
      <a href="/post/2021winter/2021-01-15/" class="list-group-item">Wei Zhang · Jan 15, 2021</a>
      
      <a href="/post/2020fall/2020-12-04/" class="list-group-item">Marius Hofert · Dec 4, 2020</a>
      
      <a href="/post/2020fall/2020-11-27/" class="list-group-item">Qing Mai · Nov 27, 2020</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="/categories/mcgill-statistics-seminar" class="list-group-item">mcgill-statistics-seminar</a>
      
      <a href="/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc-prize-address</a>
      
      <a href="/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="/tags/2021-winter" class="list-group-item">2021-winter</a>
      
      <a href="/tags/2020-winter" class="list-group-item">2020-winter</a>
      
      <a href="/tags/2020-fall" class="list-group-item">2020-fall</a>
      
      <a href="/tags/2019-winter" class="list-group-item">2019-winter</a>
      
      <a href="/tags/2019-fall" class="list-group-item">2019-fall</a>
      
      <a href="/tags/2018-winter" class="list-group-item">2018-winter</a>
      
      <a href="/tags/2018-fall" class="list-group-item">2018-fall</a>
      
      <a href="/tags/2017-winter" class="list-group-item">2017-winter</a>
      
      <a href="/tags/2017-fall" class="list-group-item">2017-fall</a>
      
      <a href="/tags/2016-winter" class="list-group-item">2016-winter</a>
      
      <a href="/tags/2016-fall" class="list-group-item">2016-fall</a>
      
      <a href="/tags/2015-winter" class="list-group-item">2015-winter</a>
      
      <a href="/tags/2015-fall" class="list-group-item">2015-fall</a>
      
      <a href="/tags/2014-winter" class="list-group-item">2014-winter</a>
      
      <a href="/tags/2014-fall" class="list-group-item">2014-fall</a>
      
      <a href="/tags/2013-winter" class="list-group-item">2013-winter</a>
      
      <a href="/tags/2013-fall" class="list-group-item">2013-fall</a>
      
      <a href="/tags/2012-winter" class="list-group-item">2012-winter</a>
      
      <a href="/tags/2012-fall" class="list-group-item">2012-fall</a>
      
      <a href="/tags/2011-fall" class="list-group-item">2011-fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

