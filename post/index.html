<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.139.4">

/post/index.xml

<link rel="canonical" href="https://mcgillstat.github.io/post/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Past Seminar Series - McGill Statistics Seminars</title>
    
    <link href="https://mcgillstat.github.io/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://mcgillstat.github.io/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Past Seminar Series</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-10-24T00:00:00JST">Oct 24, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025fall/2025-10-24/">Regularized Fine-Tuning for Representation Multi-Task Learning: Adaptivity, Minimaxity, and Robustness</a></h2>
    <h3 class="post-meta">Yang Feng · Oct 24, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-10-24">Date: 2025-10-24</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj81872329544httpsmcgillzoomusj81872329544"><a href="https://mcgill.zoom.us/j/81872329544">https://mcgill.zoom.us/j/81872329544</a></h4>
<h4 id="meeting-id-818-7232-9544">Meeting ID: 818 7232 9544</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>We study multi-task linear regression for a collection of tasks that share a latent, low-dimensional structure. Each task’s regression vector belongs to a subspace whose dimension, denoted intrinsic dimension, is much smaller than the ambient dimension. Unlike classical analyses that assume an identical subspace for every task, we allow each task’s subspace to drift from a single reference subspace by a controllable similarity radius, and we permit an unknown fraction of tasks to be outliers that violate the shared-structure assumption altogether. Our contributions are threefold. First, adaptivity: we design a penalized empirical-risk algorithm and a spectral method.  Both algorithms automatically adjust to the unknown similarity radius and to the proportion of outliers. Second, minimaxity: we prove information-theoretic lower bounds on the best achievable prediction risk over this problem class and show that both algorithms attain these bounds up to constant factors; when no outliers are present, the spectral method is exactly minimax-optimal. Third, robustness: for every choice of similarity radius and outlier proportion, the proposed estimators never incur larger expected prediction error than independent single-task regression, while delivering strict improvements whenever tasks are even moderately similar and outliers are sparse. Additionally, we introduce a thresholding algorithm to adapt to an unknown intrinsic dimension. We conduct extensive numerical experiments to validate our theoretical findings.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025fall/2025-10-24/" title="Regularized Fine-Tuning for Representation Multi-Task Learning: Adaptivity, Minimaxity, and Robustness">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-10-10T00:00:00JST">Oct 10, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025fall/2025-10-10/">K-contact Distance for Noisy Nonhomogeneous Spatial Point Data and Application to Repeating Fast Radio Burst Sources</a></h2>
    <h3 class="post-meta">Amanda M. Cook · Oct 10, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-10-10">Date: 2025-10-10</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj81986712072httpsmcgillzoomusj81986712072"><a href="https://mcgill.zoom.us/j/81986712072">https://mcgill.zoom.us/j/81986712072</a></h4>
<h4 id="meeting-id-819-8671-2072">Meeting ID: 819 8671 2072</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>In this talk, I’ll introduce an approach to analyze nonhomogeneous Poisson processes (NHPP) observed with noise which focuses on previously unstudied second-order characteristics of the noisy process. Utilizing a hierarchical Bayesian model with noisy data, we first estimate hyperparameters governing a physically motivated NHPP intensity. Leveraging the posterior distribution, we then infer the probability of detecting a certain number of events within a given radius, the $k$-contact distance. This methodology is demonstrated by its motivating application: observations of fast radio bursts (FRBs) detected by the Canadian Hydrogen Intensity Mapping Experiment&rsquo;s FRB Project (CHIME/FRB). The approach allows us to identify repeating FRB sources by computing the probability of observing $k$ physically independent sources within some radius in the detection domain, or the probability of coincidence ($P_C$). Applied, the new methodology improves the repeater detection $P_C$, in 86% of cases when applied to the largest sample of previously classified observations, with a median improvement factor (existing metric over $P_C$ from our methodology) of ~ 3000. Throughout the talk, I will provide the necessary astrophysical context to motivate the application and highlight some of the other active statistical problems in FRB science.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025fall/2025-10-10/" title="K-contact Distance for Noisy Nonhomogeneous Spatial Point Data and Application to Repeating Fast Radio Burst Sources">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-10-03T00:00:00JST">Oct 3, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025fall/2025-10-03/">Convergence Guarantees for Adversarially Robust Classifiers</a></h2>
    <h3 class="post-meta">Rachel Morris · Oct 3, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-10-03">Date: 2025-10-03</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj82469112499httpsmcgillzoomusj82469112499"><a href="https://mcgill.zoom.us/j/82469112499">https://mcgill.zoom.us/j/82469112499</a></h4>
<h4 id="meeting-id-824-6911-2499">Meeting ID: 824 6911 2499</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>Neural networks can be trained to classify images and achieve high levels of accuracy. However, researchers have discovered that well-targeted perturbations of an image can completely fool a trained classifier, even in cases where the modified image is visually indistinguishable from the original. This has sparked many new approaches to classification which include an adversary in the training process: such an adversary can improve robustness and generalization properties at the cost of decreased accuracy and increased training time. In this presentation, I will explore the connection between a certain class of adversarial training problems and the Bayes classification problem for binary classification. In particular, robustness can be encouraged by adding a regularizing nonlocal perimeter term, providing a strong connection to classical studies of perimeter. Borrowing tools from geometric measure theory, I will show the Hausdorff convergence of adversarially robust classifiers to Bayes classifiers as the strength of adversary decreases to 0. In this way, the theoretical results discussed in the presentation provide a rigorous comparison with the standard Bayes classification problem.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025fall/2025-10-03/" title="Convergence Guarantees for Adversarially Robust Classifiers">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-09-26T00:00:00JST">Sep 26, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025fall/2025-09-26/">Sparse Causal Learning: Challenges and Opportunities</a></h2>
    <h3 class="post-meta">Dingke Tang · Sep 26, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-09-26">Date: 2025-09-26</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj81200178578httpsmcgillzoomusj81200178578"><a href="https://mcgill.zoom.us/j/81200178578">https://mcgill.zoom.us/j/81200178578</a></h4>
<h4 id="meeting-id-812-0017-8578">Meeting ID: 812 0017 8578</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>In many observational studies, researchers are often interested in studying the effects of multiple exposures on a single outcome. Standard approaches for high-dimensional data such as the lasso assume the associations between the exposures and the outcome are sparse. These methods, however, do not estimate the causal effects in the presence of unmeasured confounding. In this paper, we consider an alternative approach that assumes the causal effects in view are sparse. We show that with sparse causation, the causal effects are identifiable even with unmeasured confounding. At the core of our proposal is a novel device, called the synthetic instrument, that in contrast to standard instrumental variables, can be constructed using the observed exposures directly. We show that under linear structural equation models, the problem of causal effect estimation can be formulated as an l0-penalization problem and hence can be solved efficiently using off-the-shelf software. Simulations show that our approach outperforms state-of-art methods in both low-dimensional and high-dimensional settings. We further illustrate our method using a mouse obesity dataset.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025fall/2025-09-26/" title="Sparse Causal Learning: Challenges and Opportunities">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-09-19T00:00:00JST">Sep 19, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025fall/2025-09-19/">Optimal vintage factor analysis with deflation varimax</a></h2>
    <h3 class="post-meta">Xin Bing · Sep 19, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-09-19">Date: 2025-09-19</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj83914219181httpsmcgillzoomusj83914219181"><a href="https://mcgill.zoom.us/j/83914219181">https://mcgill.zoom.us/j/83914219181</a></h4>
<h4 id="meeting-id-839-1421-9181">Meeting ID: 839 1421 9181</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>Vintage factor analysis is one important type of factor analysis that aims to first find a low-dimensional representation of the original data, and then to seek a rotation such that the rotated low-dimensional representation is scientifically meaningful. The most widely used vintage factor analysis is the Principal Component Analysis (PCA) followed by the varimax rotation. Despite its popularity, little theoretical guarantee can be provided to date mainly because varimax rotation requires to solve a non-convex optimization over the set of orthogonal matrices.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025fall/2025-09-19/" title="Optimal vintage factor analysis with deflation varimax">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-09-12T00:00:00JST">Sep 12, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025fall/2025-09-12/">Proper Correlation Coefficients for Nominal Random Variables</a></h2>
    <h3 class="post-meta">Lukas Wermuth · Sep 12, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-09-12">Date: 2025-09-12</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj88021402798httpsmcgillzoomusj88021402798"><a href="https://mcgill.zoom.us/j/88021402798">https://mcgill.zoom.us/j/88021402798</a></h4>
<h4 id="meeting-id-880-2140-2798">Meeting ID: 880 2140 2798</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>This work develops an intuitive concept of perfect dependence between two variables of which at least one has a nominal scale that is attainable for all marginal distributions and proposes a set of dependence measures that are 1 if and only if this perfect dependence is satisfied. The advantages of these dependence measures relative to classical dependence measures like contingency coefficients, Goodman-Kruskal&rsquo;s lambda and tau and the so-called uncertainty coefficient are twofold. Firstly, they are defined if one of the variables is real-valued and exhibits continuities. Secondly, they satisfy the property of attainability. That is, they can take all values in the interval [0,1] irrespective of the marginals involved. Both properties are not shared by the classical dependence measures which need two discrete marginal distributions and can in some situations yield values close to 0 even though the dependence is strong or even perfect.
Additionally, this work provide a consistent estimator for one of the new dependence measures together with its asymptotic distribution under independence as well as in the general case. This allows to construct confidence intervals and an independence test, whose finite sample performance is subsequently examine in a simulation study. Finally, we illustrate the use of the new dependence measure in two applications on the dependence between the variables country and income or country and religion, respectively.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025fall/2025-09-12/" title="Proper Correlation Coefficients for Nominal Random Variables">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-05-23T00:00:00JST">May 23, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025winter/2025-05-23/">GARCH copulas, v-transforms and D-vines</a></h2>
    <h3 class="post-meta">Alexander McNeil · May 23, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-05-23">Date: 2025-05-23</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj89626299031httpsmcgillzoomusj89626299031"><a href="https://mcgill.zoom.us/j/89626299031">https://mcgill.zoom.us/j/89626299031</a></h4>
<h4 id="meeting-id-896-2629-9031">Meeting ID: 896 2629 9031</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>Stationary models from the GARCH class have proved to be extremely useful for forecasting volatility and measuring risk in financial time series. However, the nature of their implied copulas is opaque.</p>
<p>We analyse the serial dependence structure of first-order GARCH-type models in terms of the implied bivariate copulas that describe the dependence and partial dependence of pairs of variables at different lags. Our aim is to understand whether such dependence structures could be approximated with appropriately chosen bivariate copulas arranged in D-vines.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025winter/2025-05-23/" title="GARCH copulas, v-transforms and D-vines">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-04-04T00:00:00JST">Apr 4, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025winter/2025-04-04/">Normalization effects on deep neural networks and deep learning for scientific problems</a></h2>
    <h3 class="post-meta">Konstantinos Spiliopoulos · Apr 4, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-04-04">Date: 2025-04-04</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj81100654212httpsmcgillzoomusj81100654212"><a href="https://mcgill.zoom.us/j/81100654212">https://mcgill.zoom.us/j/81100654212</a></h4>
<h4 id="meeting-id-811-0065-4212">Meeting ID: 811 0065 4212</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>We study the effect of normalization on the layers of deep neural networks. A given layer $i$ with $N_{i}$ hidden units is normalized by $1/N_{i}^{\gamma_{i}}$ with $\gamma_{i}\in[1/2,1]$. We study the effect of the choice of the $\gamma_{i}$ on the statistical behavior of the neural network’s output (such as variance) as well as on the test accuracy and generalization properties of the architecture.  We find that in terms of variance of the neural network’s output and test accuracy the best choice is to choose the $\gamma_{i}$’s to be equal to one, which is the mean-field scaling. We also find that this is particularly true for the outer layer, in that the neural network’s behavior is more sensitive in the scaling of the outer layer as opposed to the scaling of the inner layers. The mechanism for the mathematical analysis is an asymptotic expansion for the neural network’s output. An important practical consequence of the analysis is that it provides a systematic and mathematically informed way to choose the learning rate hyperparameters. Such a choice guarantees that the neural network behaves in a statistically robust way as the number of hidden units $N_i$ grow.  Time permitting, I will discuss applications of these ideas to design of deep learning algorithms for scientific problems including solving high dimensional partial differential equations (PDEs), closure of PDE models and reinforcement learning with applications to financial engineering, turbulence and more.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025winter/2025-04-04/" title="Normalization effects on deep neural networks and deep learning for scientific problems">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-03-28T00:00:00JST">Mar 28, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025winter/2025-03-28/">From the distribution of string counts in Bernoulli sequences to multivariate discrete models</a></h2>
    <h3 class="post-meta">Éric Marchand · Mar 28, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-03-28">Date: 2025-03-28</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj85849766730httpsmcgillzoomusj85849766730"><a href="https://mcgill.zoom.us/j/85849766730">https://mcgill.zoom.us/j/85849766730</a></h4>
<h4 id="meeting-id-858-4976-6730">Meeting ID: 858 4976 6730</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>I will provide a personalized account of a sequence of problems, that I have worked on over the years, beginning with string counts in Bernoulli sequences and transiting to multivariate discrete models. As a starting point, we consider independent Bernoulli trials with varying success probabilities 1/k for the kth trial, the sum of the products of two consecutive occurrences,  and  the problem of establishing that the sum is distributed Poisson with mean equal to 1.  We will explain how this finding connects to cycles in random permutations, records for continuous random variables, the Hoppe-Polya urn, and the classical Montmort matching problem.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025winter/2025-03-28/" title="From the distribution of string counts in Bernoulli sequences to multivariate discrete models">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2025-03-14T00:00:00JST">Mar 14, 2025</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2025winter/2025-03-14/">A computational framework for linear inverse problems via the maximum entropy on the mean method</a></h2>
    <h3 class="post-meta">Tim Hoheisel · Mar 14, 2025 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2025-03-14">Date: 2025-03-14</h4>
<h4 id="time-1530-1630-montreal-time">Time: 15:30-16:30 (Montreal time)</h4>
<h4 id="location-in-person-burnside-1104">Location: In person, Burnside 1104</h4>
<h4 id="httpsmcgillzoomusj88555780651httpsmcgillzoomusj88555780651"><a href="https://mcgill.zoom.us/j/88555780651">https://mcgill.zoom.us/j/88555780651</a></h4>
<h4 id="meeting-id-885-5578-0651">Meeting ID: 885 5578 0651</h4>
<h4 id="passcode-none">Passcode: None</h4>
<h2 id="abstract">Abstract:</h2>
<p>We present a framework for solving linear inverse problems that is computationally tractable and has mathematical certificates. To this end, we interpret the ground truth of a linear inverse problem as a random vector with unknown distribution. We solve for a distribution which is close to a prior P (guessed or data-driven) measured in the KL-divergence while also having an expectation that yields high fidelity with the given data that defines the problem. After reformulation this yields a strictly convex, finite dimensional optimization problem whose regularizer, the MEM functional, is paired in duality with the log-moment generating function of the prior P. We exploit this computationally via Fenchel-Rockafellar duality. When no obvious guess for P is available, we use data to generate an empirical prior. Using techniques from variational analysis and stochastic optimization, we show that, and at what rate, the solution of the empirical problems converge (as the sample size grows) to the solution of the problem with known prior.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2025winter/2025-03-14/" title="A computational framework for linear inverse problems via the maximum entropy on the mean method">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li class="disabled"><a href="#">Previous</a></li>
    

    
    <li><a href="/post/page/2/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-fall/" class="list-group-item"> · Oct 24, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/" class="list-group-item"> · Oct 24, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar/" class="list-group-item"> · Oct 24, 2025</a>
      
      <a href="https://mcgillstat.github.io/post/2025fall/2025-10-24/" class="list-group-item">Yang Feng · Oct 24, 2025</a>
      
      <a href="https://mcgillstat.github.io/tags/" class="list-group-item"> · Oct 24, 2025</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar" class="list-group-item">mcgill statistics seminar</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc prize address</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-winter" class="list-group-item">2025 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2025-fall" class="list-group-item">2025 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-winter" class="list-group-item">2024 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-fall" class="list-group-item">2024 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-winter" class="list-group-item">2023 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-summer" class="list-group-item">2023 summer</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-fall" class="list-group-item">2023 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-winter" class="list-group-item">2022 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-fall" class="list-group-item">2022 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-winter" class="list-group-item">2021 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-fall" class="list-group-item">2021 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-winter" class="list-group-item">2020 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-fall" class="list-group-item">2020 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-winter" class="list-group-item">2019 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-fall" class="list-group-item">2019 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-winter" class="list-group-item">2018 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-fall" class="list-group-item">2018 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-winter" class="list-group-item">2017 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-fall" class="list-group-item">2017 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-winter" class="list-group-item">2016 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-fall" class="list-group-item">2016 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-winter" class="list-group-item">2015 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-fall" class="list-group-item">2015 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-winter" class="list-group-item">2014 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-fall" class="list-group-item">2014 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-winter" class="list-group-item">2013 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-fall" class="list-group-item">2013 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-winter" class="list-group-item">2012 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-fall" class="list-group-item">2012 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2011-fall" class="list-group-item">2011 fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

