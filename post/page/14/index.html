<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.36.1" />

<link rel="alternate" type="application/rss+xml" title="RSS" href="/post/index.xml">

<link rel="canonical" href="/post/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Past Seminar Series - McGill Statistics Seminars</title>
    
    <link href="/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Past Seminar Series</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-02-13T00:00:00JST">Feb 13, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2015winter/2015-02-13/">Tuning parameters in high-dimensional statistics</a></h2>
    <h3 class="post-meta">Johannes Lederer · Feb 13, 2015 </h3>
  </header>

  
  <div class="summary">Date: 2015-02-13 Time: 15:30-16:30 Location: BURN 1205 Abstract: High-dimensional statistics is the basis for analyzing large and complex data sets that are generated by cutting-edge technologies in genetics, neuroscience, astronomy, and many other fields. However, Lasso, Ridge Regression, Graphical Lasso, and other standard methods in high-dimensional statistics depend on tuning parameters that are difficult to calibrate in practice. In this talk, I present two novel approaches to overcome this difficulty.</div>

  
  <footer>
    <a href="/post/2015winter/2015-02-13/" title="Tuning parameters in high-dimensional statistics">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-02-05T00:00:00JST">Feb 5, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2015winter/2015-02-05/">A fast unified algorithm for solving group Lasso penalized learning problems</a></h2>
    <h3 class="post-meta">Yi Yang · Feb 5, 2015 </h3>
  </header>

  
  <div class="summary">Date: 2015-02-05 Time: 15:30-16:30 Location: BURN 1B39 Abstract: We consider a class of group-lasso learning problems where the objective function is the sum of an empirical loss and the group-lasso penalty. For a class of loss function satisfying a quadratic majorization condition, we derive a unified algorithm called groupwise-majorization-descent (GMD) for efficiently computing the solution paths of the corresponding group-lasso penalized learning problem. GMD allows for general design matrices, without requiring the predictors to be group-wise orthonormal.</div>

  
  <footer>
    <a href="/post/2015winter/2015-02-05/" title="A fast unified algorithm for solving group Lasso penalized learning problems">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-02-02T00:00:00JST">Feb 2, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2015winter/2015-02-02/">Joint analysis of multiple multi-state processes via copulas</a></h2>
    <h3 class="post-meta">Liqun Diao · Feb 2, 2015 </h3>
  </header>

  
  <div class="summary">Date: 2015-02-02 Time: 15:30-16:30 Location: BURN 1214 Abstract: A copula-based model is described which enables joint analysis of multiple progressive multi-state processes. Unlike intensity-based or frailty-based approaches to joint modeling, the copula formulation proposed herein ensures that a wide range of marginal multi-state processes can be specified and the joint model will retain these marginal features. The copula formulation also facilitates a variety of approaches to estimation and inference including composite likelihood and two-stage estimation procedures.</div>

  
  <footer>
    <a href="/post/2015winter/2015-02-02/" title="Joint analysis of multiple multi-state processes via copulas">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-30T00:00:00JST">Jan 30, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2015winter/2015-01-30/">Distributed estimation and inference for sparse regression</a></h2>
    <h3 class="post-meta">Yuekai Sun · Jan 30, 2015 </h3>
  </header>

  
  <div class="summary">Date: 2015-01-30 Time: 15:30-16:30 Location: BURN 1205 Abstract: We address two outstanding challenges in sparse regression: (i) computationally efficient estimation in distributed settings; (ii) valid inference for the selected coefficients. The main computational challenge in a distributed setting is harnessing the computational capabilities of all the machines while keeping communication costs low. We devise an approach that requires only a single round of communication among the machines. We show the approach recovers the convergence rate of the (centralized) lasso as long as each machine has access to an adequate number of samples.</div>

  
  <footer>
    <a href="/post/2015winter/2015-01-30/" title="Distributed estimation and inference for sparse regression">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-16T00:00:00JST">Jan 16, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2015winter/2015-01-16/">Simultaneous white noise models and shrinkage recovery of functional data</a></h2>
    <h3 class="post-meta">Fang Yao · Jan 16, 2015 </h3>
  </header>

  
  <div class="summary">Date: 2015-01-16 Time: 15:30-16:30 Location: BURN 1205 Abstract: We consider the white noise representation of functional data taken as i.i.d. realizations of a Gaussian process. The main idea is to establish an asymptotic equivalence in Le Cam’s sense between an experiment which simultaneously describes these realizations and a collection of white noise models. In this context, we project onto an arbitrary basis and apply a novel variant of Stein-type estimation for optimal recovery of the realized trajectories.</div>

  
  <footer>
    <a href="/post/2015winter/2015-01-16/" title="Simultaneous white noise models and shrinkage recovery of functional data">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-15T00:00:00JST">Jan 15, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2015winter/2015-01-15/">Functional data analysis and related topics</a></h2>
    <h3 class="post-meta">Fang Yao · Jan 15, 2015 </h3>
  </header>

  
  <div class="summary">Date: 2015-01-15 Time: 16:00-17:00 Location: CRM 1360 (U. de Montréal) Abstract: Functional data analysis (FDA) has received substantial attention, with applications arising from various disciplines, such as engineering, public health, finance etc. In general, the FDA approaches focus on nonparametric underlying models that assume the data are observed from realizations of stochastic processes satisfying some regularity conditions, e.g., smoothness constraints. The estimation and inference procedures usually do not depend on merely a finite number of parameters, which contrasts with parametric models, and exploit techniques, such as smoothing methods and dimension reduction, that allow data to speak for themselves.</div>

  
  <footer>
    <a href="/post/2015winter/2015-01-15/" title="Functional data analysis and related topics">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-13T00:00:00JST">Jan 13, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2015winter/2015-01-13/">Mixtures of coalesced generalized hyperbolic distributions</a></h2>
    <h3 class="post-meta">Ryan P. Browne · Jan 13, 2015 </h3>
  </header>

  
  <div class="summary">Date: 2015-01-13 Time: 15:30-16:30 Location: BURN 1205 Abstract: A mixture of coalesced generalized hyperbolic distributions is developed by joining a finite mixture of generalized hyperbolic distributions with a mixture of multiple scaled generalized hyperbolic distributions. The result is a mixture of mixtures with shared model parameters and common mode. We begin by discussing the generalized hyperbolic distribution, which has the t, Gaussian and others as special cases. The generalized hyperbolic distribution can represented as a normal-variance mixture using a generalized inverse Gaussian distribution.</div>

  
  <footer>
    <a href="/post/2015winter/2015-01-13/" title="Mixtures of coalesced generalized hyperbolic distributions">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-09T00:00:00JST">Jan 9, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2015winter/2015-01-9/">Space-time data analysis: Out of the Hilbert box</a></h2>
    <h3 class="post-meta">James O. Ramsay · Jan 9, 2015 </h3>
  </header>

  
  <div class="summary">Date: 2015-01-09 Time: 15:30-16:30 Location: BURN 1205 Abstract: Given the discouraging state of current efforts to curb global warming, we can imagine that we will soon turn our attention to mitigation. On a global scale, distressed populations will turn to national and international organizations for solutions to dramatic problems caused by climate change. These institutions in turn will mandate the collection of data on a scale and resolution that will present extraordinary statistical and computational challenges to those of us viewed as having the appropriate expertise.</div>

  
  <footer>
    <a href="/post/2015winter/2015-01-9/" title="Space-time data analysis: Out of the Hilbert box">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2014-12-12T00:00:00JST">Dec 12, 2014</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2014fall/2014-12-12/">Testing for structured Normal means</a></h2>
    <h3 class="post-meta">James Sharpnack · Dec 12, 2014 </h3>
  </header>

  
  <div class="summary">Date: 2014-12-12 Time: 15:30-16:30 Location: BURN 1205 Abstract: We will discuss the detection of pattern in images and graphs from a high-dimensional Gaussian measurement. This problem is relevant to many applications including detecting anomalies in sensor and computer networks, large-scale surveillance, co-expressions in gene networks, disease outbreaks, etc. Beyond its wide applicability, structured Normal means detection serves as a case study in the difficulty of balancing computational complexity with statistical power.</div>

  
  <footer>
    <a href="/post/2014fall/2014-12-12/" title="Testing for structured Normal means">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2014-12-05T00:00:00JST">Dec 5, 2014</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2014fall/2014-12-05/">Copula model selection: A statistical approach</a></h2>
    <h3 class="post-meta">Julien Roger · Dec 5, 2014 </h3>
  </header>

  
  <div class="summary">Date: 2014-12-05 Time: 15:30-16:30 Location: BURN 1205 Abstract: Copula model selection is an important problem because similar but differing copula models can offer different conclusions surrounding the dependence structure of random variables. Chen &amp; Fan (2005) proposed a model selection method involving a statistical hypothesis test. The hypothesis test attempts to take into account the randomness of the AIC and other likelihood-based model selection methods for finite samples. Performance of the test compared to the more common approach of AIC is illustrated in a series of simulations.</div>

  
  <footer>
    <a href="/post/2014fall/2014-12-05/" title="Copula model selection: A statistical approach">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/post/page/13/">Previous</a></li>
    

    
    <li><a href="/post/page/15/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="/post/2020fall/2020-09-25/" class="list-group-item">Yingying Fan · Sep 25, 2020</a>
      
      <a href="/post/2020fall/2020-09-18/" class="list-group-item">Simon Mak · Sep 18, 2020</a>
      
      <a href="/post/2020fall/2020-09-11/" class="list-group-item">Stefan Wager · Sep 11, 2020</a>
      
      <a href="/post/2020winter/2020-03-27/" class="list-group-item">Heungsun Hwang · Mar 27, 2020</a>
      
      <a href="/post/2020winter/2020-03-20/" class="list-group-item">Shirin Golchi · Mar 20, 2020</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="/categories/mcgill-statistics-seminar" class="list-group-item">mcgill-statistics-seminar</a>
      
      <a href="/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc-prize-address</a>
      
      <a href="/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="/tags/2020-winter" class="list-group-item">2020-winter</a>
      
      <a href="/tags/2020-fall" class="list-group-item">2020-fall</a>
      
      <a href="/tags/2019-winter" class="list-group-item">2019-winter</a>
      
      <a href="/tags/2019-fall" class="list-group-item">2019-fall</a>
      
      <a href="/tags/2018-winter" class="list-group-item">2018-winter</a>
      
      <a href="/tags/2018-fall" class="list-group-item">2018-fall</a>
      
      <a href="/tags/2017-winter" class="list-group-item">2017-winter</a>
      
      <a href="/tags/2017-fall" class="list-group-item">2017-fall</a>
      
      <a href="/tags/2016-winter" class="list-group-item">2016-winter</a>
      
      <a href="/tags/2016-fall" class="list-group-item">2016-fall</a>
      
      <a href="/tags/2015-winter" class="list-group-item">2015-winter</a>
      
      <a href="/tags/2015-fall" class="list-group-item">2015-fall</a>
      
      <a href="/tags/2014-winter" class="list-group-item">2014-winter</a>
      
      <a href="/tags/2014-fall" class="list-group-item">2014-fall</a>
      
      <a href="/tags/2013-winter" class="list-group-item">2013-winter</a>
      
      <a href="/tags/2013-fall" class="list-group-item">2013-fall</a>
      
      <a href="/tags/2012-winter" class="list-group-item">2012-winter</a>
      
      <a href="/tags/2012-fall" class="list-group-item">2012-fall</a>
      
      <a href="/tags/2011-fall" class="list-group-item">2011-fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

