<!DOCTYPE html>
<html>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=4321&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.136.5">

/post/index.xml

<link rel="canonical" href="http://localhost:4321/post/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Past Seminar Series - McGill Statistics Seminars</title>
    
    <link href="http://localhost:4321/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://localhost:4321/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Past Seminar Series</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-02-20T00:00:00JST">Feb 20, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-02-20/">Comparison and assessment of particle diffusion models in biological fluids</a></h2>
    <h3 class="post-meta">Martin Lysy · Feb 20, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-02-20">Date: 2015-02-20</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Rapidly progressing particle tracking techniques have revealed that foreign particles in biological fluids exhibit rich and at times unexpected behavior, with important consequences for disease diagnosis and drug delivery. Yet, there remains a frustrating lack of coherence in the description of these particles&rsquo; motion. Largely this is due to a reliance on functional statistics (e.g., mean-squared displacement) to perform model selection and assess goodness-of-fit. However, not only are such functional characteristics typically estimated with substantial variability, but also they may fail to distinguish between a number of stochastic processes &mdash; each making fundamentally different predictions for relevant quantities of scientific interest. In this talk, I will describe a detailed Bayesian analysis of leading candidate models for subdiffusive particle trajectories in human pulmonary mucus. Efficient and scalable computational strategies will be proposed. Model selection will be achieved by way of intrinsic Bayes factors, which avoid both non-informative priors and &ldquo;using the data twice&rdquo;. Goodness-of-fit will be evaluated via second-order criteria along with exact model residuals. Our findings suggest that a simple model of fractional Brownian motion describes the data just as well as a first-principles physical model of visco-elastic subdiffusion.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-02-20/" title="Comparison and assessment of particle diffusion models in biological fluids">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-02-13T00:00:00JST">Feb 13, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-02-13/">Tuning parameters in high-dimensional statistics</a></h2>
    <h3 class="post-meta">Johannes Lederer · Feb 13, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-02-13">Date: 2015-02-13</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>High-dimensional statistics is the basis for analyzing large and complex data sets that are generated by cutting-edge technologies in genetics, neuroscience, astronomy, and many other fields. However, Lasso, Ridge Regression, Graphical Lasso, and other standard methods in high-dimensional statistics depend on tuning parameters that are difficult to calibrate in practice. In this talk, I present two novel approaches to overcome this difficulty. My first approach is based on a novel testing scheme that is inspired by Lepski’s idea for bandwidth selection in non-parametric statistics. This approach provides tuning parameter calibration for estimation and prediction with the Lasso and other standard methods and is to date the only way to ensure high performance, fast computations, and optimal finite sample guarantees. My second approach is based on the minimization of an objective function that avoids tuning parameters altogether. This approach provides accurate variable selection in regression settings and, additionally, opens up new possibilities for the estimation of gene regulation networks, microbial ecosystems, and many other network structures.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-02-13/" title="Tuning parameters in high-dimensional statistics">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-02-05T00:00:00JST">Feb 5, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-02-05/">A fast unified algorithm for solving group Lasso penalized learning problems</a></h2>
    <h3 class="post-meta">Yi Yang · Feb 5, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-02-05">Date: 2015-02-05</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1b39">Location: BURN 1B39</h4>
<h2 id="abstract">Abstract:</h2>
<p>We consider a class of group-lasso learning problems where the objective function is the sum of an empirical loss and the group-lasso penalty. For a class of loss function satisfying a quadratic majorization condition, we derive a unified algorithm called groupwise-majorization-descent (GMD) for efficiently computing the solution paths of the corresponding group-lasso penalized learning problem. GMD allows for general design matrices, without requiring the predictors to be group-wise orthonormal. As illustration examples, we develop concrete algorithms for solving the group-lasso penalized least squares and several group-lasso penalized large margin classifiers. These group-lasso models have been implemented in an R package gglasso publicly available from the Comprehensive R Archive Network (CRAN) at <a href="http://cran.r-project.org/web/packages/gglasso">http://cran.r-project.org/web/packages/gglasso</a>. On simulated and real data, gglasso consistently outperforms the existing software for computing the group-lasso that implements either the classical groupwise descent algorithm or Nesterov&rsquo;s method. An application in risk segmentation of insurance business is illustrated by analysis of an auto insurance claim dataset.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-02-05/" title="A fast unified algorithm for solving group Lasso penalized learning problems">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-02-02T00:00:00JST">Feb 2, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-02-02/">Joint analysis of multiple multi-state processes via copulas</a></h2>
    <h3 class="post-meta">Liqun Diao · Feb 2, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-02-02">Date: 2015-02-02</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1214">Location: BURN 1214</h4>
<h2 id="abstract">Abstract:</h2>
<p>A copula-based model is described which enables joint analysis of multiple progressive multi-state processes. Unlike intensity-based or frailty-based approaches to joint modeling, the copula formulation proposed herein ensures that a wide range of marginal multi-state processes can be specified and the joint model will retain these marginal features. The copula formulation also facilitates a variety of approaches to estimation and inference including composite likelihood and two-stage estimation procedures. We consider processes with Markov margins in detail, which are often suitable when chronic diseases are progressive in nature. We give special attention to the setting in which individuals are examined intermittently and transition times are consequently interval-censored. Simulation studies give empirical insight into the different methods of analysis and an application involving progression in joint damage in psoriatic arthritis provides further illustration.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-02-02/" title="Joint analysis of multiple multi-state processes via copulas">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-30T00:00:00JST">Jan 30, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-01-30/">Distributed estimation and inference for sparse regression</a></h2>
    <h3 class="post-meta">Yuekai Sun · Jan 30, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-01-30">Date: 2015-01-30</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>We address two outstanding challenges in sparse regression: (i) computationally efficient estimation in distributed settings; (ii) valid inference for the selected coefficients. The main computational challenge in a distributed setting is harnessing the computational capabilities of all the machines while keeping communication costs low. We devise an approach that requires only a single round of communication among the machines. We show the approach recovers the convergence rate of the (centralized) lasso as long as each machine has access to an adequate number of samples. Turning to the second challenge, we devise an approach to post-selection inference by conditioning on the selected model. In a nutshell, our approach gives inferences with the same frequency interpretation as those given by data/sample splitting, but it is more broadly applicable and more powerful. The validity of our approach also does not depend on the correctness of the selected model, i.e., it gives valid inferences even when the selected model is incorrect.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-01-30/" title="Distributed estimation and inference for sparse regression">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-16T00:00:00JST">Jan 16, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-01-16/">Simultaneous white noise models and shrinkage recovery of functional data</a></h2>
    <h3 class="post-meta">Fang Yao · Jan 16, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-01-16">Date: 2015-01-16</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>We consider the white noise representation of functional data taken as i.i.d. realizations of a Gaussian process. The main idea is to establish an asymptotic equivalence in Le Cam’s sense between an experiment which simultaneously describes these realizations and a collection of white noise models. In this context, we project onto an arbitrary basis and apply a novel variant of Stein-type estimation for optimal recovery of the realized trajectories. A key inequality is derived showing that the corresponding risks, conditioned on the underlying curves, are minimax optimal and can be made arbitrarily close to those that an oracle with knowledge of the process would attain. Empirical performance is illustrated through simulated and real data examples.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-01-16/" title="Simultaneous white noise models and shrinkage recovery of functional data">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-15T00:00:00JST">Jan 15, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-01-15/">Functional data analysis and related topics</a></h2>
    <h3 class="post-meta">Fang Yao · Jan 15, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-01-15">Date: 2015-01-15</h4>
<h4 id="time-1600-1700">Time: 16:00-17:00</h4>
<h4 id="location-crm-1360-u-de-montréal">Location: CRM 1360 (U. de Montréal)</h4>
<h2 id="abstract">Abstract:</h2>
<p>Functional data analysis (FDA) has received substantial attention, with applications arising from various disciplines, such as engineering, public health, finance etc. In general, the FDA approaches focus on nonparametric underlying models that assume the data are observed from realizations of stochastic processes satisfying some regularity conditions, e.g., smoothness constraints. The estimation and inference procedures usually do not depend on merely a finite number of parameters, which contrasts with parametric models, and exploit techniques, such as smoothing methods and dimension reduction, that allow data to speak for themselves. In this talk, I will give an overview of FDA methods and related topics developed in recent years.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-01-15/" title="Functional data analysis and related topics">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-13T00:00:00JST">Jan 13, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-01-13/">Mixtures of coalesced generalized hyperbolic distributions</a></h2>
    <h3 class="post-meta">Ryan P. Browne · Jan 13, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-01-13">Date: 2015-01-13</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>A mixture of coalesced generalized hyperbolic distributions is developed by joining a finite mixture of generalized hyperbolic distributions with a mixture of multiple scaled generalized hyperbolic distributions. The result is a mixture of mixtures with shared model parameters and common mode. We begin by discussing the generalized hyperbolic distribution, which has the t, Gaussian and others as special cases. The generalized hyperbolic distribution can represented as a normal-variance mixture using a generalized inverse Gaussian distribution. This representation makes it a suitable candidate for the expectation-maximization algorithm. Secondly, we discuss the multiple scale generalized hyperbolic distribution which arises via implementation of a multi-dimensional weight function. A parameter estimation scheme is developed using the ever-expanding class of MM algorithms and the Bayesian information criterion is used for model selection. Special consideration is given to the contour shape. We use the coalesced distribution for clustering and compare them to finite mixtures of skew-t distributions using simulated and real data sets. Finally, the role of generalized hyperbolic mixtures within the wider model-based clustering, classification, and density estimation literature is discussed.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-01-13/" title="Mixtures of coalesced generalized hyperbolic distributions">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-01-09T00:00:00JST">Jan 9, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2015winter/2015-01-9/">Space-time data analysis: Out of the Hilbert box</a></h2>
    <h3 class="post-meta">James O. Ramsay · Jan 9, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-01-09">Date: 2015-01-09</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Given the discouraging state of current efforts to curb global warming, we can imagine that we will soon turn our attention to mitigation. On a global scale, distressed populations will turn to national and international organizations for solutions to dramatic problems caused by climate change. These institutions in turn will mandate the collection of data on a scale and resolution that will present extraordinary statistical and computational challenges to those of us viewed as having the appropriate expertise. A review of the current state of our space-time data analysis machinery suggests that we have much to do. Most of current spatial modelling methodology is based on concepts translated from time series analysis, is heavily dependent on various kinds of stationarity assumptions, uses the Gaussian distribution to model data and depends on a priori coordinate systems that do not exist in nature. A way forward from this restrictive framework is proposed by modelling data over textured domains using layered coordinate systems.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2015winter/2015-01-9/" title="Space-time data analysis: Out of the Hilbert box">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2014-12-12T00:00:00JST">Dec 12, 2014</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="http://localhost:4321/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="http://localhost:4321/post/2014fall/2014-12-12/">Testing for structured Normal means</a></h2>
    <h3 class="post-meta">James Sharpnack · Dec 12, 2014 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2014-12-12">Date: 2014-12-12</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>We will discuss the detection of pattern in images and graphs from a high-dimensional Gaussian measurement. This problem is relevant to many applications including detecting anomalies in sensor and computer networks, large-scale surveillance, co-expressions in gene networks, disease outbreaks, etc. Beyond its wide applicability, structured Normal means detection serves as a case study in the difficulty of balancing computational complexity with statistical power. We will begin by discussing the detection of active rectangles in images and sensor grids. We will develop an adaptive scan test and determine its asymptotic distribution. We propose an approximate algorithm that runs in nearly linear time but achieves the same asymptotic distribution as the naive, quadratic run-time algorithm. We will move on to the more general problem of detecting a well-connected active subgraph within a graph in the Normal means context. Because the generalized likelihood ratio test is computationally infeasible, we propose approximate algorithms and study their statistical efficiency. One such algorithm that we develop is the graph Fourier scan statistic, whose statistical performance is characterized by the spectrum of the graph Laplacian. Another relaxation that we have developed is the Lovasz extended scan statistic (LESS), which is based on submodular optimization and the performance is described using electrical network theory. We also introduce the spanning tree wavelet basis over graphs, a localized basis that reflects the topology of the graph. For each of these tests we compare their statistical guarantees to an information theoretic lower bound.</p></div>

  
  <footer>
    <a href="http://localhost:4321/post/2014fall/2014-12-12/" title="Testing for structured Normal means">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/post/page/21/">Previous</a></li>
    

    
    <li><a href="/post/page/23/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="http://localhost:4321/tags/2024-fall/" class="list-group-item"> · Nov 8, 2024</a>
      
      <a href="http://localhost:4321/post/2024fall/2024-11-08/" class="list-group-item">Christian Genest · Nov 8, 2024</a>
      
      <a href="http://localhost:4321/categories/" class="list-group-item"> · Nov 8, 2024</a>
      
      <a href="http://localhost:4321/categories/mcgill-statistics-seminar/" class="list-group-item"> · Nov 8, 2024</a>
      
      <a href="http://localhost:4321/tags/" class="list-group-item"> · Nov 8, 2024</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="http://localhost:4321/categories/mcgill-statistics-seminar" class="list-group-item">mcgill statistics seminar</a>
      
      <a href="http://localhost:4321/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc prize address</a>
      
      <a href="http://localhost:4321/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="http://localhost:4321/tags/2024-winter" class="list-group-item">2024 winter</a>
      
      <a href="http://localhost:4321/tags/2024-fall" class="list-group-item">2024 fall</a>
      
      <a href="http://localhost:4321/tags/2023-winter" class="list-group-item">2023 winter</a>
      
      <a href="http://localhost:4321/tags/2023-summer" class="list-group-item">2023 summer</a>
      
      <a href="http://localhost:4321/tags/2023-fall" class="list-group-item">2023 fall</a>
      
      <a href="http://localhost:4321/tags/2022-winter" class="list-group-item">2022 winter</a>
      
      <a href="http://localhost:4321/tags/2022-fall" class="list-group-item">2022 fall</a>
      
      <a href="http://localhost:4321/tags/2021-winter" class="list-group-item">2021 winter</a>
      
      <a href="http://localhost:4321/tags/2021-fall" class="list-group-item">2021 fall</a>
      
      <a href="http://localhost:4321/tags/2020-winter" class="list-group-item">2020 winter</a>
      
      <a href="http://localhost:4321/tags/2020-fall" class="list-group-item">2020 fall</a>
      
      <a href="http://localhost:4321/tags/2019-winter" class="list-group-item">2019 winter</a>
      
      <a href="http://localhost:4321/tags/2019-fall" class="list-group-item">2019 fall</a>
      
      <a href="http://localhost:4321/tags/2018-winter" class="list-group-item">2018 winter</a>
      
      <a href="http://localhost:4321/tags/2018-fall" class="list-group-item">2018 fall</a>
      
      <a href="http://localhost:4321/tags/2017-winter" class="list-group-item">2017 winter</a>
      
      <a href="http://localhost:4321/tags/2017-fall" class="list-group-item">2017 fall</a>
      
      <a href="http://localhost:4321/tags/2016-winter" class="list-group-item">2016 winter</a>
      
      <a href="http://localhost:4321/tags/2016-fall" class="list-group-item">2016 fall</a>
      
      <a href="http://localhost:4321/tags/2015-winter" class="list-group-item">2015 winter</a>
      
      <a href="http://localhost:4321/tags/2015-fall" class="list-group-item">2015 fall</a>
      
      <a href="http://localhost:4321/tags/2014-winter" class="list-group-item">2014 winter</a>
      
      <a href="http://localhost:4321/tags/2014-fall" class="list-group-item">2014 fall</a>
      
      <a href="http://localhost:4321/tags/2013-winter" class="list-group-item">2013 winter</a>
      
      <a href="http://localhost:4321/tags/2013-fall" class="list-group-item">2013 fall</a>
      
      <a href="http://localhost:4321/tags/2012-winter" class="list-group-item">2012 winter</a>
      
      <a href="http://localhost:4321/tags/2012-fall" class="list-group-item">2012 fall</a>
      
      <a href="http://localhost:4321/tags/2011-fall" class="list-group-item">2011 fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

