<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.36" />

<link rel="alternate" type="application/rss+xml" title="RSS" href="/post/index.xml">

<link rel="canonical" href="/post/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Past Seminar Series - McGill Statistics Seminars</title>
    
    <link href="/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Past Seminar Series</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-03-23T00:00:00JST">Mar 23, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-03-23/">Model selection principles in misspecified models</a></h2>
    <h3 class="post-meta">Jinchi Lv · Mar 23, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-03-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: Model selection is of fundamental importance to high-dimensional modeling featured in many contemporary applications. Classical principles of model selection include the Bayesian principle and the Kullback-Leibler divergence principle, which lead to the Bayesian information criterion and Akaike information criterion, respectively, when models are correctly specified. Yet model misspecification is unavoidable in practice. We derive novel asymptotic expansions of the two well-known principles in misspecified generalized linear models, which give the generalized BIC (GBIC) and generalized AIC.</div>

  
  <footer>
    <a href="/post/2012winter/2012-03-23/" title="Model selection principles in misspecified models">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-03-16T00:00:00JST">Mar 16, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-03-16/">Variable selection in longitudinal data with a change-point</a></h2>
    <h3 class="post-meta">Azadeh Shohoudi · Mar 16, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-03-16 Time: 15:30-16:30 Location: BURN 1205 Abstract: Follow-up studies are frequently carried out to investigate the evolution of measurements through time, taken on a set of subjects. These measurements (responses) are bound to be influenced by subject specific covariates and if a regression model is used the data analyst is faced with the problem of selecting those covariates that “best explain” the data. For example, in a clinical trial, subjects may be monitored for a response following the administration of a treatment with a view of selecting the covariates that are best predictive of a treatment response.</div>

  
  <footer>
    <a href="/post/2012winter/2012-03-16/" title="Variable selection in longitudinal data with a change-point">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-03-09T00:00:00JST">Mar 9, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-03-09/">Using tests of homoscedasticity to test missing completely at random | Hugh Chipman: Sequential optimization of a computer model and other Active Learning problems</a></h2>
    <h3 class="post-meta">Hugh Chipman and Mori Jamshidian · Mar 9, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-03-09 Time: 14:00-16:30 Location: UQAM, 201 ave. du Président-Kennedy, salle 5115 Abstract: Li: The problem of selecting the most useful features from a great many (eg, thousands) of candidates arises in many areas of modern sciences. An interesting problem from genomic research is that, from thousands of genes that are active (expressed) in certain tissue cells, we want to ﬁnd the genes that can be used to separate tissues of diﬀerent classes (eg.</div>

  
  <footer>
    <a href="/post/2012winter/2012-03-09/" title="Using tests of homoscedasticity to test missing completely at random | Hugh Chipman: Sequential optimization of a computer model and other Active Learning problems">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-03-02T00:00:00JST">Mar 2, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-03-02/">Estimating a variance-covariance surface for functional and longitudinal data</a></h2>
    <h3 class="post-meta">James O. Ramsay · Mar 2, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-03-02 Time: 15:30-16:30 Location: BURN 1205 Abstract: In functional data analysis, as in its multivariate counterpart, estimates of the bivariate covariance kernel σ(s,t ) and its inverse are useful for many things, and we need the inverse of a covariance matrix or kernel especially often. However, the dimensionality of functional observations often exceeds the sample size available to estimate σ(s,t, and then the analogue S of the multivariate sample estimate is singular and non-invertible.</div>

  
  <footer>
    <a href="/post/2012winter/2012-03-02/" title="Estimating a variance-covariance surface for functional and longitudinal data">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-02-17T00:00:00JST">Feb 17, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-02-17/">McGillivray: A penalized quasi-likelihood approach for estimating the number of states in a hidden Markov model | Best: Risk-set sampling and left truncation in survival analysis</a></h2>
    <h3 class="post-meta">Annaliza McGillivray and Ana Best · Feb 17, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-02-17 Time: 15:30-16:30 Location: BURN 1205 Abstract: McGillivray: In statistical applications of hidden Markov models (HMMs), one may have no knowledge of the number of hidden states (or order) of the model needed to be able to accurately represent the underlying process of the data. The problem of estimating the number of hidden states of the HMM is thus brought to the forefront. In this talk, we present a penalized quasi-likelihood approach for order estimation in HMMs which makes use of the fact that the marginal distribution of the observations from a HMM is a finite mixture model.</div>

  
  <footer>
    <a href="/post/2012winter/2012-02-17/" title="McGillivray: A penalized quasi-likelihood approach for estimating the number of states in a hidden Markov model | Best: Risk-set sampling and left truncation in survival analysis">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-02-10T00:00:00JST">Feb 10, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-02-10/">Stute: Principal component analysis of the Poisson Process | Blath: Longterm properties of the symbiotic branching model</a></h2>
    <h3 class="post-meta">Winfried Stute and Jochen Blath · Feb 10, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-02-10 Time: 14:00-16:30 Location: Concordia Abstract: Stute: The Poisson Process constitutes a well-known model for describing random events over time. It has many applications in marketing research, insurance mathematics and finance. Though it has been studied for decades not much is known how to check (in a non-asymptotic way) the validity of the Poisson Process. In this talk we present the principal component decomposition of the Poisson Process which enables us to derive finite sample properties of associated goodness-of-fit tests.</div>

  
  <footer>
    <a href="/post/2012winter/2012-02-10/" title="Stute: Principal component analysis of the Poisson Process | Blath: Longterm properties of the symbiotic branching model">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-02-03T00:00:00JST">Feb 3, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-02-03/">Du: Simultaneous fixed and random effects selection in finite mixtures of linear mixed-effects models | Harel: Measuring fatigue in systemic sclerosis: a comparison of the SF-36 vitality subscale and FACIT fatigue scale using item response theory</a></h2>
    <h3 class="post-meta">Yeting Du and Daphna Harel · Feb 3, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-02-03 Time: 15:30-16:30 Location: BURN 1205 Abstract: Du: Linear mixed-effects (LME) models are frequently used for modeling longitudinal data. One complicating factor in the analysis of such data is that samples are sometimes obtained from a population with significant underlying heterogeneity, which would be hard to capture by a single LME model. Such problems may be addressed by a finite mixture of linear mixed-effects (FMLME) models, which segments the population into subpopulations and models each subpopulation by a distinct LME model.</div>

  
  <footer>
    <a href="/post/2012winter/2012-02-03/" title="Du: Simultaneous fixed and random effects selection in finite mixtures of linear mixed-effects models | Harel: Measuring fatigue in systemic sclerosis: a comparison of the SF-36 vitality subscale and FACIT fatigue scale using item response theory">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-01-27T00:00:00JST">Jan 27, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-01-27/">Applying Kalman filtering to problems in causal inference</a></h2>
    <h3 class="post-meta">Sepideh Farsinezhad · Jan 27, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-01-27 Time: 15:30-16:30 Location: BURN 1205 Abstract: A common problem in observational studies is estimating the causal effect of time-varying treatment in the presence of a time varying confounder. When random assignment of subjects to comparison groups is not possible, time-varying confounders can cause bias in estimating causal effects even after standard regression adjustment if past treatment history is a predictor of future confounders. To eliminate the bias of standard methods for estimating the causal effect of time varying treatment, Robins developed a number of innovative methods for discrete treatment levels, including G-computation, G-estimation, and marginal structural models (MSMs).</div>

  
  <footer>
    <a href="/post/2012winter/2012-01-27/" title="Applying Kalman filtering to problems in causal inference">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-01-20T00:00:00JST">Jan 20, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-01-20/">A concave regularization technique for sparse mixture models</a></h2>
    <h3 class="post-meta">Martin Larsson · Jan 20, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-01-20 Time: 15:30-16:30 Location: BURN 1205 Abstract: Latent variable mixture models are a powerful tool for exploring the structure in large datasets. A common challenge for interpreting such models is a desire to impose sparsity, the natural assumption that each data point only contains few latent features. Since mixture distributions are constrained in their L1 norm, typical sparsity techniques based on L1 regularization become toothless, and concave regularization becomes necessary.</div>

  
  <footer>
    <a href="/post/2012winter/2012-01-20/" title="A concave regularization technique for sparse mixture models">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2012-01-13T00:00:00JST">Jan 13, 2012</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="/post/2012winter/2012-01-13/">Bayesian approaches to evidence synthesis in clinical practice guideline development</a></h2>
    <h3 class="post-meta">Yulei He · Jan 13, 2012 </h3>
  </header>

  
  <div class="summary">Date: 2012-01-13 Time: 15:30-16:30 Location: Concordia, Library Building LB-921.04 Abstract: The American College of Cardiology Foundation (ACCF) and the American Heart Association (AHA) have jointly engaged in the production of guideline in the area of cardiovascular disease since 1980. The developed guidelines are intended to assist health care providers in clinical decision making by describing a range of generally acceptable approaches for the diagnosis, management, or prevention of specific diseases or conditions.</div>

  
  <footer>
    <a href="/post/2012winter/2012-01-13/" title="Bayesian approaches to evidence synthesis in clinical practice guideline development">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/post/page/17/">Previous</a></li>
    

    
    <li><a href="/post/page/19/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="/post/2019winter/2019-01-25/" class="list-group-item">Ying Cui · Jan 25, 2019</a>
      
      <a href="/post/2019winter/2019-01-18/" class="list-group-item">Masoud Asgharian · Jan 18, 2019</a>
      
      <a href="/post/2019winter/2019-01-11/" class="list-group-item">Boxiang Wang · Jan 11, 2019</a>
      
      <a href="/post/2018fall/2018-11-23/" class="list-group-item">David Wolfson · Nov 23, 2018</a>
      
      <a href="/post/2018fall/2018-11-16/" class="list-group-item">James Hugh McVittie · Nov 16, 2018</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="/categories/mcgill-statistics-seminar" class="list-group-item">mcgill-statistics-seminar</a>
      
      <a href="/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc-prize-address</a>
      
      <a href="/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="/tags/2019-winter" class="list-group-item">2019-winter</a>
      
      <a href="/tags/2018-winter" class="list-group-item">2018-winter</a>
      
      <a href="/tags/2018-fall" class="list-group-item">2018-fall</a>
      
      <a href="/tags/2017-winter" class="list-group-item">2017-winter</a>
      
      <a href="/tags/2017-fall" class="list-group-item">2017-fall</a>
      
      <a href="/tags/2016-winter" class="list-group-item">2016-winter</a>
      
      <a href="/tags/2016-fall" class="list-group-item">2016-fall</a>
      
      <a href="/tags/2015-winter" class="list-group-item">2015-winter</a>
      
      <a href="/tags/2015-fall" class="list-group-item">2015-fall</a>
      
      <a href="/tags/2014-winter" class="list-group-item">2014-winter</a>
      
      <a href="/tags/2014-fall" class="list-group-item">2014-fall</a>
      
      <a href="/tags/2013-winter" class="list-group-item">2013-winter</a>
      
      <a href="/tags/2013-fall" class="list-group-item">2013-fall</a>
      
      <a href="/tags/2012-winter" class="list-group-item">2012-winter</a>
      
      <a href="/tags/2012-fall" class="list-group-item">2012-fall</a>
      
      <a href="/tags/2011-fall" class="list-group-item">2011-fall</a>
      
    </div>
  </section>
  

</aside>


  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

