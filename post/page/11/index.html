<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.139.4">

/post/index.xml

<link rel="canonical" href="https://mcgillstat.github.io/post/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Past Seminar Series - McGill Statistics Seminars</title>
    
    <link href="https://mcgillstat.github.io/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://mcgillstat.github.io/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Past Seminar Series</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-10-09T00:00:00JST">Oct 9, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020fall/2020-10-09/">Machine Learning and Neural Networks: Foundations and Some Fundamental Questions</a></h2>
    <h3 class="post-meta">Masoud Asgharian, Damoon Robatian and Zedian Xiao · Oct 9, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-10-09">Date: 2020-10-09</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="zoom-linkhttpsmcgillzoomusj92453904989pwdzdr6rumxtznyk0zime9obwtomgjqdz09"><a href="https://mcgill.zoom.us/j/92453904989?pwd=ZDR6RUMxTzNYK0ZiME9ObWtoMGJqdz09">Zoom Link</a></h4>
<h4 id="meeting-id-924-5390-4989">Meeting ID: 924 5390 4989</h4>
<h4 id="passcode-690084">Passcode: 690084</h4>
<h2 id="abstract">Abstract:</h2>
<p>Statistical learning theory is by now a mature branch of data science that hosts a vast variety of practical techniques for tackling data-related problems. In this talk we present some fundamental concepts upon which statistical learning theory has been based. Different approaches to statistical inference will be discussed and the main problem of learning from Vapnik&rsquo;s point of view will be explained. Further we discuss the topic of function estimation as the heart of Vapnik-Chervonenkis theory. There exist several state-of-the-art methods for estimating functional dependencies, such as maximum margin estimator and artificial neural networks. While for some of these methods, e.g., the support vector machines, there has already been developed a profound theory, others require more investigation. Accordingly, we pay a closer attention to the so-called mapping neural networks and try to shed some light on certain theoretical aspects of them. We highlight some of the fundamental challenges that have attracted the attention of researcher and they are yet to be fully resolved. One of these challenges is estimation of the intrinsic dimension of data that will be discussed in detail. Another challenge is inferring causal direction when the training data set is not representative of the target population.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020fall/2020-10-09/" title="Machine Learning and Neural Networks: Foundations and Some Fundamental Questions">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-10-02T00:00:00JST">Oct 2, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020fall/2020-10-02/">Data Science, Classification, Clustering and Three-Way Data</a></h2>
    <h3 class="post-meta">Paul McNicholas · Oct 2, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-10-02">Date: 2020-10-02</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="zoom-linkhttpsumontrealzoomusj93983313215pwdclb6cunssjavrmfmme1pblhktutsqt09"><a href="https://umontreal.zoom.us/j/93983313215?pwd=clB6cUNsSjAvRmFMME1PblhkTUtsQT09">Zoom Link</a></h4>
<h4 id="meeting-id-939-8331-3215">Meeting ID: 939 8331 3215</h4>
<h4 id="passcode-096952">Passcode: 096952</h4>
<h2 id="abstract">Abstract:</h2>
<p>Data science is discussed along with some historical perspective.  Selected problems in classification are considered, either via specific datasets or general problem types.  In each case, the problem is introduced before one or more potential solutions are discussed and applied.  The problems discussed include data with outliers, longitudinal data, and three-way data.  The proposed approaches are generally mixture model-based.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020fall/2020-10-02/" title="Data Science, Classification, Clustering and Three-Way Data">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-09-25T00:00:00JST">Sep 25, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020fall/2020-09-25/">Large-scale Network Inference</a></h2>
    <h3 class="post-meta">Yingying Fan · Sep 25, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-09-25">Date: 2020-09-25</h4>
<h4 id="time-1400-1500">Time: 14:00-15:00</h4>
<h4 id="zoom-linkhttpsmcgillzoomusj93947077997"><a href="https://mcgill.zoom.us/j/93947077997">Zoom Link</a></h4>
<h4 id="meeting-id-939-4707-7997">Meeting ID: 939 4707 7997</h4>
<h4 id="passcode-no-password">Passcode: no password</h4>
<h2 id="abstract">Abstract:</h2>
<p>Network data is prevalent in many contemporary big data applications in which a common interest is to unveil important latent links between different pairs of nodes. Yet a simple fundamental question of how to precisely quantify the statistical uncertainty associated with the identification of latent links still remains largely unexplored. In this paper, we propose the method of statistical inference on membership profiles in large networks (SIMPLE) in the setting of degree-corrected mixed membership model, where the null hypothesis assumes that the pair of nodes share the same profile of community memberships. In the simpler case of no degree heterogeneity, the model reduces to the mixed membership model for which an alternative more robust test is also proposed. Both tests are of the Hotelling-type statistics based on the rows of empirical eigenvectors or their ratios, whose asymptotic covariance matrices are very challenging to derive and estimate. Nevertheless, their analytical expressions are unveiled and the unknown covariance matrices are consistently estimated. Under some mild regularity conditions, we establish the exact limiting distributions of the two forms of SIMPLE test statistics under the null hypothesis and contiguous alternative hypothesis. They are the chi-square distributions and the noncentral chi-square distributions, respectively, with degrees of freedom depending on whether the degrees are corrected or not. We also address the important issue of estimating the unknown number of communities and establish the asymptotic properties of the associated test statistics. The advantages and practical utility of our new procedures in terms of both size and power are demonstrated through several simulation examples and real network applications.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020fall/2020-09-25/" title="Large-scale Network Inference">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-09-18T00:00:00JST">Sep 18, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020fall/2020-09-18/">BdryGP: a boundary-integrated Gaussian process model for computer code emulation</a></h2>
    <h3 class="post-meta">Simon Mak · Sep 18, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-09-18">Date: 2020-09-18</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="zoom-linkhttpsmcgillzoomusj92453904989pwdzdr6rumxtznyk0zime9obwtomgjqdz09"><a href="https://mcgill.zoom.us/j/92453904989?pwd=ZDR6RUMxTzNYK0ZiME9ObWtoMGJqdz09">Zoom Link</a></h4>
<h4 id="meeting-id-924-5390-4989">Meeting ID: 924 5390 4989</h4>
<h4 id="passcode-690084">Passcode: 690084</h4>
<h2 id="abstract">Abstract:</h2>
<p>With advances in mathematical modeling and computational methods, complex phenomena (e.g., universe formations, rocket propulsion) can now be reliably simulated via computer code. This code solves a complicated system of equations representing the underlying science of the problem. Such simulations can be very time-intensive, requiring months of computation for a single run. Gaussian processes (GPs) are widely used as predictive models for “emulating” this expensive computer code. Yet with limited training data on a high-dimensional parameter space, such models can suffer from poor predictive performance and physical interpretability.
Fortunately, in many physical applications, there is additional boundary information on the code beforehand, either from governing physics or scientific knowledge. We propose a new BdryGP model which incorporates such boundary information for prediction. We show that BdryGP not only enjoys improved convergence rates over standard GP models which do not incorporate boundaries, but is also more resistant to the ``curse-of-dimensionality&rsquo;&rsquo; in nonparametric regression. We then demonstrate the improved predictive performance and posterior contraction of the BdryGP model on several test problems in the literature.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020fall/2020-09-18/" title="BdryGP: a boundary-integrated Gaussian process model for computer code emulation">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-09-11T00:00:00JST">Sep 11, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020fall/2020-09-11/">Machine Learning for Causal Inference</a></h2>
    <h3 class="post-meta">Stefan Wager · Sep 11, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-09-11">Date: 2020-09-11</h4>
<h4 id="time-1600-1700">Time: 16:00-17:00</h4>
<h4 id="zoom-linkhttpsumontrealzoomusj96525367383pwddzburjbvc2fwtgpyruh4aurbz0rvqt09"><a href="https://umontreal.zoom.us/j/96525367383?pwd=dzBURjBvc2FWTGpyRUh4aURBZ0RvQT09">Zoom Link</a></h4>
<h4 id="meeting-id-965-2536-7383">Meeting ID: 965 2536 7383</h4>
<h4 id="passcode-421254">Passcode: 421254</h4>
<h2 id="abstract">Abstract:</h2>
<p>Given advances in machine learning over the past decades, it is now possible to accurately solve difficult non-parametric prediction problems in a way that is routine and reproducible. In this talk, I’ll discuss how machine learning tools can be rigorously integrated into observational study analyses, and how they interact with classical statistical ideas around randomization, semiparametric modeling, double robustness, etc. I’ll also survey some recent advances in methods for treatment heterogeneity. When deployed carefully, machine learning enables us to develop causal estimators that reflect an observational study design more closely than basic linear regression based methods.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020fall/2020-09-11/" title="Machine Learning for Causal Inference">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-03-27T00:00:00JST">Mar 27, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020winter/2020-03-27/">A gentle introduction to generalized structured component analysis and its recent developments</a></h2>
    <h3 class="post-meta">Heungsun Hwang · Mar 27, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-03-27">Date: 2020-03-27</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burnside-1205">Location: BURNSIDE 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Generalized structured component analysis (GSCA) was developed as a component-based approach to structural equation modeling, where constructs are represented by components or weighted composites of observed variables, rather than (common) factors. Unlike another long-lasting component-based approach – partial least squares path modeling, GSCA is a full-information method that optimizes a single criterion to estimate model parameters simultaneously, utilizing all information available in the entire system of equations. Over the decade, this approach has been refined and extended in various ways to enhance its data-analytic capability. I will briefly discuss the theoretical underpinnings of GSCA and demonstrate the use of an R package for GSCA - gesca. Moreover, I will outline some recent developments in GSCA, which include GSCA_M for estimating models with factors and integrated GSCA (IGSCA) for estimating models with both factors and components.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020winter/2020-03-27/" title="A gentle introduction to generalized structured component analysis and its recent developments">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-03-20T00:00:00JST">Mar 20, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020winter/2020-03-20/">Informative Prior Elicitation from Historical Individual Patient Data</a></h2>
    <h3 class="post-meta">Shirin Golchi · Mar 20, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-03-20">Date: 2020-03-20</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burnside-1205">Location: BURNSIDE 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Historical data from previous studies may be utilized to strengthen statistical inference. Under the Bayesian framework incorporation of information obtained from any source other than the current data is facilitated through construction of an informative prior. The existing methodology for defining an informative prior based on historical data relies on measuring similarity to the current data at the study level that can result in discarding useful individual patient data (IPD). In this talk I present a family of priors that utilize IPD to strengthen statistical inference. IPD-based priors can be obtained as a weighted likelihood of the historical data where each individual&rsquo;s weight is a function of their distance to the current study population. It is demonstrated that the proposed prior construction approach can considerably improve estimation accuracy and precision in compare with existing methods.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020winter/2020-03-20/" title="Informative Prior Elicitation from Historical Individual Patient Data">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-03-13T00:00:00JST">Mar 13, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020winter/2020-03-13/">Geometry-based Data Exploration</a></h2>
    <h3 class="post-meta">Wolf Guy · Mar 13, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-03-13">Date: 2020-03-13</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burnside-1205">Location: BURNSIDE 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>High-throughput data collection technologies are becoming increasingly common in many fields, especially in biomedical applications involving single cell data (e.g., scRNA-seq and CyTOF). These introduce a rising need for exploratory analysis to reveal and understand hidden structure in the collected (high-dimensional) Big Data. A crucial aspect in such analysis is the separation of intrinsic data geometry from data distribution, as (a) the latter is typically biased by collection artifacts and data availability, and (b) rare subpopulations and sparse transitions between meta-stable states are often of great interest in biomedical data analysis. In this talk, I will show several tools that leverage manifold learning, graph signal processing, and harmonic analysis for biomedical (in particular, genomic/proteomic) data exploration, with emphasis on visualization, data generation/augmentation, and nonlinear feature extraction. A common thread in the presented tools is the construction of a data-driven diffusion geometry that both captures intrinsic structure in data and provides a generalization of Fourier harmonics on it. These, in turn, are used to process data features along the data geometry for denoising and generative purposes. Finally, I will relate this approach to the recently-proposed geometric scattering transform that generalizes Mallat&rsquo;s scattering to non-Euclidean domains, and provides a mathematical framework for theoretical understanding of the emerging field of geometric deep learning.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020winter/2020-03-13/" title="Geometry-based Data Exploration">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-02-28T00:00:00JST">Feb 28, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020winter/2020-02-28/">Neyman-Pearson classification: parametrics and sample size requirement</a></h2>
    <h3 class="post-meta">Yang Feng · Feb 28, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-02-28">Date: 2020-02-28</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burnside-1104">Location: BURNSIDE 1104</h4>
<h2 id="abstract">Abstract:</h2>
<p>The Neyman-Pearson (NP) paradigm in binary classification seeks classifiers that achieve a minimal type II error while enforcing the prioritized type I error controlled under some user-specified level alpha. This paradigm serves naturally in applications such as severe disease diagnosis and spam detection, where people have clear priorities among the two error types. Recently, Tong, Feng and Li (2018) proposed a nonparametric umbrella algorithm that adapts all scoring-type classification methods (e.g., logistic regression, support vector machines, random forest) to respect the given type I error (i.e., conditional probability of classifying a class 0 observation as class 1 under the 0-1 coding) upper bound alpha with high probability, without specific distributional assumptions on the features and the responses. Universal the umbrella algorithm is, it demands an explicit minimum sample size requirement on class 0, which is often the more scarce class, such as in rare disease diagnosis applications. In this work, we employ the parametric linear discriminant analysis (LDA) model and propose a new parametric thresholding algorithm, which does not need the minimum sample size requirements on class 0 observations and thus is suitable for small sample applications such as rare disease diagnosis. Leveraging both the existing nonparametric and the newly proposed parametric thresholding rules, we propose four LDA-based NP classifiers, for both low- and high-dimensional settings. On the theoretical front, we prove NP oracle inequalities for one proposed classifier, where the rate for excess type II error benefits from the explicit parametric model assumption. Furthermore, as NP classifiers involve a sample splitting step of class 0 observations,  we construct a new adaptive sample splitting scheme that can be applied universally to NP classifiers, and this adaptive strategy reduces the type II error of these classifiers. The proposed NP classifiers are implemented in the R package nproc.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020winter/2020-02-28/" title="Neyman-Pearson classification: parametrics and sample size requirement">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2020-02-21T00:00:00JST">Feb 21, 2020</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2020winter/2020-02-21/">Non-central squared copulas: properties and applications</a></h2>
    <h3 class="post-meta">Bouchra Nasri · Feb 21, 2020 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2020-02-21">Date: 2020-02-21</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burnside-1205">Location: BURNSIDE 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>The goal of this presentation is to introduce new families of multivariate copulas, extending the chi-square copulas, the Fisher copula, and squared copulas. The new families are constructed from existing copulas by first transforming their margins to standard Gaussian distributions, then transforming these variables into non-central chi-square variables with one degree of freedom, and finally by considering the copula associated with these new variables. It is shown that by varying the non-centrality parameters, one can model non-monotonic dependence, and when one or many non-centrality parameters are outside a given hyper-rectangle, then the copula is almost the same as the one when these parameters are infinite. For these new families, the tail behavior, the monotonicity of dependence measures such as Kendall’s tau and Spearman’s rho are investigated, and estimation is discussed. Some examples will illustrate the usefulness of these new copula families.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2020winter/2020-02-21/" title="Non-central squared copulas: properties and applications">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/post/page/10/">Previous</a></li>
    

    
    <li><a href="/post/page/12/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-fall/" class="list-group-item"> · Nov 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/" class="list-group-item"> · Nov 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/post/2025fall/2025-11-28/" class="list-group-item">Li-Hsiang Lin · Nov 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar/" class="list-group-item"> · Nov 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/tags/" class="list-group-item"> · Nov 28, 2025</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar" class="list-group-item">mcgill statistics seminar</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc prize address</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-winter" class="list-group-item">2025 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2025-fall" class="list-group-item">2025 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-winter" class="list-group-item">2024 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-fall" class="list-group-item">2024 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-winter" class="list-group-item">2023 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-summer" class="list-group-item">2023 summer</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-fall" class="list-group-item">2023 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-winter" class="list-group-item">2022 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-fall" class="list-group-item">2022 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-winter" class="list-group-item">2021 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-fall" class="list-group-item">2021 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-winter" class="list-group-item">2020 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-fall" class="list-group-item">2020 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-winter" class="list-group-item">2019 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-fall" class="list-group-item">2019 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-winter" class="list-group-item">2018 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-fall" class="list-group-item">2018 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-winter" class="list-group-item">2017 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-fall" class="list-group-item">2017 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-winter" class="list-group-item">2016 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-fall" class="list-group-item">2016 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-winter" class="list-group-item">2015 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-fall" class="list-group-item">2015 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-winter" class="list-group-item">2014 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-fall" class="list-group-item">2014 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-winter" class="list-group-item">2013 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-fall" class="list-group-item">2013 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-winter" class="list-group-item">2012 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-fall" class="list-group-item">2012 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2011-fall" class="list-group-item">2011 fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

