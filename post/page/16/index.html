<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.136.5">

/post/index.xml

<link rel="canonical" href="https://mcgillstat.github.io/post/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Past Seminar Series - McGill Statistics Seminars</title>
    
    <link href="https://mcgillstat.github.io/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://mcgillstat.github.io/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Past Seminar Series</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-01-26T00:00:00JST">Jan 26, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2018winter/2018-01-26/">Back to the future: why I think REGRESSION is the new black in genetic association studies</a></h2>
    <h3 class="post-meta">Lei Sun · Jan 26, 2018 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2018-01-26">Date: 2018-01-26</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-room-6254-pavillon-andre-aisenstadt-2920-udem">Location: ROOM 6254 Pavillon Andre-Aisenstadt 2920, UdeM</h4>
<h2 id="abstract">Abstract:</h2>
<p>Linear regression remains an important framework in the era of big and complex data. In this talk I present some recent examples where we resort to the classical simple linear regression model and its celebrated extensions in novel settings. The Eureka moment came while reading Wu and Guan&rsquo;s (2015) comments on our generalized Kruskal-Wallis (GKW) test (Elif Acar and Sun 2013, Biometrics). Wu and Guan presented an alternative “rank linear regression model and derived the proposed GKW statistic as a score test statistic&quot;, and astutely pointed out that “the linear model approach makes the derivation more straightforward and transparent, and leads to a simplified and unified approach to the general rank based multi-group comparison problem.&quot; More recently, we turned our attention to extending Levene&rsquo;s variance test for data with group uncertainty and sample correlation. While a direct modification of the original statistic is indeed challenging, I will demonstrate that a two-stage regression framework makes the ensuing development quite straightforward, eventually leading to a generalized joint location-scale test (David Soave and Sun 2017, Biometrics). Finally, I will discuss on-going work, with graduate student Lin Zhang, on developing an allele-based association test that is robust to the assumption of Hardy-Weinberg equilibrium and is generalizable to complex data structure. The crux of this work is, again, reformulating the problem as a regression!</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2018winter/2018-01-26/" title="Back to the future: why I think REGRESSION is the new black in genetic association studies">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-01-19T00:00:00JST">Jan 19, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2018winter/2018-01-19/">Generalized Sparse Additive Models</a></h2>
    <h3 class="post-meta">Asad Haris · Jan 19, 2018 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2018-01-19">Date: 2018-01-19</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>I will present a unified approach to the estimation of generalized sparse additive models in high dimensional regression problems. Our approach is based on combining structure-inducing and sparsity penalties in a single regression problem. It allows for the use of a large family of structure-inducing penalties: Those characterized by semi-norm constraints. This includes finite dimensional linear subspaces, sobolev and holder classes, classes with bounded total variation, among others. We give an efficient computational algorithm to fit this family of models that easily scales to thousands of observations and features. In addition we develop a framework for proving convergence bounds on these estimators; and show that our estimators converge at the minimax optimal rate under suitable conditions. We also compare the performance of existing methods in an empirical study and discuss directions for future work.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2018winter/2018-01-19/" title="Generalized Sparse Additive Models">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2018-01-12T00:00:00JST">Jan 12, 2018</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2018winter/2018-01-12/">Modelling RNA stability for decoding the regulatory programs that drive human diseases</a></h2>
    <h3 class="post-meta">Hamed Najafabadi · Jan 12, 2018 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2018-01-12">Date: 2018-01-12</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>The key determinant of the identity and behaviour of the cell is gene regulation, i.e. which genes are active and which genes are inactive in a particular cell. One of the least understood aspects of gene regulation is RNA stability: genes produce RNA molecules to carry their genetic information – the more stable these RNA molecules are, the longer they can function within the cell, and the less stable they are, the more rapidly they are removed from the pool of active molecules. The cell can effectively switch the genes on and off by regulating RNA stability. However, we do not know which genes are regulated at the RNA stability level, and what factors affect their stability. The focus of our research is development of novel computational methods that enables the measurement of RNA stability and decay rate from functional genomics data, and inference of models that explain how human cells regulate RNA stability. We are particularly interested in how defects in regulation of RNA stability can lead to development and progression of various human diseases, such as cancer.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2018winter/2018-01-12/" title="Modelling RNA stability for decoding the regulatory programs that drive human diseases">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-12-01T00:00:00JST">Dec 1, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-12-01/">Fisher’s method revisited: set-based genetic association and interaction studies</a></h2>
    <h3 class="post-meta">Lei Sun · Dec 1, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-12-01">Date: 2017-12-01</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Fisher’s method, also known as Fisher’s combined probability test, is commonly used in meta-analyses to combine p-values from the same test applied to K independent samples to evaluate a common null hypothesis. Here we propose to use it to combine p-values from different tests applied to the same sample in two settings: when jointly analyzing multiple genetic variants in set-based genetic association studies, or when jointly capturing main and interaction effects in the presence of missing one of the interacting variables. In the first setting, we show that many existing methods (e.g. the so called burden test and SKAT) can be classified into a class of linear statistics and another class of quadratic statistics, where each class is powerful only in part of the high-dimensional parameter space. In the second setting, we show that the class of scale-tests for heteroscedasticity can be utilized to indirectly identify unspecified interaction effects, complementing the class of location-tests designed for detecting main effects only. In both settings, we show that the two classes of tests are asymptotically independent of each other under the global null hypothesis. Thus, we can evaluate the significance of the resulting Fisher’s test statistic using the chi-squared distribution with four degrees of freedom; this is a desirable feature for analyzing big data. In addition to analytical results, we provide empirical evidence to show that the new class of joint test is not only robust but can also have better power than the individual tests. This is based on join work with formal graduate students Andriy Derkach (Derkach et al. 2013, Genetic Epidemiology; Derkach et al. 2014, Statistical Science) and David Soave (Soave et al. 2015, The American Journal of Human Genetics; Soave and Sun 2017, Biometrics).</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017fall/2017-12-01/" title="Fisher’s method revisited: set-based genetic association and interaction studies">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-11-24T00:00:00JST">Nov 24, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-11-24/">150 years (and more) of data analysis in Canada</a></h2>
    <h3 class="post-meta">David R. Bellhouse · Nov 24, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-11-24">Date: 2017-11-24</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-lea-232">Location: LEA 232</h4>
<h2 id="abstract">Abstract:</h2>
<p>As Canada celebrates its 150th anniversary, it may be good to reflect on the past and future of data analysis and statistics in this country. In this talk, I will review the Victorian Statistics Movement and its effect in Canada, data analysis by a Montréal physician in the 1850s, a controversy over data analysis in the 1850s and 60s centred in Montréal, John A. MacDonald’s use of statistics, the Canadian insurance industry and the use of statistics, the beginning of mathematical statistics in Canada, the Fisherian revolution, the influence of Fisher, Neyman and Pearson, the computer revolution, and the emergence of data science.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017fall/2017-11-24/" title="150 years (and more) of data analysis in Canada">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-11-17T00:00:00JST">Nov 17, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-11-17/">A log-linear time algorithm for constrained changepoint detection</a></h2>
    <h3 class="post-meta">Toby Hocking · Nov 17, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-11-17">Date: 2017-11-17</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Changepoint detection is a central problem in time series and genomic data. For some applications, it is natural to impose constraints on the directions of changes. One example is ChIP-seq data, for which adding an up-down constraint improves peak detection accuracy, but makes the optimization problem more complicated. In this talk I will explain how a recently proposed functional pruning algorithm can be generalized to solve such constrained changepoint detection problems. Our proposed log-linear time algorithm achieves state-of-the-art peak detection accuracy in a benchmark of several genomic data sets, and is orders of magnitude faster than our previous quadratic time algorithm. Our implementation is available as the PeakSegPDPA function in the PeakSegOptimal R package, <a href="https://cran.r-project.org/package=PeakSegOptimal">https://cran.r-project.org/package=PeakSegOptimal</a></p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017fall/2017-11-17/" title="A log-linear time algorithm for constrained changepoint detection">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-11-10T00:00:00JST">Nov 10, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-11-10/">PAC-Bayesian Generalizations Bounds for Deep Neural Networks</a></h2>
    <h3 class="post-meta">Daniel Roy · Nov 10, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-11-10">Date: 2017-11-10</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>One of the defining properties of deep learning is that models are chosen to have many more parameters than available training data. In light of this capacity for overfitting, it is remarkable that simple algorithms like SGD reliably return solutions with low test error. One roadblock to explaining these phenomena in terms of implicit regularization, structural properties of the solution, and/or easiness of the data is that many learning bounds are quantitatively vacuous when applied to networks learned by SGD in this &ldquo;deep learning&rdquo; regime. Logically, in order to explain generalization, we need nonvacuous bounds. We return to an idea by Langford and Caruana (2001), who used PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization error for stochastic two-layer two-hidden-unit neural networks via a sensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples. We connect our findings to recent and old work on flat minima and MDL-based explanations of generalization. Time permitting, I will discuss recent work on computing even tighter generalization bounds associated with a learning algorithm introduced by Chaudhari et al. (2017), called Entropy-SGD. We show that Entropy-SGD indirectly optimizes a PAC-Bayes bound, but does so by optimizing the &ldquo;prior&rdquo; term, violating the hypothesis that the prior be independent of the data. We show how to fix this defect using differential privacy. The result is a new PAC-Bayes bound for data-dependent priors, which we show, up to some approximations, delivers even tighter generalization bounds. Joint work with Gintare Karolina Dziugaite, based on <a href="https://arxiv.org/abs/1703.11008">https://arxiv.org/abs/1703.11008</a></p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017fall/2017-11-10/" title="PAC-Bayesian Generalizations Bounds for Deep Neural Networks">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-11-03T00:00:00JST">Nov 3, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-11-03/">How to do statistics</a></h2>
    <h3 class="post-meta">Daniel Simpson · Nov 3, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-11-03">Date: 2017-11-03</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>In this talk, I will outline how to do (Bayesian) statistics. I will focus particularly on the things that need to be done before you see data, including prior specification and checking that your inference algorithm actually works.</p>
<h2 id="speaker">Speaker</h2>
<p>Daniel Simpson is an Assistant Professor in the Department of Statistical Sciences, University of Toronto</p></div>

  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-10-27T00:00:00JST">Oct 27, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-10-27/">Penalized robust regression estimation with applications to proteomics</a></h2>
    <h3 class="post-meta">Gabriela V. Cohen Freue · Oct 27, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-10-27">Date: 2017-10-27</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>In many current applications, scientists can easily measure a very large number of variables (for example, hundreds of protein levels), some of which are expected be useful to explain or predict a specific response variable of interest. These potential explanatory variables are most likely to contain redundant or irrelevant information, and in many cases, their quality and reliability may be suspect. We developed two penalized robust regression estimators that can be used to identify a useful subset of explanatory variables to predict the response, while protecting the resulting estimator against possible aberrant observations in the data set. Using an elastic net penalty, the proposed estimator can be used to select variables, even in cases with more variables than observations or when many of the candidate explanatory variables are correlated. In this talk, I will present the new estimator and an algorithm to compute it. I will also illustrate its performance in a simulation study and a real data set. This is joint work with Professor Matias Salibian-Barrera, my PhD student David Kepplinger, and my PDF Ezequiel Smuggler.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017fall/2017-10-27/" title="Penalized robust regression estimation with applications to proteomics">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2017-10-20T00:00:00JST">Oct 20, 2017</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2017fall/2017-10-20/">Statistical optimization and nonasymptotic robustness</a></h2>
    <h3 class="post-meta">Qiang Sun · Oct 20, 2017 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2017-10-20">Date: 2017-10-20</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Statistical optimization has generated quite some interest recently. It refers to the case where hidden and local convexity can be discovered in most cases for nonconvex problems, making polynomial algorithms possible. It relies on a careful analysis of the geometry near global optima. In this talk, I will explore this issue by focusing on sparse regression problems in high dimensions. A computational framework named iterative local adaptive majorize-minimization (I-LAMM) will be proposed to simultaneously control algorithmic complexity and statistical error. I-LAMM effectively turns the nonconvex penalized regression problem into a series of convex programs by utilizing the locally strong convexity of the problem when restricting the solution set in an L_1 cone. Computationally, we establish a phase transition phenomenon: it enjoys a linear rate of convergence after a sub-linear burn-in. Statistically, it provides solutions with optimal statistical errors. Extensions to robust regression will be discussed.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2017fall/2017-10-20/" title="Statistical optimization and nonasymptotic robustness">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/post/page/15/">Previous</a></li>
    

    
    <li><a href="/post/page/17/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-winter/" class="list-group-item"> · Mar 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/" class="list-group-item"> · Mar 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/post/2025winter/2025-03-28/" class="list-group-item">Éric Marchand · Mar 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar/" class="list-group-item"> · Mar 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/tags/" class="list-group-item"> · Mar 28, 2025</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar" class="list-group-item">mcgill statistics seminar</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc prize address</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-winter" class="list-group-item">2025 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-winter" class="list-group-item">2024 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-fall" class="list-group-item">2024 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-winter" class="list-group-item">2023 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-summer" class="list-group-item">2023 summer</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-fall" class="list-group-item">2023 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-winter" class="list-group-item">2022 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-fall" class="list-group-item">2022 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-winter" class="list-group-item">2021 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-fall" class="list-group-item">2021 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-winter" class="list-group-item">2020 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-fall" class="list-group-item">2020 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-winter" class="list-group-item">2019 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-fall" class="list-group-item">2019 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-winter" class="list-group-item">2018 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-fall" class="list-group-item">2018 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-winter" class="list-group-item">2017 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-fall" class="list-group-item">2017 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-winter" class="list-group-item">2016 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-fall" class="list-group-item">2016 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-winter" class="list-group-item">2015 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-fall" class="list-group-item">2015 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-winter" class="list-group-item">2014 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-fall" class="list-group-item">2014 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-winter" class="list-group-item">2013 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-fall" class="list-group-item">2013 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-winter" class="list-group-item">2012 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-fall" class="list-group-item">2012 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2011-fall" class="list-group-item">2011 fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

