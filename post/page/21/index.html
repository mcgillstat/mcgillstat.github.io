<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<meta name="generator" content="Hugo 0.136.5">

/post/index.xml

<link rel="canonical" href="https://mcgillstat.github.io/post/">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>Past Seminar Series - McGill Statistics Seminars</title>
    
    <link href="https://mcgillstat.github.io/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://mcgillstat.github.io/">McGill Statistics Seminars</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/">Current Seminar Series</a></li>
              
              
              
              <li><a href="/post/">Past Seminar Series</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    
    <header class="page-header">
      <h1>Past Seminar Series</h1>
    </header>
    

    <ul class="p-articles">
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2016-01-22T00:00:00JST">Jan 22, 2016</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2016winter/2016-01-22/">Robust estimation in the presence of influential units in surveys</a></h2>
    <h3 class="post-meta">David Haziza · Jan 22, 2016 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2016-01-22">Date: 2016-01-22</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Influential units are those which make classical estimators (e.g., the Horvitz-Thompson estimator or calibration estimators) very unstable. The problem of influential units is particularly important in business surveys, which collect economic variables, whose distribution are highly skewed (heavy right tail). In this talk, we will attempt to answer the following questions:</p>
<p>(1)   What is an influential value in surveys?
(2)   How measure the influence of unit?
(3)   How reduce the impact of influential units at the estimation stage?</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2016winter/2016-01-22/" title="Robust estimation in the presence of influential units in surveys">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-12-10T00:00:00JST">Dec 10, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-12-10/">Causal discovery with confidence using invariance principles</a></h2>
    <h3 class="post-meta">Nicolai Meinshausen · Dec 10, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-12-10">Date: 2015-12-10</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-udem-pav-roger-gaudry-salle-s-116">Location: UdeM, Pav. Roger-Gaudry, salle S-116</h4>
<h2 id="abstract">Abstract:</h2>
<p>What is interesting about causal inference? One of the most compelling aspects is that any prediction under a causal model is valid in environments that are possibly very different to the environment used for inference. For example, variables can be actively changed and predictions will still be valid and useful. This invariance is very useful but still leaves open the difficult question of inference. We propose to turn this invariance principle around and exploit the invariance for inference. If we observe a system in different environments (or under different but possibly not well specified interventions) we can identify all models that are invariant. We know that any causal model has to be in this subset of invariant models. This allows causal inference with valid confidence intervals. We propose different estimators, depending on the nature of the interventions and depending on whether hidden variables and feedbacks are present. Some empirical examples demonstrate the power and possible pitfalls of this approach.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-12-10/" title="Causal discovery with confidence using invariance principles">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-11-26T00:00:00JST">Nov 26, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-11-26/">Inference regarding within-family association in disease onset times under biased sampling schemes</a></h2>
    <h3 class="post-meta">Richard J. Cook · Nov 26, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-11-26">Date: 2015-11-26</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-306">Location: BURN 306</h4>
<h2 id="abstract">Abstract:</h2>
<p>In preliminary studies of the genetic basis for chronic conditions, interest routinely lies in the within-family dependence in disease status. When probands are selected from disease registries and their respective families are recruited, a variety of ascertainment bias-corrected methods of inference are available which are typically based on models for correlated binary data. This approach ignores the age that family members are at the time of assessment. We consider copula-based models for assessing the within-family dependence in the disease onset time and disease progression, based on right-censored and current status observation of the non-probands. Inferences based on likelihood, composite likelihood and estimating functions are each discussed and compared in terms of asymptotic and empirical  relative efficiency. This is joint work with Yujie Zhong.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-11-26/" title="Inference regarding within-family association in disease onset times under biased sampling schemes">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-11-13T00:00:00JST">Nov 13, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-11-13/">Prevalent cohort studies: Length-biased sampling with right censoring</a></h2>
    <h3 class="post-meta">Masoud Asgharian · Nov 13, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-11-13">Date: 2015-11-13</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Logistic or other constraints often preclude the possibility of conducting incident cohort studies. A feasible alternative in such cases is to conduct a cross-sectional prevalent cohort study for which we recruit prevalent cases, i.e., subjects who have already experienced the initiating event, say the onset of a disease. When the interest lies in estimating the lifespan between the initiating event and a terminating event, say death for instance, such subjects may be followed prospectively until the terminating event or loss to follow-up, whichever happens first. It is well known that prevalent cases have, on average, longer lifespans. As such, they do not form a representative random sample from the target population; they comprise a biased sample. If the initiating events are generated from a stationary Poisson process, the so-called stationarity assumption, this bias is called length bias. I present the basics of nonparametric inference using length-biased right censored failure time data. I&rsquo;ll then discuss some recent progress and current challenges. Our study is mainly motivated by challenges and questions raised in analyzing survival data collected on patients with dementia as part of a nationwide study in Canada, called the Canadian Study of Health and Aging (CSHA). I&rsquo;ll use these data throughout the talk to discuss and motivate our methodology and its applications.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-11-13/" title="Prevalent cohort studies: Length-biased sampling with right censoring">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-11-06T00:00:00JST">Nov 6, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-11-06/">Bayesian analysis of non-identifiable models, with an example from epidemiology and biostatistics</a></h2>
    <h3 class="post-meta">Lawrence McCandless · Nov 6, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-11-06">Date: 2015-11-06</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Most regression models in biostatistics assume identifiability, which means that each point in the parameter space corresponds to a unique likelihood function for the observable data. Recently there has been interest in Bayesian inference for non-identifiable models, which can better represent uncertainty in some contexts. One example is in the field of epidemiology, where the investigator is concerned with bias due to unmeasured confounders (omitted variables). In this talk, I will illustrate Bayesian analysis of a non-identifiable model from epidemiology using government administrative data from British Columbia. I will show how to use the software STAN, which is new software developed by Andrew Gelman and others in the USA. STAN allows the careful study of posterior distributions in a vast collection of Bayesian models, including non-identifiable models for bias in epidemiology, which are poorly suited to conventional Gibbs sampling.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-11-06/" title="Bayesian analysis of non-identifiable models, with an example from epidemiology and biostatistics">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-10-30T00:00:00JST">Oct 30, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-10-30/">A knockoff filter for controlling the false discovery rate</a></h2>
    <h3 class="post-meta">Emmanuel Candès · Oct 30, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-10-30">Date: 2015-10-30</h4>
<h4 id="time-1600-1700">Time: 16:00-17:00</h4>
<h4 id="location-salle-1360-pavillon-andré-aisenstadt-université-de-montréa">Location: Salle 1360, Pavillon André-Aisenstadt, Université de Montréa</h4>
<h2 id="abstract">Abstract:</h2>
<p>The big data era has created a new scientific paradigm: collect data first, ask questions later. Imagine that we observe a response variable together with a large number of potential explanatory variables, and would like to be able to discover which variables are truly associated with the response. At the same time, we need to know that the false discovery rate (FDR) - the expected fraction of false discoveries among all discoveries - is not too high, in order to assure the scientist that most of the discoveries are indeed true and replicable. We introduce the knockoff filter, a new variable selection procedure controlling the FDR in the statistical linear model whenever there are at least as many observations as variables. This method works by constructing fake variables, knockoffs, which can then be used as controls for the true variables; the method achieves exact FDR control in finite-sample settings no matter the design or covariates, the number of variables in the model, and the amplitudes of the unknown regression coefficients, and does not require any knowledge of the noise level. This is joint work with Rina Foygel Barber.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-10-30/" title="A knockoff filter for controlling the false discovery rate">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-10-23T00:00:00JST">Oct 23, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-10-23/">Robust mixture regression and outlier detection via penalized likelihood</a></h2>
    <h3 class="post-meta">Weixin Yao · Oct 23, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-10-23">Date: 2015-10-23</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Finite mixture regression models have been widely used for modeling mixed regression relationships arising from a clustered and thus heterogenous population. The classical normal mixture model, despite of its simplicity and wide applicability, may fail dramatically in the presence of severe outliers. We propose a robust mixture regression approach based on a sparse, case-specific, and scale-dependent mean-shift parameterization, for simultaneously conducting outlier detection and robust parameter estimation. A penalized likelihood approach is adopted to induce sparsity among the mean-shift parameters so that the outliers are distinguished from the good observations, and a thresholding-embedded Expectation-Maximization (EM) algorithm is developed to enable stable and efficient computation. The proposed penalized estimation approach is shown to have strong connections with other robust methods including the trimmed likelihood and the M-estimation methods. Comparing with several existing methods, the proposed methods show outstanding performance in numerical studies.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-10-23/" title="Robust mixture regression and outlier detection via penalized likelihood">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-10-16T00:00:00JST">Oct 16, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-10-16/">Estimating high-dimensional multi-layered networks through penalized maximum likelihood</a></h2>
    <h3 class="post-meta">George Michailidis · Oct 16, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-10-16">Date: 2015-10-16</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Gaussian graphical models represent a good tool for capturing interactions between nodes represent the underlying random variables. However, in many applications in biology one is interested in modeling associations both between, as well as within molecular compartments (e.g., interactions between genes and proteins/metabolites). To this end, inferring multi-layered network structures from high-dimensional data provides insight into understanding the conditional relationships among nodes within layers, after adjusting for and quantifying the effects of nodes from other layers. We propose an integrated algorithmic approach for estimating multi-layered networks, that incorporates a screening step for significant variables, an optimization algorithm for estimating the key model parameters and a stability selection step for selecting the most stable effects. The proposed methodology offers an efficient way of estimating the edges within and across layers iteratively, by solving an optimization problem constructed based on penalized maximum likelihood (under a Gaussianity assumption). The optimization is solved on a reduced parameter space that is identified through screening, which remedies the instability in high-dimension. Theoretical properties are considered to ensure identifiability and consistent estimation of the parameters and convergence of the optimization algorithm, despite the lack of global convexity. The performance of the methodology is illustrated on synthetic data sets and on an application on gene and metabolic expression data for patients with renal disease.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-10-16/" title="Estimating high-dimensional multi-layered networks through penalized maximum likelihood">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-10-09T00:00:00JST">Oct 9, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-10-09/">Parameter estimation of partial differential equations over irregular domains</a></h2>
    <h3 class="post-meta">Michelle Carey · Oct 9, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-10-09">Date: 2015-10-09</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>Spatio-temporal data are abundant in many scientific fields; examples include daily satellite images of the earth, hourly temperature readings from multiple weather stations, and the spread of an infectious disease over a particular region. In many instances the spatio-temporal data are accompanied by mathematical models expressed in terms of partial differential equations (PDEs). These PDEs determine the theoretical aspects of the behavior of the physical, chemical or biological phenomena considered. Azzimonti (2013) showed that including the associated PDE as a regularization term as opposed to the conventional two-dimensional Laplacian provides a considerable improvement in the estimation accuracy. The PDEs parameters often have interesting interpretations. Although they are typically unknown and must be inferred from expert knowledge of the phenomena considered. In this talk I will discuss extending the profiling with a parameter cascading procedure outlined in Ramsay et al. (2007) to incorporate PDE parameter estimation. I will also show how, following Sangalli et al. (2013), the estimation procedure can be extended to include finite-element methods (FEMs). This allows the proposed method to account for attributes of the geometry of the physical problem such as irregular shaped domains, external and internal boundary features, as well as strong concavities. Thus this talk will introduce a methodology for data-driven estimates of the parameters of PDEs defined over irregular domains.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-10-09/" title="Parameter estimation of partial differential equations over irregular domains">Read More…</a>
  </footer>
  
</article>
</li>
      
      <li><article class="li">
  <header>
    <ul class="p-facts">
      <li><i class="fa fa-calendar" aria-hidden="true"></i><time datetime="2015-10-02T00:00:00JST">Oct 2, 2015</time></li>
      <li><i class="fa fa-bookmark" aria-hidden="true"></i><a href="https://mcgillstat.github.io/post/">post</a></li>
      
    </ul>
    <h2 class="title"><a href="https://mcgillstat.github.io/post/2015fall/2015-10-02/">Estimating covariance matrices of intermediate size</a></h2>
    <h3 class="post-meta">Didier Chételat · Oct 2, 2015 </h3>
  </header>

  
  <div class="summary"><h4 id="date-2015-10-02">Date: 2015-10-02</h4>
<h4 id="time-1530-1630">Time: 15:30-16:30</h4>
<h4 id="location-burn-1205">Location: BURN 1205</h4>
<h2 id="abstract">Abstract:</h2>
<p>In finance, the covariance matrix of many assets is a key component of financial portfolio optimization and is usually estimated from historical data. Much research in the past decade has focused on improving estimation by studying the asymptotics of large covariance matrices in the so-called high-dimensional regime, where the dimension p grows at the same pace as the sample size n, and this approach has been very successful. This choice of growth makes sense in part because, based on results for eigenvalues, it appears that there are only two limits: the high-dimensional one when p grows like n, and the classical one, when p grows more slowly than n. In this talk, I will present evidence that this binary view is false, and that there could be hidden intermediate regimes lying in between. In turn, this allows for corrections to the sample covariance matrix that are more appropriate when the dimension is large but moderate with respect to the sample size, as is often the case; this can also lead to better optimization for portfolio volatility in many situations of interest.</p></div>

  
  <footer>
    <a href="https://mcgillstat.github.io/post/2015fall/2015-10-02/" title="Estimating covariance matrices of intermediate size">Read More…</a>
  </footer>
  
</article>
</li>
      
    </ul>

    
<nav>
  <ul class="pager">

    
    <li><a href="/post/page/20/">Previous</a></li>
    

    
    <li><a href="/post/page/22/">Next</a></li>
    

  </ul>
</nav>



  </div>
  <div class="col-md-4">
    
<aside class="l-sidebar">

  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">Recent Talks</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-winter/" class="list-group-item"> · Feb 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/" class="list-group-item"> · Feb 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/post/2025winter/2025-02-28/" class="list-group-item">Johannes Lederer · Feb 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar/" class="list-group-item"> · Feb 28, 2025</a>
      
      <a href="https://mcgillstat.github.io/tags/" class="list-group-item"> · Feb 28, 2025</a>
      
    </div>
  </section>

  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">CATEGORY</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/categories/mcgill-statistics-seminar" class="list-group-item">mcgill statistics seminar</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-ssc-prize-address" class="list-group-item">crm-ssc prize address</a>
      
      <a href="https://mcgillstat.github.io/categories/crm-colloquium" class="list-group-item">crm-colloquium</a>
      
    </div>
  </section>
  
  <section class="panel panel-default">
    <div class="panel-heading">
      <div class="panel-title">TAG</div>
    </div>
    <div class="list-group">
      
      <a href="https://mcgillstat.github.io/tags/2025-winter" class="list-group-item">2025 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-winter" class="list-group-item">2024 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2024-fall" class="list-group-item">2024 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-winter" class="list-group-item">2023 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-summer" class="list-group-item">2023 summer</a>
      
      <a href="https://mcgillstat.github.io/tags/2023-fall" class="list-group-item">2023 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-winter" class="list-group-item">2022 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2022-fall" class="list-group-item">2022 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-winter" class="list-group-item">2021 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2021-fall" class="list-group-item">2021 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-winter" class="list-group-item">2020 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2020-fall" class="list-group-item">2020 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-winter" class="list-group-item">2019 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2019-fall" class="list-group-item">2019 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-winter" class="list-group-item">2018 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2018-fall" class="list-group-item">2018 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-winter" class="list-group-item">2017 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2017-fall" class="list-group-item">2017 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-winter" class="list-group-item">2016 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2016-fall" class="list-group-item">2016 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-winter" class="list-group-item">2015 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2015-fall" class="list-group-item">2015 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-winter" class="list-group-item">2014 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2014-fall" class="list-group-item">2014 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-winter" class="list-group-item">2013 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2013-fall" class="list-group-item">2013 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-winter" class="list-group-item">2012 winter</a>
      
      <a href="https://mcgillstat.github.io/tags/2012-fall" class="list-group-item">2012 fall</a>
      
      <a href="https://mcgillstat.github.io/tags/2011-fall" class="list-group-item">2011 fall</a>
      
    </div>
  </section>
  

</aside>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    
  </div>
</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
        <p><span class="h-logo">&copy; McGill Statistics Seminars</span></p>
        <aside>
          <p><a href="http://www.mcgill.ca/mathstat/">Department of Mathematics and Statistics</a>.</p>
          <p><a href="https://www.mcgill.ca/">McGill University</a></p>
        </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

