<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2016 Fall on McGill Statistics Seminars</title>
    <link>/tags/2016-fall/</link>
    <description>Recent content in 2016 Fall on McGill Statistics Seminars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Dec 2016 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/2016-fall/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Modeling dependence in bivariate multi-state processes: A frailty approach</title>
      <link>/post/2016fall/2016-12-02/</link>
      <pubDate>Fri, 02 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-12-02/</guid>
      <description>Date: 2016-12-02 Time: 15:30-16:30 Location: BURN 1205 Abstract: The aim of this talk is to present a statistical framework for the analysis of dependent bivariate multistate processes, allowing one to study the dependence both across subjects in a pair and among individual-specific events. As for the latter, copula- based models are employed, whereas dependence between multi-state models can be accomplished by means of frailties. The well known Marshall-Olkin Bivariate Exponential Distribution (MOBVE) is considered for the joint distribution of frailties.</description>
    </item>
    
    <item>
      <title>High-dimensional changepoint estimation via sparse projection</title>
      <link>/post/2016fall/2016-12-01/</link>
      <pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-12-01/</guid>
      <description>Date: 2016-12-01 Time: 15:30-16:30 Location: BURN 708 Abstract: Changepoints are a very common feature of Big Data that arrive in the form of a data stream. We study high-dimensional time series in which, at certain time points, the mean structure changes in a sparse subset of the coordinates. The challenge is to borrow strength across the coordinates in order to detect smaller changes than could be observed in any individual component series.</description>
    </item>
    
    <item>
      <title>Spatio-temporal models for skewed processes</title>
      <link>/post/2016fall/2016-11-25/</link>
      <pubDate>Fri, 25 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-11-25/</guid>
      <description>Date: 2016-11-25 Time: 15:30-16:30 Location: BURN 1205 Abstract: In the analysis of most spatio-temporal processes in environmental studies, observations present skewed distributions. Usually, a single transformation of the data is used to approximate normality, and stationary Gaussian processes are assumed to model the transformed data. The choice of transformation is key for spatial interpolation and temporal prediction. We propose a spatio-temporal model for skewed data that does not require the use of data transformation.</description>
    </item>
    
    <item>
      <title>Progress in theoretical understanding of deep learning</title>
      <link>/post/2016fall/2016-11-18/</link>
      <pubDate>Fri, 18 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-11-18/</guid>
      <description>Date: 2016-11-18 Time: 15:30-16:30 Location: BURN 1205 Abstract: Deep learning has arisen around 2006 as a renewal of neural networks research allowing such models to have more layers. Theoretical investigations have shown that functions obtained as deep compositions of simpler functions (which includes both deep and recurrent nets) can express highly varying functions (with many ups and downs and different input regions that can be distinguished) much more efficiently (with fewer parameters) than otherwise, under a prior which seems to work well for artificial intelligence tasks.</description>
    </item>
    
    <item>
      <title>Tyler&#39;s M-estimator: Subspace recovery and high-dimensional regime</title>
      <link>/post/2016fall/2016-11-11/</link>
      <pubDate>Fri, 11 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-11-11/</guid>
      <description>Date: 2016-11-11 Time: 15:30-16:30 Location: BURN 1205 Abstract: Given a data set, Tyler&amp;rsquo;s M-estimator is a widely used covariance matrix estimator with robustness to outliers or heavy-tailed distribution. We will discuss two recent results of this estimator. First, we show that when a certain percentage of the data points are sampled from a low-dimensional subspace, Tyler&amp;rsquo;s M-estimator can be used to recover the subspace exactly. Second, in the high-dimensional regime that the number of samples n and the dimension p both go to infinity, p/n converges to a constant y between 0 and 1, and when the data samples are identically and independently generated from the Gaussian distribution N(0,I), we showed that the difference between the sample covariance matrix and a scaled version of Tyler&amp;rsquo;s M-estimator tends to zero in spectral norm, and the empirical spectral densities of both estimators converge to the Marcenko-Pastur distribution.</description>
    </item>
    
    <item>
      <title>Lawlor: Time-varying mixtures of Markov chains: An application to traffic modeling Piché: Bayesian nonparametric modeling of heterogeneous groups of censored data</title>
      <link>/post/2016fall/2016-11-04/</link>
      <pubDate>Fri, 04 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-11-04/</guid>
      <description>Date: 2016-11-04 Time: 15:30-16:30 Location: BURN 1205 Abstract: Piché: Analysis of survival data arising from different groups, whereby the data in each group is scarce, but abundant overall, is a common issue in applied statistics. Bayesian nonparametrics are tools of choice to handle such datasets given their ability to share information across groups. In this presentation, we will compare three popular Bayesian nonparametric methods on the modeling of survival functions coming from related heterogeneous groups.</description>
    </item>
    
    <item>
      <title>First talk: Bootstrap in practice | Second talk: Statistics and Big Data at Google</title>
      <link>/post/2016fall/2016-11-02/</link>
      <pubDate>Wed, 02 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-11-02/</guid>
      <description>Date: 2016-11-02 Time: 15:00-16:00 17:35-18:25 Location: 1st: BURN 306 2nd: ADAMS AUD Abstract: First talk: This talk focuses on three practical aspects of resampling: communication, accuracy, and software. I&amp;rsquo;ll introduce the bootstrap and permutation tests, and discussed how they may be used to help clients understand statistical results. I&amp;rsquo;ll talk about accuracy &amp;ndash; there are dramatic differences in how accurate different bootstrap methods are. Surprisingly, the most common bootstrap methods are less accurate than classical methods for small samples, and more accurate for larger samples.</description>
    </item>
    
    <item>
      <title>Efficient tests of covariate effects in two-phase failure time studies</title>
      <link>/post/2016fall/2016-10-28/</link>
      <pubDate>Fri, 28 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-10-28/</guid>
      <description>Date: 2016-10-28 Time: 15:30-16:30 Location: BURN 1205 Abstract: Two-phase studies are frequently used when observations on certain variables are expensive or difficult to obtain. One such situation is when a cohort exists for which certain variables have been measured (phase 1 data); then, a sub-sample of individuals is selected, and additional data are collected on them (phase 2). Efficiency for tests and estimators can be increased by basing the selection of phase 2 individuals on data collected at phase 1.</description>
    </item>
    
    <item>
      <title>Statistical analysis of two-level hierarchical clustered data</title>
      <link>/post/2016fall/2016-10-21/</link>
      <pubDate>Fri, 21 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-10-21/</guid>
      <description>Date: 2016-10-21 Time: 15:30-16:30 Location: BURN 1205 Abstract: Multi-level hierarchical clustered data are commonly seen in financial and biostatistics applications. In this talk, we introduce several modeling strategies for describing the dependent relationships for members within a cluster or between different clusters (in the same or different levels). In particular we will apply the hierarchical Kendall copula, first proposed by Brechmann (2014), to model two-level hierarchical clustered survival data. This approach provides a clever way of dimension reduction in modeling complicated multivariate data.</description>
    </item>
    
    <item>
      <title>A Bayesian finite mixture of bivariate regressions model for causal mediation analyses</title>
      <link>/post/2016fall/2016-10-14/</link>
      <pubDate>Fri, 14 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-10-14/</guid>
      <description>Date: 2016-10-14 Time: 15:30-16:30 Location: BURN 1205 Abstract: Building on the work of Schwartz, Gelfand and Miranda (Statistics in Medicine (2010); 29(16), 1710-23), we propose a Bayesian finite mixture of bivariate regressions model for causal mediation analyses. Using an identifiability condition within each component of the mixture, we express the natural direct and indirect effects of the exposure on the outcome as functions of the component-specific regression coefficients. On the basis of simulated data, we examine the behaviour of the model for estimating these effects in situations where the associations between exposure, mediator and outcome are confounded, or not.</description>
    </item>
    
    <item>
      <title>Cellular tree classifiers</title>
      <link>/post/2016fall/2016-10-07/</link>
      <pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-10-07/</guid>
      <description>Date: 2016-10-07 Time: 15:30-16:30 Location: BURN 1205 Abstract: Suppose that binary classification is done by a tree method in which the leaves of a tree correspond to a partition of d-space. Within a partition, a majority vote is used. Suppose furthermore that this tree must be constructed recursively by implementing just two functions, so that the construction can be carried out in parallel by using &amp;ldquo;cells&amp;rdquo;: first of all, given input data, a cell must decide whether it will become a leaf or internal node in the tree.</description>
    </item>
    
    <item>
      <title>CoCoLasso for high-dimensional error-in-variables regression</title>
      <link>/post/2016fall/2016-09-30/</link>
      <pubDate>Fri, 30 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-09-30/</guid>
      <description>Date: 2016-09-30 Time: 15:30-16:30 Location: BURN 1205 Abstract: Much theoretical and applied work has been devoted to high-dimensional regression with clean data. However, we often face corrupted data in many applications where missing data and measurement errors cannot be ignored. Loh and Wainwright (2012) proposed a non-convex modification of the Lasso for doing high-dimensional regression with noisy and missing data. It is generally agreed that the virtues of convexity contribute fundamentally the success and popularity of the Lasso.</description>
    </item>
    
    <item>
      <title>Stein estimation of the intensity parameter of a stationary spatial Poisson point process</title>
      <link>/post/2016fall/2016-09-23/</link>
      <pubDate>Fri, 23 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-09-23/</guid>
      <description>Date: 2016-09-23 Time: 15:30-16:30 Location: BURN 1205 Abstract: We revisit the problem of estimating the intensity parameter of a homogeneous Poisson point process observed in a bounded window of $R^d$ making use of a (now) old idea going back to James and Stein. For this, we prove an integration by parts formula for functionals defined on the Poisson space. This formula extends the one obtained by Privault and Réveillac (Statistical inference for Stochastic Processes, 2009) in the one-dimensional case and is well-suited to a notion of derivative of Poisson functionals which satisfy the chain rule.</description>
    </item>
    
    <item>
      <title>Statistical inference for fractional diffusion processes</title>
      <link>/post/2016fall/2016-09-16/</link>
      <pubDate>Fri, 16 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-09-16/</guid>
      <description>Date: 2016-09-16 Time: 16:00-17:00 Location: LB-921.04, Library Building, Concordia Univ. Abstract: There are some time series which exhibit long-range dependence as noticed by Hurst in his investigations of river water levels along Nile river. Long-range dependence is connected with the concept of self-similarity in that increments of a self-similar process with stationary increments exhibit long-range dependence under some conditions. Fractional Brownian motion is an example of such a process. We discuss statistical inference for stochastic processes modeled by stochastic differential equations driven by a fractional Brownian motion.</description>
    </item>
    
    <item>
      <title>Two-set canonical variate model in multiple populations with invariant loadings</title>
      <link>/post/2016fall/2016-09-09/</link>
      <pubDate>Fri, 09 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016fall/2016-09-09/</guid>
      <description>Date: 2016-09-09 Time: 15:30-16:30 Location: BURN 1205 Abstract: Goria and Flury (Definition 2.1, 1996) proposed the two-set canonical variate model (referred to as the CV-2 model hereafter) and its extension in multiple populations with invariant weight coefficients (Definition 2.2). The equality constraints imposed on the weight coefficients are in line with the approach to interpreting the canonical variates (i.e., the linear combinations of original variables) advocated by Harris (1975, 1989), Rencher (1988, 1992), and Rencher and Christensen (2003).</description>
    </item>
    
  </channel>
</rss>