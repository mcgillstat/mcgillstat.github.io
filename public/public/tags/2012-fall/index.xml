<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2012 Fall on McGill Statistics Seminars</title>
    <link>/tags/2012-fall/</link>
    <description>Recent content in 2012 Fall on McGill Statistics Seminars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Dec 2012 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/2012-fall/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>What percentage of children in the U.S. are eating a healthy diet? A statistical approach</title>
      <link>/post/2012fall/2012-12-14/</link>
      <pubDate>Fri, 14 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-12-14/</guid>
      <description>Date: 2012-12-14 Time: 14:30-15:30 Location: Concordia, Room LB 921-04 Abstract: In the United States the preferred method of obtaining dietary intake data is the 24-hour dietary recall, yet the measure of most interest is usual or long-term average daily intake, which is impossible to measure. Thus, usual dietary intake is assessed with considerable measurement error. Also, diet represents numerous foods, nutrients and other components, each of which have distinctive attributes.</description>
    </item>
    
    <item>
      <title>Sample size and power determination for multiple comparison procedures aiming at rejecting at least r among m false hypotheses</title>
      <link>/post/2012fall/2012-12-07/</link>
      <pubDate>Fri, 07 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-12-07/</guid>
      <description>Date: 2012-12-07 Time: 14:30-15:30 Location: BURN 1205 Abstract: Multiple testing problems arise in a variety of situations, notably in clinical trials with multiple endpoints. In such cases, it is often of interest to reject either all hypotheses or at least one of them. More generally, the question arises as to whether one can reject at least r out of m hypotheses. Statistical tools addressing this issue are rare in the literature.</description>
    </item>
    
    <item>
      <title>Sharing confidential datasets using differential privacy</title>
      <link>/post/2012fall/2012-11-30/</link>
      <pubDate>Fri, 30 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-11-30/</guid>
      <description>Date: 2012-11-30 Time: 14:30-15:30 Location: BURN 1205 Abstract: While statistical agencies would like to share their data with researchers, they must also protect the confidentiality of the data provided by their respondents. To satisfy these two conflicting objectives, agencies use various techniques to restrict and modify the data before publication. Most of these techniques however share a common flaw: their confidentiality protection can not be rigorously measured. In this talk, I will present the criterion of differential privacy, a rigorous measure of the protection offered by such methods.</description>
    </item>
    
    <item>
      <title>A nonparametric Bayesian model for local clustering</title>
      <link>/post/2012fall/2012-11-23/</link>
      <pubDate>Fri, 23 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-11-23/</guid>
      <description>Date: 2012-11-23 Time: 14:30-15:30 Location: BURN 107 Abstract: We propose a nonparametric Bayesian local clustering (NoB-LoC) approach for heterogeneous data. Using genomics data as an example, the NoB-LoC clusters genes into gene sets and simultaneously creates multiple partitions of samples, one for each gene set. In other words, the sample partitions are nested within the gene sets. Inference is guided by a joint probability model on all random elements. Biologically, the model formalizes the notion that biological samples cluster differently with respect to different genetic processes, and that each process is related to only a small subset of genes.</description>
    </item>
    
    <item>
      <title>Copula-based regression estimation and Inference</title>
      <link>/post/2012fall/2012-11-16/</link>
      <pubDate>Fri, 16 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-11-16/</guid>
      <description>Date: 2012-11-16 Time: 14:30-15:30 Location: BURN 1205 Abstract: In this paper we investigate a new approach of estimating a regression function based on copulas. The main idea behind this approach is to write the regression function in terms of a copula and marginal distributions. Once the copula and the marginal distributions are estimated we use the plug-in method to construct the new estimator. Because various methods are available in the literature for estimating both a copula and a distribution, this idea provides a rich and flexible alternative to many existing regression estimators.</description>
    </item>
    
    <item>
      <title>The multidimensional edge: Seeking hidden risks</title>
      <link>/post/2012fall/2012-11-09/</link>
      <pubDate>Fri, 09 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-11-09/</guid>
      <description>Date: 2012-11-09 Time: 14:30-15:30 Location: BURN 1205 Abstract: Assessing tail risks using the asymptotic models provided by multivariate extreme value theory has the danger that when asymptotic independence is present (as with the Gaussian copula model), the asymptotic model provides estimates of probabilities of joint tail regions that are zero. In diverse applications such as finance, telecommunications, insurance and environmental science, it may be difficult to believe in the absence of risk contagion.</description>
    </item>
    
    <item>
      <title>Multivariate extremal dependence: Estimation with bias correction</title>
      <link>/post/2012fall/2012-11-02/</link>
      <pubDate>Fri, 02 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-11-02/</guid>
      <description>Date: 2012-11-02 Time: 14:30-15:30 Location: BURN 1205 Abstract: Estimating extreme risks in a multivariate framework is highly connected with the estimation of the extremal dependence structure. This structure can be described via the stable tail dependence function L, for which several estimators have been introduced. Asymptotic normality is available for empirical estimates of L, with rate of convergence k^1&amp;frasl;2, where k denotes the number of high order statistics used in the estimation.</description>
    </item>
    
    <item>
      <title>Simulation model calibration and prediction using outputs from multi-fidelity simulators</title>
      <link>/post/2012fall/2012-10-26/</link>
      <pubDate>Fri, 26 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-10-26/</guid>
      <description>Date: 2012-10-26 Time: 14:30-15:30 Location: BURN 1205 Abstract: Computer simulators are used widely to describe physical processes in lieu of physical observations. In some cases, more than one computer code can be used to explore the same physical system - each with different degrees of fidelity. In this work, we combine field observations and model runs from deterministic multi-fidelity computer simulators to build a predictive model for the real process.</description>
    </item>
    
    <item>
      <title>Observational studies in healthcare: are they any good?</title>
      <link>/post/2012fall/2012-10-19/</link>
      <pubDate>Fri, 19 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-10-19/</guid>
      <description>Date: 2012-10-19 Time: 14:30-15:30 Location: UdeM Abstract: Observational healthcare data, such as administrative claims and electronic health records, play an increasingly prominent role in healthcare. Pharmacoepidemiologic studies in particular routinely estimate temporal associations between medical product exposure and subsequent health outcomes of interest, and such studies influence prescribing patterns and healthcare policy more generally. Some authors have questioned the reliability and accuracy of such studies, but few previous efforts have attempted to measure their performance.</description>
    </item>
    
    <item>
      <title>	Modeling operational risk using a Bayesian approach to EVT</title>
      <link>/post/2012fall/2012-10-12/</link>
      <pubDate>Fri, 12 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-10-12/</guid>
      <description>Date: 2012-10-12 Time: 14:30-15:30 Location: BURN 1205 Abstract: Extreme Value Theory has been widely used for assessing risk for highly unusual events, either by using block maxima or peaks over the threshold (POT) methods. However, one of the main drawbacks of the POT method is the choice of a threshold, which plays an important role in the estimation since the parameter estimates strongly depend on this value. Bayesian inference is an alternative to handle these difficulties; the threshold can be treated as another parameter in the estimation, avoiding the classical empirical approach.</description>
    </item>
    
    <item>
      <title>Markov switching regular vine copulas</title>
      <link>/post/2012fall/2012-10-05/</link>
      <pubDate>Fri, 05 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-10-05/</guid>
      <description>Date: 2012-10-05 Time: 14:30-15:30 Location: BURN 1205 Abstract: Using only bivariate copulas as building blocks, regular vines(R-vines) constitute a flexible class of high-dimensional dependence models. In this talk we introduce a Markov switching R-vine copula model, combining the flexibility of general R-vine copulas with the possibility for dependence structures to change over time. Frequentist as well as Bayesian parameter estimation is discussed. Further, we apply the newly proposed model to examine the dependence of exchange rates as well as stock and stock index returns.</description>
    </item>
    
    <item>
      <title>The current state of Q-learning for personalized medicine</title>
      <link>/post/2012fall/2012-09-28/</link>
      <pubDate>Fri, 28 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-09-28/</guid>
      <description>Date: 2012-09-28 Time: 14:30-15:30 Location: BURN 1205 Abstract: In this talk, I will provide an introduction to DTRs and an overview the state of the art (and science) of Q-learning, a popular tool in reinforcement learning. The use of Q-learning and its variance in randomized and non-randomized studies will be discussed, as well as issues concerning inference as the resulting estimators are not always regular. Current and future directions of interest will also be considered.</description>
    </item>
    
    <item>
      <title>Regularized semiparametric functional linear regression</title>
      <link>/post/2012fall/2012-09-21/</link>
      <pubDate>Fri, 21 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012fall/2012-09-21/</guid>
      <description>Date: 2012-09-21 Time: 14:30-15:30 Location: McGill, Burnside Hall 1214 Abstract: In many scientific experiments we need to face analysis with functional data, where the observations are sampled from random process, together with a potentially large number of non-functional covariates. The complex nature of functional data makes it difficult to directly apply existing methods to model selection and estimation. We propose and study a new class of penalized semiparametric functional linear regression to characterize the regression relation between a scalar response and multiple covariates, including both functional covariates and scalar covariates.</description>
    </item>
    
  </channel>
</rss>