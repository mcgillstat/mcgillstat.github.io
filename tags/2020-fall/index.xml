<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2020 Fall on McGill Statistics Seminars</title>
    <link>/tags/2020-fall/</link>
    <description>Recent content in 2020 Fall on McGill Statistics Seminars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Oct 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/2020-fall/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Test-based integrative analysis of randomized trial and real-world data for treatment heterogeneity estimation</title>
      <link>/post/2020fall/2020-10-30/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020fall/2020-10-30/</guid>
      <description>Date: 2020-10-30 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: Parallel randomized clinical trial (RCT) and real-world data (RWD) are becoming increasingly available for treatment evaluation. Given the complementary features of the RCT and RWD, we propose a test-based integrative analysis of the RCT and RWD for accurate and robust estimation of the heterogeneity of treatment effect (HTE), which lies at the heart of precision medicine.</description>
    </item>
    
    <item>
      <title>Linear Regression and its Inference on Noisy Network-linked Data</title>
      <link>/post/2020fall/2020-10-23/</link>
      <pubDate>Fri, 23 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020fall/2020-10-23/</guid>
      <description>Date: 2020-10-23 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: Linear regression on a set of observations linked by a network has been an essential tool in modeling the relationship between response and covariates with additional network data. Despite its wide range of applications in many areas, such as social sciences and health-related research, the problem has not been well-studied in statistics so far. Previous methods either lack of inference tools or rely on restrictive assumptions on social effects, and usually treat the network structure as precisely observed, which is too good to be true in many problems.</description>
    </item>
    
    <item>
      <title>Adaptive MCMC For Everyone</title>
      <link>/post/2020fall/2020-10-16/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020fall/2020-10-16/</guid>
      <description>Date: 2020-10-16 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: Markov chain Monte Carlo (MCMC) algorithms, such as the Metropolis Algorithm and the Gibbs Sampler, are an extremely useful and popular method of approximately sampling from complicated probability distributions. Adaptive MCMC attempts to automatically modify the algorithm while it runs, to improve its performance on the fly. However, such adaptation often destroys the ergodicity properties necessary for the algorithm to be valid.</description>
    </item>
    
    <item>
      <title>Machine Learning and Neural Networks: Foundations and Some Fundamental Questions</title>
      <link>/post/2020fall/2020-10-09/</link>
      <pubDate>Fri, 09 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020fall/2020-10-09/</guid>
      <description>Date: 2020-10-09 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: Statistical learning theory is by now a mature branch of data science that hosts a vast variety of practical techniques for tackling data-related problems. In this talk we present some fundamental concepts upon which statistical learning theory has been based. Different approaches to statistical inference will be discussed and the main problem of learning from Vapnik&amp;rsquo;s point of view will be explained.</description>
    </item>
    
    <item>
      <title>Data Science, Classification, Clustering and Three-Way Data</title>
      <link>/post/2020fall/2020-10-02/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020fall/2020-10-02/</guid>
      <description>Date: 2020-10-02 Time: 15:30-16:30 Zoom Link Meeting ID: 939 8331 3215 Passcode: 096952 Abstract: Data science is discussed along with some historical perspective. Selected problems in classification are considered, either via specific datasets or general problem types. In each case, the problem is introduced before one or more potential solutions are discussed and applied. The problems discussed include data with outliers, longitudinal data, and three-way data. The proposed approaches are generally mixture model-based.</description>
    </item>
    
    <item>
      <title>Large-scale Network Inference</title>
      <link>/post/2020fall/2020-09-25/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020fall/2020-09-25/</guid>
      <description>Date: 2020-09-25 Time: 14:00-15:00 Zoom Link Meeting ID: 939 4707 7997 Passcode: no password Abstract: Network data is prevalent in many contemporary big data applications in which a common interest is to unveil important latent links between different pairs of nodes. Yet a simple fundamental question of how to precisely quantify the statistical uncertainty associated with the identification of latent links still remains largely unexplored. In this paper, we propose the method of statistical inference on membership profiles in large networks (SIMPLE) in the setting of degree-corrected mixed membership model, where the null hypothesis assumes that the pair of nodes share the same profile of community memberships.</description>
    </item>
    
    <item>
      <title>BdryGP: a boundary-integrated Gaussian process model for computer code emulation</title>
      <link>/post/2020fall/2020-09-18/</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020fall/2020-09-18/</guid>
      <description>Date: 2020-09-18 Time: 15:30-16:30 Zoom Link Meeting ID: 924 5390 4989 Passcode: 690084 Abstract: With advances in mathematical modeling and computational methods, complex phenomena (e.g., universe formations, rocket propulsion) can now be reliably simulated via computer code. This code solves a complicated system of equations representing the underlying science of the problem. Such simulations can be very time-intensive, requiring months of computation for a single run. Gaussian processes (GPs) are widely used as predictive models for “emulating” this expensive computer code.</description>
    </item>
    
    <item>
      <title>Machine Learning for Causal Inference</title>
      <link>/post/2020fall/2020-09-11/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020fall/2020-09-11/</guid>
      <description>Date: 2020-09-11 Time: 16:00-17:00 Zoom Link Meeting ID: 965 2536 7383 Passcode: 421254 Abstract: Given advances in machine learning over the past decades, it is now possible to accurately solve difficult non-parametric prediction problems in a way that is routine and reproducible. In this talk, I’ll discuss how machine learning tools can be rigorously integrated into observational study analyses, and how they interact with classical statistical ideas around randomization, semiparametric modeling, double robustness, etc.</description>
    </item>
    
  </channel>
</rss>