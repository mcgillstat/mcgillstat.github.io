<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2018 Fall on McGill Statistics Seminars</title>
    <link>http://localhost:4321/tags/2018-fall/</link>
    <description>Recent content in 2018 Fall on McGill Statistics Seminars</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Nov 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:4321/tags/2018-fall/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>p-values vs Bayes factors: Is there a compromise?</title>
      <link>http://localhost:4321/post/2018fall/2018-11-23/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-11-23/</guid>
      <description>&lt;h4 id=&#34;date-2018-11-23&#34;&gt;Date: 2018-11-23&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;This is not a research talk. Rather, the goal is to address the topic of the talk title through a&#xA;2017 multi-authored paper published in Nature Human Behaviour. The Nature article proposes that the standard cut-off significance level of .05 should be replaced by a cut-off level of .005 when new discoveries are being claimed. The authors attribute the high proportion of irreducible results in the literature that accompany claimed new discoveries, in part, to the low-bar cut-off of .05. Their fix is built around the Bayes factor. I will begin with a brief presentation of the difference between the frequentist and Bayesian approaches to statistical inference, and lead into p-values vs Bayes factors for hypothesis testing before discussing the Nature article itself. It is hoped that the talk will provoke thought about the way we do statistics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Estimation of the Median Residual Lifetime Function for Length-Biased Failure Time Data</title>
      <link>http://localhost:4321/post/2018fall/2018-11-16/</link>
      <pubDate>Fri, 16 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-11-16/</guid>
      <description>&lt;h4 id=&#34;date-2018-11-16&#34;&gt;Date: 2018-11-16&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;The median residual lifetime function is a statistical quantity which describes the future point in time at which the probability of current survival has dropped by 50%. In deriving an estimator for the median residual lifetime function for length-biased data, the added features of left-truncation and right-censoring must be taken into account.&lt;/p&gt;&#xA;&lt;p&gt;In this talk, we give a brief description of length-biased failure time data and show that by using a particular non-parametric estimator for the survival function that it is possible to derive the asymptotically most-efficient non-parametric estimator for the median residual lifetime function. We give some details on the proof of the asymptotic results and examine the performance of the estimator using simulated data. We also apply the proposed estimator to the Canadian Study of Health and Aging data set to study the median residual lifetime function of patients with dementia.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Density estimation of mixtures of Gaussians and Ising models</title>
      <link>http://localhost:4321/post/2018fall/2018-11-09/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-11-09/</guid>
      <description>&lt;h4 id=&#34;date-2018-11-09&#34;&gt;Date: 2018-11-09&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;Density estimation lies at the intersection of statistics, theoretical computer science, and machine learning. We review some old and new results on the sample complexities (also known as minimax convergence rates) of estimating densities of high-dimensional distributions, in particular mixtures of Gaussians and Ising models.&lt;/p&gt;&#xA;&lt;p&gt;Based on joint work with Hassan Ashtiani, Shai Ben-David, Luc Devroye, Nick Harvey, Christopher Liaw, Yani Plan, and Tommy Reddad.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Terrorists never congregate in even numbers (and other strange results in fragmentation-coalescence)</title>
      <link>http://localhost:4321/post/2018fall/2018-11-02/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-11-02/</guid>
      <description>&lt;h4 id=&#34;date-2018-11-02&#34;&gt;Date: 2018-11-02&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;The rigorous mathematical treatment of random fragmentation-coalescent models in the literature is difficult to find, and perhaps for good reason. We examine two different types of random fragmentation-coalescent models which produce somewhat unexpected results.&lt;/p&gt;&#xA;&lt;p&gt;The first concerns an agent-based model in which, with a rate that depends on the configuration of the system, agents coalesce into clusters that also fragment into their individual constituent membership. We consider the large-scale, long-term behaviour of this system in a similar spirit to recent use of such models to characterise the evolution of terrorist cells. Under appropriate assumptions we find an unusual behaviour; the system displays stabilisation with clusters that only contain an odd number of individuals.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Object Oriented Data Analysis with Application to Neuroimaging Studies</title>
      <link>http://localhost:4321/post/2018fall/2018-10-26/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-10-26/</guid>
      <description>&lt;h4 id=&#34;date-2018-10-26&#34;&gt;Date: 2018-10-26&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;In this talk, I will first briefly introduce my research on object oriented data analysis with application to neuroimaging studies. I will then talk about a detailed example on imaging genetics. In this project, we develop a high-dimensional matrix linear regression model to correlate 2D imaging responses with high-dimensional genetic covariates. We propose a fast and efficient screening procedure based on the spectral norm to deal with the case that the dimension of scalar covariates is much larger than the sample size. We develop an efficient estimation procedure based on the nuclear norm regularization, which explicitly borrows the matrix structure of coefficient matrices. We examine the finite-sample performance of our methods using simulations and a large-scale imaging genetic dataset from the Alzheimer&amp;rsquo;s Disease Neuroimaging Initiative study.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multilevel clustering and optimal transport</title>
      <link>http://localhost:4321/post/2018fall/2018-10-19/</link>
      <pubDate>Fri, 19 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-10-19/</guid>
      <description>&lt;h4 id=&#34;date-2018-10-19&#34;&gt;Date: 2018-10-19&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;Optimal transport plays an increasingly relevant and useful role in the theory and application of mixture model based clustering and inference. In this talk I will describe some recent progress in characterizing the convergence behavior of mixing distributions when one fits a mixture model to the data. This theory hinges on the relationship between the space of mixture densities, which is endowed with variational or Hellinger distance, and the space of mixing measures endowed with optimal transport distance metrics. Next, I will introduce an optimal transport based technique for the problem of multilevel clustering, which aims to simultaneously partition data in each group and discover grouping patterns among groups in a potentially large hierarchically structured corpus of data. Our method involves a joint optimization formulation over several spaces of discrete probability measures. We propose a number of variants of this problem, which admit fast optimization algorithms, by exploiting the connection to the problem of finding Wasserstein barycenters.  Some theoretical and experimental results will be presented.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Robust estimation in the presence of influential units for skewed finite and infinite populations</title>
      <link>http://localhost:4321/post/2018fall/2018-10-12/</link>
      <pubDate>Fri, 12 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-10-12/</guid>
      <description>&lt;h4 id=&#34;date-2018-10-12&#34;&gt;Date: 2018-10-12&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1600-&#34;&gt;Time: 16:00-&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-crm-université-de-montréal-pavillon-andré-aisenstadt-salle-6254&#34;&gt;Location: CRM, Université de Montréal, Pavillon André-Aisenstadt, salle 6254&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;Many variables encountered in practice (e.g., economic variables) have skewed distributions. The latter provide a conducive ground for the presence of influential observations, which are those that have a drastic impact on the estimates if they were to be excluded from the sample. We examine the problem of influential observations in a classical statistic setting as well as in a finite population setting that includes two main frameworks: the design-based framework and the model-based framework. Within each setting, classical estimators may be highly unstable in the presence of influential units. We propose a robust estimator of the population mean based on the concept of conditional bias of a unit, which is a measure of influence. The idea is to reduce the impact of the sample units that have a large conditional bias. The proposed estimator depends on a cut-off value. We suggest selecting the cut-off value that minimizes the maximum absolute estimated conditional bias with respect to the robust estimator. The properties of the proposed estimator will be discussed. Finally, the results of a simulation study comparing the performance of several estimators in terms of bias and mean square error will be presented.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dimension Reduction for Causal Inference</title>
      <link>http://localhost:4321/post/2018fall/2018-10-05/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-10-05/</guid>
      <description>&lt;h4 id=&#34;date-2018-10-05&#34;&gt;Date: 2018-10-05&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;In this talk, we discuss how sufficient dimension reduction can be used to aid causal inference. We propose a new matching approach based on the reduced covariates obtained from sufficient dimension reduction. Compared with the original covariates and the propensity scores, which are commonly used for matching in the literature, the reduced covariates are estimable nonparametrically and are effective in imputing the missing potential outcomes. Under the ignorability assumption, the consistency of the proposed approach requires a weaker common support condition than the one we often assume for propensity score-based methods. We develop asymptotic properties, and conduct simulation studies as well as real data analysis to illustrate the proposed approach.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Selective inference for dynamic treatment regimes via the LASSO</title>
      <link>http://localhost:4321/post/2018fall/2018-09-28/</link>
      <pubDate>Fri, 28 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-09-28/</guid>
      <description>&lt;h4 id=&#34;date-2018-09-28&#34;&gt;Date: 2018-09-28&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1205&#34;&gt;Location: BURN 1205&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;Constructing an optimal dynamic treatment regime become complex when there are large number of prognostic factors, such as patient’s genetic information, demographic characteristics, medical history over time. Existing methods only focus on selecting the important variables for the decision-making process and fall short in providing inference for the selected model. We fill this gap by leveraging the conditional selective inference methodology. We show that the proposed method is asymptotically valid given certain rate assumptions in semiparametric regression.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Possession Sketches: Mapping NBA Strategies</title>
      <link>http://localhost:4321/post/2018fall/2018-09-21/</link>
      <pubDate>Fri, 21 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-09-21/</guid>
      <description>&lt;h4 id=&#34;date-2018-09-21&#34;&gt;Date: 2018-09-21&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-0930-1015&#34;&gt;Time: 09:30-10:15&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-bronfman-building-001&#34;&gt;Location: Bronfman Building 001&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;We present Possession Sketches, a new machine learning method for organizing and exploring a database of basketball player-tracks. Our method organizes basketball possessions by offensive structure. We first develop a model for populating a dictionary of short, repeated, and spatially registered actions. Each action corresponds to an interpretable type of player movement. We examine statistical patterns in these actions, and show how they can be used to describe individual player behavior. Leveraging this vocabulary of actions, we develop a hierarchical model that describes interactions between players. Our approach draws on the topic-modeling literature, extending Latent Dirichlet Allocation (LDA) through a novel representation of player movement data which uses techniques common in animation and video game design. We show that our model is able to group together possessions with similar offensive structure, allowing for efficient search and exploration of the entire database of player-tracking data. We show that our model finds repeated offensive structure in teams (e.g. strategy), providing a much more sophisticated, yet interpretable lens into basketball player-tracking data. This is joint work with Andrew Miller.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Quantile LASSO in Nonparametric Models with Changepoints Under Optional Shape Constraints</title>
      <link>http://localhost:4321/post/2018fall/2018-09-14/</link>
      <pubDate>Fri, 14 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-09-14/</guid>
      <description>&lt;h4 id=&#34;date-2018-09-14&#34;&gt;Date: 2018-09-14&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;Nonparametric models are popular modeling tools because of their natural overall flexibility. In our&#xA;approach, we apply nonparametric techniques for panel data structures with changepoints and optional&#xA;shape constraints and the estimation is performed in a fully data driven manner by utilizing atomic pursuit&#xA;methods – LASSO regularization techniques in particular. However, in order to obtain robust estimates&#xA;and, also, to have a more complex insight into the underlying data structure, we target conditional&#xA;quantiles rather then the conditional mean only. The whole estimation process and the following inference&#xA;become both more challenging but the results are more useful in practical applications. The underlying&#xA;model is firstly introduced and some theoretical results are presented. The proposed methodology is&#xA;applied for a real data scenario and some finite sample properties are investigated via an extensive&#xA;simulation study. This is a joint work with Ivan Mizera, University of Alberta and Gabriela Ciuperca, University of Lyon&lt;/p&gt;</description>
    </item>
    <item>
      <title>Association Measures for Clustered Competing Risks Data</title>
      <link>http://localhost:4321/post/2018fall/2018-09-07/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018fall/2018-09-07/</guid>
      <description>&lt;h4 id=&#34;date-2018-09-07&#34;&gt;Date: 2018-09-07&lt;/h4&gt;&#xA;&lt;h4 id=&#34;time-1530-1630&#34;&gt;Time: 15:30-16:30&lt;/h4&gt;&#xA;&lt;h4 id=&#34;location-burn-1104&#34;&gt;Location: BURN 1104&lt;/h4&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract:&lt;/h2&gt;&#xA;&lt;p&gt;In this work, we propose a semiparametric model for multivariate clustered competing&#xA;risks data when the cause-specific failure times and the occurrence of competing risk&#xA;events among subjects within the same cluster are of interest. The cause-specific&#xA;hazard functions are assumed to follow Cox proportional hazard models, and the&#xA;associations between failure times given the same or different cause events and the&#xA;associations between occurrences of competing risk events within the same cluster are&#xA;investigated through copula models. A cross-odds ratio measure is explored under our&#xA;proposed models. Two-stage estimation procedure is proposed in which the marginal&#xA;models are estimated in the first stage, and the dependence parameters are estimated&#xA;via an Expectation-Maximization algorithm in the second stage. The proposed&#xA;estimators are shown to yield consistent and asymptotically normal under mild&#xA;regularity conditions. Simulation studies are conducted to assess finite sample&#xA;performance of the proposed method. The proposed technique is demonstrated&#xA;through an application to a multicenter Bone Marrow transplantation dataset.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
