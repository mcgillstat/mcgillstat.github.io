<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2021 fall on McGill Statistics Seminars</title>
    <link>https://mcgillstat.github.io/tags/2021-fall/</link>
    <description>Recent content in 2021 fall on McGill Statistics Seminars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://mcgillstat.github.io/tags/2021-fall/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Opinionated practices for teaching reproducibility: motivation, guided instruction and practice</title>
      <link>https://mcgillstat.github.io/post/2021fall/2021-10-29/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://mcgillstat.github.io/post/2021fall/2021-10-29/</guid>
      <description>Date: 2021-10-29 Time: 15:30-16:30 (Montreal time) Zoom Link Meeting ID: 939 8331 3215 Passcode: 096952 Abstract: In the data science courses at the University of British Columbia, we define data science as the study, development and practice of reproducible and auditable processes to obtain insight from data. While reproducibility is core to our definition, most data science learners enter the field with other aspects of data science in mind, for example predictive modelling, which is often one of the most interesting topic to novices.</description>
    </item>
    
    <item>
      <title>Imbalanced learning using actuarial modified loss function in tree-based models</title>
      <link>https://mcgillstat.github.io/post/2021fall/2021-10-08/</link>
      <pubDate>Fri, 08 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://mcgillstat.github.io/post/2021fall/2021-10-08/</guid>
      <description>Date: 2021-10-08 Time: 15:30-16:30 (Montreal time) https://mcgill.zoom.us/j/83436686293?pwd=b0RmWmlXRXE3OWR6NlNIcWF5d0dJQT09 Meeting ID: 834 3668 6293 Passcode: 12345 Abstract: Tree-based models have gained momentum in insurance claim loss modeling; however, the point mass at zero and the heavy tail of insurance loss distribution pose the challenge to apply conventional methods directly to claim loss modeling. With a simple illustrative dataset, we first demonstrate how the traditional tree-based algorithm&amp;rsquo;s splitting function fails to cope with a large proportion of data with zero responses.</description>
    </item>
    
    <item>
      <title>The HulC: Hull based Confidence Regions</title>
      <link>https://mcgillstat.github.io/post/2021fall/2021-10-01/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://mcgillstat.github.io/post/2021fall/2021-10-01/</guid>
      <description>Date: 2021-10-01 Time: 15:30-16:30 (Montreal time) https://mcgill.zoom.us/j/83436686293?pwd=b0RmWmlXRXE3OWR6NlNIcWF5d0dJQT09 Meeting ID: 834 3668 6293 Passcode: 12345 Abstract: We develop and analyze the HulC, an intuitive and general method for constructing confidence sets using the convex hull of estimates constructed from subsets of the data. Unlike classical methods which are based on estimating the (limiting) distribution of an estimator, the HulC is often simpler to use and effectively bypasses this step. In comparison to the bootstrap, the HulC requires fewer regularity conditions and succeeds in many examples where the bootstrap provably fails.</description>
    </item>
    
    <item>
      <title>Deep down, everyone wants to be causal</title>
      <link>https://mcgillstat.github.io/post/2021fall/2021-09-24/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://mcgillstat.github.io/post/2021fall/2021-09-24/</guid>
      <description>Date: 2021-09-24 Time: 15:00-16:00 (Montreal time) https://mcgill.zoom.us/j/9791073141 Meeting ID: 979 107 3141 Abstract: In the data science courses at the University of British Columbia, we define data science as the study, development and practice of reproducible and auditable processes to obtain insight from data. While reproducibility is core to our definition, most data science learners enter the field with other aspects of data science in mind, for example predictive modelling, which is often one of the most interesting topic to novices.</description>
    </item>
    
    <item>
      <title>On the Minimal Error of Empirical Risk Minimization</title>
      <link>https://mcgillstat.github.io/post/2021fall/2021-09-17/</link>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://mcgillstat.github.io/post/2021fall/2021-09-17/</guid>
      <description>Date: 2021-09-17 Time: 15:30-16:30 (Montreal time) https://mcgill.zoom.us/j/83436686293?pwd=b0RmWmlXRXE3OWR6NlNIcWF5d0dJQT09 Meeting ID: 834 3668 6293 Passcode: 12345 Abstract: In recent years, highly expressive machine learning models, i.e. models that can express rich classes of functions, are becoming more and more commonly used due their success both in regression and classification tasks, such models are deep neural nets, kernel machines and more. From the classical theory statistics point of view (the minimax theory), rich models tend to have a higher minimax rate, i.</description>
    </item>
    
    <item>
      <title>Weighted empirical processes</title>
      <link>https://mcgillstat.github.io/post/2021fall/2021-09-10/</link>
      <pubDate>Fri, 10 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://mcgillstat.github.io/post/2021fall/2021-09-10/</guid>
      <description>Date: 2021-09-10 Time: 15:30-16:30 (Montreal time) https://mcgill.zoom.us/j/83436686293?pwd=b0RmWmlXRXE3OWR6NlNIcWF5d0dJQT09 Meeting ID: 834 3668 6293 Passcode: 12345 Abstract: Empirical processes concern the uniform behavior of averaged sums over a sample of observations where the sums are indexed by a class of functions. Classical empirical processes typically study the empirical distribution function over the real line, while more modern empirical processes study much more general indexing function classes (e.g., Vapnik-Chervonenkis class, smoothness class); typical results include moment bounds and deviation inequalities.</description>
    </item>
    
  </channel>
</rss>
