<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2019 Fall on McGill Statistics Seminars</title>
    <link>/tags/2019-fall/</link>
    <description>Recent content in 2019 Fall on McGill Statistics Seminars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Nov 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/2019-fall/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title> Logarithmic divergence: from finance to optimal transport and information geometry</title>
      <link>/post/2019fall/2019-11-15/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2019fall/2019-11-15/</guid>
      <description>Date: 2019-11-15 Time: 15:30-16:30 Location: BURN 1205 Abstract: Divergences, such as the Kullback-Leibler divergence, are distance-like quantities which arise in many applications in probability, statistics and data science. We introduce a family of logarithmic divergences which is a non-linear extension of the celebrated Bregman divergence. It is defined for any exponentially concave function (a function whose exponential is concave). We motivate this divergence by mathematical finance and large deviations of Dirichlet process.</description>
    </item>
    
    <item>
      <title>Regression Models for Spatial Images</title>
      <link>/post/2019fall/2019-09-27/</link>
      <pubDate>Thu, 27 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2019fall/2019-09-27/</guid>
      <description>Date: 2019-09-27 Time: 15:30-16:30 Location: McIntyre Medical Building, Room 521 Abstract: This work is motivated by a problem in describing forest nitrogen cycling, and a consequent goal of constructing regression models for spatial images. Specifically, I present a functional concurrent linear model (FLCM) with varying coefficients for two-dimensional spatial images. To address overparameterization issues, the parameter surfaces in this model are transformed into the wavelet domain and then sparse representations are found using two different methods: LASSO and Bayesian variable selection.</description>
    </item>
    
    <item>
      <title>Deep Representation Learning using Discrete Domain Symmetries</title>
      <link>/post/2019fall/2019-09-20/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2019fall/2019-09-20/</guid>
      <description>Date: 2019-09-20 Time: 15:30-16:30 Location: BURN 1205 Abstract: Symmetry has played a significant role in modern physics, in part by constraining the physical laws. I will discuss how it could play a fundamental role in AI by constraining the deep model design. In particular, I focus on discrete domain symmetries and through examples show how we can use this inductive bias as a principled means for constraining a feedforward layer and significantly improving its sample efficiency.</description>
    </item>
    
    <item>
      <title>Integrative computational approach in genomics and healthcare</title>
      <link>/post/2019fall/2019-09-13/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2019fall/2019-09-13/</guid>
      <description>Date: 2019-09-13 Time: 15:30-16:30 Location: BURN 1205 Abstract: In the current era of multi-omics and digital healthcare, we are facing unprecedented amount of data with tremendous opportunities to link molecular phenotypes with complex diseases. However, the lack of integrative statistical method hinders system-level interrogation of relevant disease-related pathways and the genetic implication in various healthcare outcome.
In this talk, I will present our current progress in mining genomics and healthcare data.</description>
    </item>
    
    <item>
      <title>MAPLE; Semiparametric Estimation and Variable Selection for Length-biased Data with Heavy Censoring</title>
      <link>/post/2019fall/2019-09-06/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2019fall/2019-09-06/</guid>
      <description>Date: 2019-09-06 Time: 15:30-16:30 Location: BURN 1205 Abstract: In this talk, we discuss two problems of semiparametric estimation and variable selection for length-biased data with heavy censoring. The common feature of the proposed estimation procedures in the literature is that they only put probability mass on failure times. Under length-biased sampling, however, censoring is informative and failing to incorporate censored observations into estimation can lead to a substantial loss of efficiency.</description>
    </item>
    
  </channel>
</rss>